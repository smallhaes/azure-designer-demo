{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "from azureml.core import Workspace, Dataset\n",
    "from azureml.core.compute import AmlCompute, ComputeTarget\n",
    "from azureml.pipeline.core.graph import DataType\n",
    "from azureml.pipeline.wrapper import Module, dsl, Pipeline\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Warning: Falling back to use azure cli login credentials.\nIf you run your code in unattended mode, i.e., where you can't give a user input, then we recommend to use ServicePrincipalAuthentication or MsiAuthentication.\nPlease refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\nfundamental3\nfundamental\neastasia\n4f455bd0-f95a-4b7d-8d08-078611508e0b\ndict_keys(['aml-compute'])\n"
    }
   ],
   "source": [
    "subscription_id = '4f455bd0-f95a-4b7d-8d08-078611508e0b'\n",
    "resource_group = 'fundamental'\n",
    "workspace_name = 'fundamental3'\n",
    "namespace=workspace_name # for loading module\n",
    "# set this if you have multiple tenant\n",
    "tenant_id=\"72f988bf-86f1-41af-91ab-2d7cd011db47\"\n",
    "interactive_auth = InteractiveLoginAuthentication(tenant_id=tenant_id)\n",
    "\n",
    "workspace = Workspace(subscription_id, resource_group, workspace_name)\n",
    "print(workspace.name, workspace.resource_group, workspace.location, workspace.subscription_id, workspace.compute_targets.keys(),sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'aml-compute': AmlCompute(workspace=Workspace.create(name='fundamental3', subscription_id='4f455bd0-f95a-4b7d-8d08-078611508e0b', resource_group='fundamental'), name=aml-compute, id=/subscriptions/4f455bd0-f95a-4b7d-8d08-078611508e0b/resourceGroups/fundamental/providers/Microsoft.MachineLearningServices/workspaces/fundamental3/computes/aml-compute, type=AmlCompute, provisioning_state=Succeeded, location=eastasia, tags=None)}\nFound existing compute target: aml-compute\nAmlCompute(workspace=Workspace.create(name='fundamental3', subscription_id='4f455bd0-f95a-4b7d-8d08-078611508e0b', resource_group='fundamental'), name=aml-compute, id=/subscriptions/4f455bd0-f95a-4b7d-8d08-078611508e0b/resourceGroups/fundamental/providers/Microsoft.MachineLearningServices/workspaces/fundamental3/computes/aml-compute, type=AmlCompute, provisioning_state=Succeeded, location=eastasia, tags=None)\n"
    }
   ],
   "source": [
    "print(workspace.compute_targets)\n",
    "aml_compute_name = 'aml-compute'\n",
    "try:\n",
    "    aml_compute = AmlCompute(workspace, aml_compute_name)\n",
    "    print(\"Found existing compute target: {}\".format(aml_compute_name))\n",
    "except:\n",
    "    print(\"Creating new compute target: {}\".format(aml_compute_name))\n",
    "\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size=\"STANDARD_D2_V2\",\n",
    "                                                                min_nodes=1,\n",
    "                                                                max_nodes=4)\n",
    "    aml_compute = ComputeTarget.create(workspace, aml_compute_name, provisioning_config)\n",
    "    aml_compute.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "print(aml_compute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<azureml.pipeline.core.graph.DataType at 0x161ab7292b0>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# register my own datatype\n",
    "DataType.create_data_type(workspace, 'MyDirectory', description='', is_directory=True) # won't register repeatedly\n",
    "DataType.create_data_type(workspace, 'MyFile', description='', is_directory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "FileDataset\n{\n  \"source\": [\n    \"https://datastore4fasttext.blob.core.windows.net/mytest3/THUCNews.txt\"\n  ],\n  \"definition\": [\n    \"GetFiles\"\n  ],\n  \"registration\": {\n    \"id\": \"9e16ea04-3074-4f84-8a8c-83adb226c4ae\",\n    \"name\": \"THUCNews_TXT\",\n    \"version\": 1,\n    \"description\": \"THUCNews dataset is generated by filtering and filtering historical data of Sina News RSS subscription channel from 2005 to 2011\",\n    \"workspace\": \"Workspace.create(name='fundamental3', subscription_id='4f455bd0-f95a-4b7d-8d08-078611508e0b', resource_group='fundamental')\"\n  }\n}\nFileDataset\n{\n  \"source\": [\n    \"https://datastore4fasttext.blob.core.windows.net/mytest3/character2index.json\"\n  ],\n  \"definition\": [\n    \"GetFiles\"\n  ],\n  \"registration\": {\n    \"id\": \"9de9b550-46a4-41ce-b1b4-54b6c665fcf3\",\n    \"name\": \"Char2Index_JSON\",\n    \"version\": 1,\n    \"description\": \"The mapping relationship between character and index \",\n    \"workspace\": \"Workspace.create(name='fundamental3', subscription_id='4f455bd0-f95a-4b7d-8d08-078611508e0b', resource_group='fundamental')\"\n  }\n}\n"
    }
   ],
   "source": [
    "# load data\n",
    "dataset_name = 'THUCNews_TXT'\n",
    "char2index_name = 'Char2Index_JSON'\n",
    "\n",
    "if dataset_name not in workspace.datasets:\n",
    "    print('Registering a THUCNews dataset for fasttext pipeline ...')\n",
    "    path = ['https://datastore4fasttext.blob.core.windows.net/mytest3/THUCNews.txt']\n",
    "    data = Dataset.File.from_files(path=path)\n",
    "    data.register(workspace=workspace, name=dataset_name, description='THUCNews dataset is generated by filtering and filtering historical data of Sina News RSS subscription channel from 2005 to 2011')\n",
    "    print('Registerd')\n",
    "data = workspace.datasets[dataset_name]\n",
    "\n",
    "if char2index_name not in workspace.datasets:\n",
    "    print('Registering a Char2Index_JSON for fasttext pipeline ...')\n",
    "    path = ['https://datastore4fasttext.blob.core.windows.net/mytest3/character2index.json']\n",
    "    data = Dataset.File.from_files(path=path)\n",
    "    data.register(workspace=workspace, name=char2index_name, description='The mapping relationship between character and index ')\n",
    "    print('Registerd')\n",
    "char2index = workspace.datasets[char2index_name]\n",
    "\n",
    "print(data)\n",
    "print(char2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "found split_data_txt_module\nfound split_data_txt_parallel_module\nfound fasttext_train_module\nfound fasttext_evaluation_module\nfound fasttext_score_module\nfound fasttext_score_parallel_module\nfound compare2model_module\n"
    }
   ],
   "source": [
    "# load module\n",
    "try:\n",
    "    split_data_txt_module_func = Module.load(workspace=workspace, namespace=namespace, name='Split Data Txt')\n",
    "    print('found split_data_txt_module')\n",
    "except:\n",
    "    print('not found split_data_txt_module, register it now...')\n",
    "    yaml_file='split_data_txt/split_data_txt.spec.yaml'\n",
    "    split_data_txt_module_func = Module.register(workspace=workspace, yaml_file=yaml_file)\n",
    "\n",
    "try:\n",
    "    split_data_txt_parallel_module_func = Module.load(workspace=workspace, namespace=namespace, name='Split Data Txt Parallel')\n",
    "    print('found split_data_txt_parallel_module')\n",
    "except:\n",
    "    print('not found split_data_txt_parallel_module, register it now...')\n",
    "    yaml_file='split_data_txt_parallel/split_data_txt_parallel.spec.yaml'\n",
    "    split_data_txt_module_func = Module.register(workspace=workspace, yaml_file=yaml_file)\n",
    "\n",
    "try:\n",
    "    fasttext_train_module_func = Module.load(workspace=workspace, namespace=namespace, name='FastText Train')\n",
    "    print('found fasttext_train_module')\n",
    "except:\n",
    "    print('not found fasttext_train_module, register it now...')\n",
    "    yaml_file='fasttext_train/fasttext_train.spec.yaml'\n",
    "    fasttext_train_module_func = Module.register(workspace=workspace, yaml_file=yaml_file)\n",
    "\n",
    "try:\n",
    "    fasttext_evaluation_module_func = Module.load(workspace=workspace, namespace=namespace, name='FastText Evaluation')\n",
    "    print('found fasttext_evaluation_module')\n",
    "except:\n",
    "    print('not found fasttext_evaluation_module, register it now...')\n",
    "    yaml_file='fasttext_evaluation/fasttext_evaluation.spec.yaml'\n",
    "    fasttext_predict_module_func = Module.register(workspace=workspace, yaml_file=yaml_file)\n",
    "\n",
    "try:\n",
    "    fasttext_score_module_func = Module.load(workspace=workspace, namespace=namespace, name='FastText Score')\n",
    "    print('found fasttext_score_module')\n",
    "except:\n",
    "    print('not found fasttext_score_module, register it now...')\n",
    "    yaml_file='fasttext_score/fasttext_score.spec.yaml'\n",
    "    fasttext_score_module_func = Module.register(workspace=workspace, yaml_file=yaml_file)\n",
    "\n",
    "try:\n",
    "    fasttext_score_parallel_module_func = Module.load(workspace=workspace, namespace=namespace, name='FastText Score Parallel')\n",
    "    print('found fasttext_score_parallel_module')\n",
    "except:\n",
    "    print('not found fasttext_score_parallel_module, register it now...')\n",
    "    yaml_file='fasttext_score_parallel/fasttext_score_parallel.spec.yaml'\n",
    "    fasttext_score_module_func = Module.register(workspace=workspace, yaml_file=yaml_file)\n",
    "\n",
    "try:\n",
    "    compare2model_module_func = Module.load(workspace=workspace, namespace=namespace, name='Compare Two Models')\n",
    "    print('found compare2model_module')\n",
    "except:\n",
    "    print('not found compare2model_module, register it now...')\n",
    "    yaml_file='compare2model/compare2model.spec.yaml'\n",
    "    compare2model_module_func = Module.register(workspace=workspace, yaml_file=yaml_file)\n",
    "\n",
    "\n",
    "\n",
    "# inspect signature\n",
    "# print(inspect.signature(split_data_txt_module_func))\n",
    "# print(inspect.signature(split_data_txt_parallel_module_func))\n",
    "# print(inspect.signature(fasttext_train_module_func))\n",
    "# print(inspect.signature(fasttext_evaluation_module_func))\n",
    "# print(inspect.signature(fasttext_score_module_func))\n",
    "# print(inspect.signature(fasttext_score_parallel_module_func))\n",
    "# print(inspect.signature(compare2model_module_func))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# connect module\n",
    "split_data_txt = split_data_txt_module_func(\n",
    "    input_dir = data,\n",
    "    training_data_ratio = 0.7,\n",
    "    validation_data_ratio = 0.1,\n",
    "    random_split = False,\n",
    "    seed = 1\n",
    ")\n",
    "print(split_data_txt.outputs)\n",
    "\n",
    "fasttext_train = fasttext_train_module_func(\n",
    "    training_data_dir = split_data_txt.outputs.training_data_output,\n",
    "    validation_data_dir = split_data_txt.outputs.validation_data_output,\n",
    "    char2_index_dir = char2index,\n",
    "    epochs = 1,\n",
    "    batch_size = 64,\n",
    "    learning_rate = 0.0005,\n",
    "    embedding_dim = 128\n",
    ")\n",
    "print(fasttext_train.outputs)\n",
    "\n",
    "fasttext_score = fasttext_score_module_func(\n",
    "    trained_model_dir = fasttext_train.outputs.trained_model_dir,\n",
    "    test_data_dir = split_data_txt.outputs.test_data_output,\n",
    "    char2_index_dir = char2index\n",
    ")\n",
    "sentence = '受疫情影响, 今年很多学生在家里待了半年'\n",
    "fasttext_predict = fasttext_predict_module_func(\n",
    "        input_sentence =  sentence,\n",
    "        fasttext_model = fasttext_train.outputs.trained_model_dir,\n",
    "        char2_index_dir = char2index\n",
    ")\n",
    "print(fasttext_predict.outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline\n",
    "pipeline = Pipeline(nodes=[split_data_txt, fasttext_train, fasttext_score, fasttext_predict], workspace=workspace, default_compute_target=aml_compute_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate\n",
    "pipeline.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# run\n",
    "run = pipeline.submit(experiment_name='fasttext_with_one_training_process')\n",
    "run.wait_for_completion()\n",
    "pipeline.save(experiment_name='fasttext_with_one_training_process')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python_defaultSpec_1594174830013",
   "language": "python",
   "display_name": "Python 3.6.8 64-bit ('tmp2': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}