{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "from azureml.pipeline.core.graph import DataType\n",
    "from azureml.pipeline.wrapper import Module, dsl, Pipeline\n",
    "from fasttext_pipeline_utils import choose_workspace, choose_compute_target, load_dataset, register_datatype, load_module, get_source_child_run_id, download_model, register_model_from_local, register_enviroment, get_env, define_inference_configuration, deploy_locally, deploy_to_ACI, deploy_to_AKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: fundamental3\n",
      "resource_group fundamental\n",
      "location eastasia\n",
      "subscription_id 4f455bd0-f95a-4b7d-8d08-078611508e0b\n",
      "compute_targets dict_keys(['myaks2', 'aml-compute', 'my-compute'])\n"
     ]
    }
   ],
   "source": [
    "# chose a workspace\n",
    "subscription_id = '4f455bd0-f95a-4b7d-8d08-078611508e0b'\n",
    "resource_group = 'fundamental'\n",
    "workspace_name = 'fundamental3'\n",
    "# set this if you have multiple tenant\n",
    "tenant_id=\"72f988bf-86f1-41af-91ab-2d7cd011db47\"\n",
    "workspace=choose_workspace(subscription_id, resource_group, workspace_name, tenant_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing compute target: aml-compute\n",
      "AmlCompute(workspace=Workspace.create(name='fundamental3', subscription_id='4f455bd0-f95a-4b7d-8d08-078611508e0b', resource_group='fundamental'), name=aml-compute, id=/subscriptions/4f455bd0-f95a-4b7d-8d08-078611508e0b/resourceGroups/fundamental/providers/Microsoft.MachineLearningServices/workspaces/fundamental3/computes/aml-compute, type=AmlCompute, provisioning_state=Succeeded, location=eastasia, tags=None)\n"
     ]
    }
   ],
   "source": [
    "# choose a compute target\n",
    "name='aml-compute'\n",
    "aml_compute = choose_compute_target(workspace=workspace, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datatype of MyDirectory is registered\n",
      "Datatype of MyFile is registered\n"
     ]
    }
   ],
   "source": [
    "# register my own datatype\n",
    "register_datatype(workspace=workspace, name='MyDirectory', description='', is_directory=True)\n",
    "register_datatype(workspace=workspace, name='MyFile', description='', is_directory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded THUCNews_TXT\n",
      "Successfully loaded Char2Index_JSON\n",
      "data: THUCNews dataset is generated by filtering and filtering historical data of Sina News RSS subscription channel from 2005 to 2011\n",
      "char2index: The mapping relationship between character and index \n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "data = load_dataset(name='THUCNews_TXT', \n",
    "                    path=['https://datastore4fasttext.file.core.windows.net/data4fasttext/THUCNews.txt'], \n",
    "                    description='THUCNews dataset is generated by filtering and filtering historical data of Sina News RSS subscription channel from 2005 to 2011', \n",
    "                    workspace=workspace)\n",
    "\n",
    "char2index = load_dataset(name='Char2Index_JSON', \n",
    "                    path=['https://datastore4fasttext.file.core.windows.net/data4fasttext/character2index.json'], \n",
    "                    description='The mapping relationship between character and index', \n",
    "                    workspace=workspace)\n",
    "print('data:',data.description)\n",
    "print('char2index:',char2index.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found the module of Split Data Txt\n",
      "found the module of Split Data Txt Parallel\n",
      "found the module of FastText Train\n",
      "found the module of FastText Evaluation\n",
      "found the module of FastText Score\n",
      "found the module of FastText Score Parallel\n",
      "found the module of Compare Two Models\n"
     ]
    }
   ],
   "source": [
    "# load module\n",
    "namespace=workspace.name\n",
    "name='Split Data Txt'\n",
    "yaml_file_path='split_data_txt/split_data_txt.spec.yaml'\n",
    "split_data_txt_module_func = load_module(workspace, namespace, name, yaml_file_path)\n",
    "\n",
    "name='Split Data Txt Parallel'\n",
    "yaml_file_path='split_data_txt_parallel/split_data_txt_parallel.spec.yaml'\n",
    "split_data_txt_parallel_module_func = load_module(workspace, namespace, name, yaml_file_path)\n",
    "\n",
    "name='FastText Train'\n",
    "yaml_file_path='fasttext_train/fasttext_train.spec.yaml'\n",
    "fasttext_train_module_func = load_module(workspace, namespace, name, yaml_file_path)\n",
    "\n",
    "name='FastText Evaluation'\n",
    "yaml_file_path='fasttext_evaluation/fasttext_evaluation.spec.yaml'\n",
    "fasttext_evaluation_module_func = load_module(workspace, namespace, name, yaml_file_path)\n",
    "\n",
    "name='FastText Score'\n",
    "yaml_file_path='fasttext_score/fasttext_score.spec.yaml'\n",
    "fasttext_score_module_func = load_module(workspace, namespace, name, yaml_file_path)\n",
    "\n",
    "name='FastText Score Parallel'\n",
    "yaml_file_path='fasttext_score_parallel/fasttext_score_parallel.spec.yaml'\n",
    "fasttext_score_parallel_module_func = load_module(workspace, namespace, name, yaml_file_path)\n",
    "\n",
    "name='Compare Two Models'\n",
    "yaml_file_path='compare_two_models/compare_two_models.spec.yaml'\n",
    "compare_two_models_module_func = load_module(workspace, namespace, name, yaml_file_path)\n",
    "\n",
    "# inspect signature\n",
    "# print(inspect.signature(split_data_txt_module_func))\n",
    "# print(inspect.signature(split_data_txt_parallel_module_func))\n",
    "# print(inspect.signature(fasttext_train_module_func))\n",
    "# print(inspect.signature(fasttext_evaluation_module_func))\n",
    "# print(inspect.signature(fasttext_score_module_func))\n",
    "# print(inspect.signature(fasttext_score_parallel_module_func))\n",
    "# print(inspect.signature(compare2model_module_func))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# connect module\n",
    "@dsl.pipeline(name='test deploy', description='Test parallel', default_compute_target=aml_compute.name)\n",
    "def training_pipeline(epochs):\n",
    "    split_data_txt_parallel = split_data_txt_parallel_module_func(\n",
    "    input_dir = data,\n",
    "    training_data_ratio = 0.7,\n",
    "    validation_data_ratio = 0.1,\n",
    "    random_split = True,\n",
    "    seed = 7152113\n",
    "    )\n",
    "\n",
    "    fasttext_train = fasttext_train_module_func(\n",
    "    training_data_dir = split_data_txt_parallel.outputs.training_data_output,\n",
    "    validation_data_dir = split_data_txt_parallel.outputs.validation_data_output,\n",
    "    char2index_dir = char2index,\n",
    "    epochs = epochs,\n",
    "    batch_size = 64,\n",
    "    learning_rate = 0.0005,\n",
    "    embedding_dim = 128\n",
    "    )\n",
    "    \n",
    "    fasttext_score_parallel = fasttext_score_parallel_module_func(\n",
    "    texts_to_score = split_data_txt_parallel.outputs.test_data_output,\n",
    "    fasttext_model = fasttext_train.outputs.trained_model_dir,\n",
    "    char2index_dir = char2index\n",
    "    )\n",
    "    fasttext_score_parallel.runsettings.configure(node_count=4, process_count_per_node=4, mini_batch_size=128)\n",
    "\n",
    "    return {**fasttext_score_parallel.outputs, **fasttext_train.outputs}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pipeline\n",
    "pipeline = training_pipeline(epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "try {\n",
       "    require.undef(\"validate_widget\")\n",
       "\n",
       "    define('validate_widget', [\"@jupyter-widgets/base\"], function(widgets) {\n",
       "        var ValidateView = widgets.DOMWidgetView.extend({\n",
       "            render () {\n",
       "                window.widget_self = this\n",
       "                var visualize_id = this.model.get('visualize_id')\n",
       "\n",
       "                if (!window._renderLock) {\n",
       "                    window._renderLock = {}\n",
       "                }\n",
       "                if (window._renderLock[visualize_id]) {\n",
       "                    return\n",
       "                }\n",
       "                window._renderLock[visualize_id] = \"widget\"\n",
       "                console.log(\"load as widget\", Date.now())\n",
       "\n",
       "                var lib_url = this.model.get('lib_url')\n",
       "                var graph_json = JSON.parse(this.model.get('graph_json'))\n",
       "                var env_json = JSON.parse(this.model.get('env_json'))\n",
       "                var container_id = this.model.get('container_id')\n",
       "\n",
       "                window.render_container_id = container_id\n",
       "                window.graph_json = graph_json\n",
       "                window.env_json = env_json\n",
       "                window.before_script = performance.now()\n",
       "\n",
       "                var container = document.createElement('div')\n",
       "                container.id = container_id\n",
       "                this.el.appendChild(container)\n",
       "\n",
       "                var style = document.createElement('style')\n",
       "                style.innerHTML = [\n",
       "                    \"#\", container_id, \" svg.react-dag-editor-svg-container { height: 800px; }\",\n",
       "                    \".cell-output-ipywidget-background { background: transparent !important }\"\n",
       "                ].join('')\n",
       "                this.el.appendChild(style)\n",
       "\n",
       "                this.model.on('msg:custom', dispatchMessage, this);\n",
       "\n",
       "                if (!window.__event_hub) {\n",
       "                    window.__event_hub = {}\n",
       "                }\n",
       "                if (!window.__event_hub[container_id]) {\n",
       "                    window.__event_hub[container_id] = {}\n",
       "                }\n",
       "\n",
       "                if (!window.__send_event) {\n",
       "                    window.__send_event = {}\n",
       "                }\n",
       "                window.__send_event[container_id] = sendMessage.bind(this)\n",
       "\n",
       "                function sendMessage(message, uid, content) {\n",
       "                    return new Promise((resolve) => {\n",
       "                        this.model.send({\n",
       "                            message: `${message}:request`,\n",
       "                            body: {\n",
       "                                uid,\n",
       "                                content\n",
       "                            }\n",
       "                        })\n",
       "    \n",
       "                        var respMessageKey = `${message}:response`\n",
       "                        if (!window.__event_hub[container_id][respMessageKey]) {\n",
       "                            window.__event_hub[container_id][respMessageKey] = []\n",
       "                        }\n",
       "                        window.__event_hub[container_id][respMessageKey].push(callback)\n",
       "    \n",
       "                        function callback (response) {\n",
       "                            if (response.uid !== uid) {\n",
       "                                return\n",
       "                            }\n",
       "\n",
       "                            var idx = window.__event_hub[container_id][respMessageKey].indexOf(callback) \n",
       "                            window.__event_hub[container_id][respMessageKey].splice(idx, 1)\n",
       "                            \n",
       "                            resolve(response)\n",
       "                        }\n",
       "                    })\n",
       "                }\n",
       "\n",
       "                function dispatchMessage (rawMessage) {\n",
       "                    var message = rawMessage.message\n",
       "                    var body = rawMessage.body\n",
       "\n",
       "                    if (!window.__event_hub[container_id][message]) {\n",
       "                        window.__event_hub[container_id][message] = []\n",
       "                    }\n",
       "                    var listeners = window.__event_hub[container_id][message]\n",
       "\n",
       "                    listeners.forEach(cb => {\n",
       "                        try {\n",
       "                            cb(body)\n",
       "                        } catch (e) {\n",
       "                            console.error(\"Unexpected error in listener\", e)\n",
       "                        }\n",
       "                    })\n",
       "\n",
       "                    console.log(body)\n",
       "                }\n",
       "\n",
       "                var script = document.createElement('script')\n",
       "                script.src = lib_url\n",
       "                this.el.appendChild(script)\n",
       "            }\n",
       "        });\n",
       "\n",
       "        return {\n",
       "            ValidateView\n",
       "        }\n",
       "    })\n",
       "} catch (e) {\n",
       "    console.log(\"create validation widget failed\", e)\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cb890c73c9e4cb2b39ae7a6f51024bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ValidateView(container_id='container_id_2cb374a2-854f-4ce1-9e2e-33926e70acb9_widget', env_json='{\"subscription…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "        #container_id_2cb374a2-854f-4ce1-9e2e-33926e70acb9_script svg.react-dag-editor-svg-container {\n",
       "            height: 800px;\n",
       "        }\n",
       "        </style>\n",
       "        <div id=\"container_id_2cb374a2-854f-4ce1-9e2e-33926e70acb9_script\"></div>\n",
       "        <script>\n",
       "            (function () {\n",
       "                if (!window._renderLock) {\n",
       "                    window._renderLock = {}\n",
       "                }\n",
       "                if (window._renderLock[\"2cb374a2-854f-4ce1-9e2e-33926e70acb9\"]) {\n",
       "                    return\n",
       "                }\n",
       "                window._renderLock[\"2cb374a2-854f-4ce1-9e2e-33926e70acb9\"] = \"script\"\n",
       "                console.log(\"load as script\", Date.now())\n",
       "\n",
       "                window.render_container_id=\"container_id_2cb374a2-854f-4ce1-9e2e-33926e70acb9_script\";\n",
       "                window.graph_json={\"pipeline\": {\"name\": \"test deploy\", \"data_references\": {\"THUCNews_TXT\": {\"dataset_id\": \"b2319b6a-338d-4788-adfe-d55ca1db06b7\"}, \"Char2Index_JSON\": {\"dataset_id\": \"01760799-3cea-4885-9d68-04bbd10e3bd9\"}}, \"steps\": {\"00c1315b\": {\"inputs\": {\"Input_dir\": {\"source\": \"THUCNews_TXT\"}}, \"outputs\": {\"Training_data_output\": {\"destination\": \"2cf7d546-59d4-4b74-abac-658233708250_Training_data_output\"}, \"Validation_data_output\": {\"destination\": \"2cf7d546-59d4-4b74-abac-658233708250_Validation_data_output\"}, \"Test_data_output\": {\"destination\": \"2cf7d546-59d4-4b74-abac-658233708250_Test_data_output\"}}, \"module\": {\"id\": \"eecfa9fe-cff3-4ff0-9211-f7c891006fb9\", \"version\": \"0.0.10\"}, \"validate\": {\"error\": [], \"module_id\": \"eecfa9fe-cff3-4ff0-9211-f7c891006fb9\", \"namespace\": \"fundamental3\", \"module_name\": \"Split Data Txt Parallel\", \"module_version\": \"0.0.10\"}}, \"05c98329\": {\"inputs\": {\"Training_data_dir\": {\"source\": \"2cf7d546-59d4-4b74-abac-658233708250_Training_data_output\"}, \"Validation_data_dir\": {\"source\": \"2cf7d546-59d4-4b74-abac-658233708250_Validation_data_output\"}, \"Char2index_dir\": {\"source\": \"Char2Index_JSON\"}}, \"outputs\": {\"Trained_model_dir\": {\"destination\": \"d7090f4d-1490-47ee-b474-9e5b06d8b2ce_Trained_model_dir\"}}, \"module\": {\"id\": \"063c9b75-df48-4ad2-879e-74692d164e57\", \"version\": \"0.0.33\"}, \"validate\": {\"error\": [], \"module_id\": \"063c9b75-df48-4ad2-879e-74692d164e57\", \"namespace\": \"fundamental3\", \"module_name\": \"FastText Train\", \"module_version\": \"0.0.33\"}}, \"59a89e01\": {\"inputs\": {\"Texts_to_score\": {\"source\": \"2cf7d546-59d4-4b74-abac-658233708250_Test_data_output\"}, \"Fasttext_model\": {\"source\": \"d7090f4d-1490-47ee-b474-9e5b06d8b2ce_Trained_model_dir\"}, \"Char2index_dir\": {\"source\": \"Char2Index_JSON\"}}, \"outputs\": {\"Scored_dataset\": {\"destination\": \"53a35043-b956-4877-b26e-d14cdcbbc97d_Scored_dataset\"}}, \"module\": {\"id\": \"7f2731a9-c061-4acc-8784-a2ea1d80f4f8\", \"version\": \"0.0.9\"}, \"validate\": {\"error\": [], \"module_id\": \"7f2731a9-c061-4acc-8784-a2ea1d80f4f8\", \"namespace\": \"fundamental3\", \"module_name\": \"FastText Score Parallel\", \"module_version\": \"0.0.9\"}}}}, \"subGraphInfo\": [{\"name\": \"test deploy\", \"description\": \"Test parallel\", \"defaultCompute\": \"aml-compute\", \"id\": \"f24c6615-36de-4f2e-9da4-34b1f4d0d6d7\", \"parentGraphId\": null, \"inputs\": [{\"name\": \"THUCNews_TXT_2cf7d546-59d4-4b74-abac-658233708250\", \"external\": [], \"internal\": [{\"portName\": \"Input_dir\", \"nodeId\": \"00c1315b\"}]}, {\"name\": \"Char2Index_JSON_d7090f4d-1490-47ee-b474-9e5b06d8b2ce\", \"external\": [], \"internal\": [{\"portName\": \"Char2index_dir\", \"nodeId\": \"05c98329\"}]}, {\"name\": \"Char2Index_JSON_53a35043-b956-4877-b26e-d14cdcbbc97d\", \"external\": [], \"internal\": [{\"portName\": \"Char2index_dir\", \"nodeId\": \"59a89e01\"}]}], \"outputs\": [{\"name\": \"scored_dataset\", \"external\": [], \"internal\": [{\"portName\": \"Scored_dataset\", \"nodeId\": \"59a89e01\"}]}, {\"name\": \"trained_model_dir\", \"external\": [], \"internal\": [{\"portName\": \"Trained_model_dir\", \"nodeId\": \"05c98329\"}]}]}], \"nodeIdToSubGraphIdMapping\": {\"00c1315b\": \"f24c6615-36de-4f2e-9da4-34b1f4d0d6d7\", \"05c98329\": \"f24c6615-36de-4f2e-9da4-34b1f4d0d6d7\", \"59a89e01\": \"f24c6615-36de-4f2e-9da4-34b1f4d0d6d7\"}, \"modules\": [{\"module_id\": \"eecfa9fe-cff3-4ff0-9211-f7c891006fb9\", \"version\": \"0.0.10\", \"name\": \"Split Data Txt Parallel\", \"namespace\": \"fundamental3\", \"structured_interface\": {\"inputs\": [{\"name\": \"Input_dir\", \"label\": \"Input dir\", \"description\": null}], \"outputs\": [{\"name\": \"Training_data_output\", \"label\": \"Training data output\", \"description\": null}, {\"name\": \"Validation_data_output\", \"label\": \"Validation data output\", \"description\": null}, {\"name\": \"Test_data_output\", \"label\": \"Test data output\", \"description\": null}]}}, {\"module_id\": \"063c9b75-df48-4ad2-879e-74692d164e57\", \"version\": \"0.0.33\", \"name\": \"FastText Train\", \"namespace\": \"fundamental3\", \"structured_interface\": {\"inputs\": [{\"name\": \"Training_data_dir\", \"label\": \"Training data dir\", \"description\": null}, {\"name\": \"Validation_data_dir\", \"label\": \"Validation data dir\", \"description\": null}, {\"name\": \"Char2index_dir\", \"label\": \"Char2index dir\", \"description\": null}], \"outputs\": [{\"name\": \"Trained_model_dir\", \"label\": \"Trained model dir\", \"description\": null}]}}, {\"module_id\": \"7f2731a9-c061-4acc-8784-a2ea1d80f4f8\", \"version\": \"0.0.9\", \"name\": \"FastText Score Parallel\", \"namespace\": \"fundamental3\", \"structured_interface\": {\"inputs\": [{\"name\": \"Texts_to_score\", \"label\": \"Texts to score\", \"description\": null}, {\"name\": \"Fasttext_model\", \"label\": \"Fasttext model\", \"description\": null}, {\"name\": \"Char2index_dir\", \"label\": \"Char2index dir\", \"description\": null}], \"outputs\": [{\"name\": \"Scored_dataset\", \"label\": \"Scored dataset\", \"description\": null}]}}], \"datasources\": [{\"name\": \"THUCNews_TXT\", \"description\": \"THUCNews dataset is generated by filtering and filtering historical data of Sina News RSS subscription channel from 2005 to 2011\", \"version\": 1, \"tags\": {}, \"registered_id\": \"b2319b6a-338d-4788-adfe-d55ca1db06b7\", \"saved_id\": \"9e16ea04-3074-4f84-8a8c-83adb226c4ae\", \"nodeId\": \"1692ae10-3aec-3f26-b7f3-593e52e0fee5\"}, {\"name\": \"Char2Index_JSON\", \"description\": \"The mapping relationship between character and index \", \"version\": 1, \"tags\": {}, \"registered_id\": \"01760799-3cea-4885-9d68-04bbd10e3bd9\", \"saved_id\": \"9de9b550-46a4-41ce-b1b4-54b6c665fcf3\", \"nodeId\": \"dfcdcbb3-34ad-3e81-b126-5240de24d7a5\"}]};\n",
       "                window.env_json={\"subscription_id\": \"4f455bd0-f95a-4b7d-8d08-078611508e0b\"};\n",
       "                window.before_script = performance.now();\n",
       "\n",
       "                var script = document.createElement('script')\n",
       "                script.src = \"https://yucongj.azureedge.net/libs/prod/0.0.6/index.js\"\n",
       "                document.getElementById(\"container_id_2cb374a2-854f-4ce1-9e2e-33926e70acb9_script\").appendChild(script)\n",
       "            })()\n",
       "        </script>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'result': 'validation passed', 'errors': []}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualization\n",
    "pipeline.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save pipeline\n",
    "# pipeline_draft = pipeline.save(experiment_name='my test')\n",
    "# pipeline_draft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted PipelineRun 3e404217-983f-46d0-850f-1aa13bb656f9\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/parallel/runs/3e404217-983f-46d0-850f-1aa13bb656f9?wsid=/subscriptions/4f455bd0-f95a-4b7d-8d08-078611508e0b/resourcegroups/fundamental/workspaces/fundamental3\n",
      "PipelineRunId: 3e404217-983f-46d0-850f-1aa13bb656f9\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/parallel/runs/3e404217-983f-46d0-850f-1aa13bb656f9?wsid=/subscriptions/4f455bd0-f95a-4b7d-8d08-078611508e0b/resourcegroups/fundamental/workspaces/fundamental3\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "try {\n",
       "    require.undef(\"validate_widget\")\n",
       "\n",
       "    define('validate_widget', [\"@jupyter-widgets/base\"], function(widgets) {\n",
       "        var ValidateView = widgets.DOMWidgetView.extend({\n",
       "            render () {\n",
       "                window.widget_self = this\n",
       "                var visualize_id = this.model.get('visualize_id')\n",
       "\n",
       "                if (!window._renderLock) {\n",
       "                    window._renderLock = {}\n",
       "                }\n",
       "                if (window._renderLock[visualize_id]) {\n",
       "                    return\n",
       "                }\n",
       "                window._renderLock[visualize_id] = \"widget\"\n",
       "                console.log(\"load as widget\", Date.now())\n",
       "\n",
       "                var lib_url = this.model.get('lib_url')\n",
       "                var graph_json = JSON.parse(this.model.get('graph_json'))\n",
       "                var env_json = JSON.parse(this.model.get('env_json'))\n",
       "                var container_id = this.model.get('container_id')\n",
       "\n",
       "                window.render_container_id = container_id\n",
       "                window.graph_json = graph_json\n",
       "                window.env_json = env_json\n",
       "                window.before_script = performance.now()\n",
       "\n",
       "                var container = document.createElement('div')\n",
       "                container.id = container_id\n",
       "                this.el.appendChild(container)\n",
       "\n",
       "                var style = document.createElement('style')\n",
       "                style.innerHTML = [\n",
       "                    \"#\", container_id, \" svg.react-dag-editor-svg-container { height: 800px; }\",\n",
       "                    \".cell-output-ipywidget-background { background: transparent !important }\"\n",
       "                ].join('')\n",
       "                this.el.appendChild(style)\n",
       "\n",
       "                this.model.on('msg:custom', dispatchMessage, this);\n",
       "\n",
       "                if (!window.__event_hub) {\n",
       "                    window.__event_hub = {}\n",
       "                }\n",
       "                if (!window.__event_hub[container_id]) {\n",
       "                    window.__event_hub[container_id] = {}\n",
       "                }\n",
       "\n",
       "                if (!window.__send_event) {\n",
       "                    window.__send_event = {}\n",
       "                }\n",
       "                window.__send_event[container_id] = sendMessage.bind(this)\n",
       "\n",
       "                function sendMessage(message, uid, content) {\n",
       "                    return new Promise((resolve) => {\n",
       "                        this.model.send({\n",
       "                            message: `${message}:request`,\n",
       "                            body: {\n",
       "                                uid,\n",
       "                                content\n",
       "                            }\n",
       "                        })\n",
       "    \n",
       "                        var respMessageKey = `${message}:response`\n",
       "                        if (!window.__event_hub[container_id][respMessageKey]) {\n",
       "                            window.__event_hub[container_id][respMessageKey] = []\n",
       "                        }\n",
       "                        window.__event_hub[container_id][respMessageKey].push(callback)\n",
       "    \n",
       "                        function callback (response) {\n",
       "                            if (response.uid !== uid) {\n",
       "                                return\n",
       "                            }\n",
       "\n",
       "                            var idx = window.__event_hub[container_id][respMessageKey].indexOf(callback) \n",
       "                            window.__event_hub[container_id][respMessageKey].splice(idx, 1)\n",
       "                            \n",
       "                            resolve(response)\n",
       "                        }\n",
       "                    })\n",
       "                }\n",
       "\n",
       "                function dispatchMessage (rawMessage) {\n",
       "                    var message = rawMessage.message\n",
       "                    var body = rawMessage.body\n",
       "\n",
       "                    if (!window.__event_hub[container_id][message]) {\n",
       "                        window.__event_hub[container_id][message] = []\n",
       "                    }\n",
       "                    var listeners = window.__event_hub[container_id][message]\n",
       "\n",
       "                    listeners.forEach(cb => {\n",
       "                        try {\n",
       "                            cb(body)\n",
       "                        } catch (e) {\n",
       "                            console.error(\"Unexpected error in listener\", e)\n",
       "                        }\n",
       "                    })\n",
       "\n",
       "                    console.log(body)\n",
       "                }\n",
       "\n",
       "                var script = document.createElement('script')\n",
       "                script.src = lib_url\n",
       "                this.el.appendChild(script)\n",
       "            }\n",
       "        });\n",
       "\n",
       "        return {\n",
       "            ValidateView\n",
       "        }\n",
       "    })\n",
       "} catch (e) {\n",
       "    console.log(\"create validation widget failed\", e)\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71c9d40812a94e7b84b75f300e55692d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ValidateView(container_id='container_id_f8e17598-d48e-47ae-9ba8-c498bc1ee6af_widget', env_json='{}', graph_jso…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "        #container_id_f8e17598-d48e-47ae-9ba8-c498bc1ee6af_script svg.react-dag-editor-svg-container {\n",
       "            height: 800px;\n",
       "        }\n",
       "        </style>\n",
       "        <div id=\"container_id_f8e17598-d48e-47ae-9ba8-c498bc1ee6af_script\"></div>\n",
       "        <script>\n",
       "            (function () {\n",
       "                if (!window._renderLock) {\n",
       "                    window._renderLock = {}\n",
       "                }\n",
       "                if (window._renderLock[\"f8e17598-d48e-47ae-9ba8-c498bc1ee6af\"]) {\n",
       "                    return\n",
       "                }\n",
       "                window._renderLock[\"f8e17598-d48e-47ae-9ba8-c498bc1ee6af\"] = \"script\"\n",
       "                console.log(\"load as script\", Date.now())\n",
       "\n",
       "                window.render_container_id=\"container_id_f8e17598-d48e-47ae-9ba8-c498bc1ee6af_script\";\n",
       "                window.graph_json={\"pipeline\": {\"name\": \"test deploy\", \"data_references\": {\"THUCNews_TXT\": {\"dataset_id\": \"b2319b6a-338d-4788-adfe-d55ca1db06b7\"}, \"Char2Index_JSON\": {\"dataset_id\": \"01760799-3cea-4885-9d68-04bbd10e3bd9\"}}, \"steps\": {\"6d155c0c\": {\"inputs\": {\"Input_dir\": {\"source\": \"THUCNews_TXT\"}}, \"outputs\": {\"Training_data_output\": {\"destination\": \"2cf7d546-59d4-4b74-abac-658233708250_Training_data_output\"}, \"Validation_data_output\": {\"destination\": \"2cf7d546-59d4-4b74-abac-658233708250_Validation_data_output\"}, \"Test_data_output\": {\"destination\": \"2cf7d546-59d4-4b74-abac-658233708250_Test_data_output\"}}, \"module\": {\"id\": \"eecfa9fe-cff3-4ff0-9211-f7c891006fb9\", \"version\": \"0.0.10\"}, \"validate\": {\"error\": [], \"module_id\": \"eecfa9fe-cff3-4ff0-9211-f7c891006fb9\", \"namespace\": \"fundamental3\", \"module_name\": \"Split Data Txt Parallel\", \"module_version\": \"0.0.10\"}}, \"9783c0aa\": {\"inputs\": {\"Training_data_dir\": {\"source\": \"2cf7d546-59d4-4b74-abac-658233708250_Training_data_output\"}, \"Validation_data_dir\": {\"source\": \"2cf7d546-59d4-4b74-abac-658233708250_Validation_data_output\"}, \"Char2index_dir\": {\"source\": \"Char2Index_JSON\"}}, \"outputs\": {\"Trained_model_dir\": {\"destination\": \"d7090f4d-1490-47ee-b474-9e5b06d8b2ce_Trained_model_dir\"}}, \"module\": {\"id\": \"063c9b75-df48-4ad2-879e-74692d164e57\", \"version\": \"0.0.33\"}, \"validate\": {\"error\": [], \"module_id\": \"063c9b75-df48-4ad2-879e-74692d164e57\", \"namespace\": \"fundamental3\", \"module_name\": \"FastText Train\", \"module_version\": \"0.0.33\"}}, \"26d6c8e7\": {\"inputs\": {\"Texts_to_score\": {\"source\": \"2cf7d546-59d4-4b74-abac-658233708250_Test_data_output\"}, \"Fasttext_model\": {\"source\": \"d7090f4d-1490-47ee-b474-9e5b06d8b2ce_Trained_model_dir\"}, \"Char2index_dir\": {\"source\": \"Char2Index_JSON\"}}, \"outputs\": {\"Scored_dataset\": {\"destination\": \"53a35043-b956-4877-b26e-d14cdcbbc97d_Scored_dataset\"}}, \"module\": {\"id\": \"7f2731a9-c061-4acc-8784-a2ea1d80f4f8\", \"version\": \"0.0.9\"}, \"validate\": {\"error\": [], \"module_id\": \"7f2731a9-c061-4acc-8784-a2ea1d80f4f8\", \"namespace\": \"fundamental3\", \"module_name\": \"FastText Score Parallel\", \"module_version\": \"0.0.9\"}}}}, \"subGraphInfo\": [{\"name\": \"test deploy\", \"description\": \"Test parallel\", \"defaultCompute\": \"aml-compute\", \"id\": \"f24c6615-36de-4f2e-9da4-34b1f4d0d6d7\", \"parentGraphId\": null, \"inputs\": [{\"name\": \"THUCNews_TXT_2cf7d546-59d4-4b74-abac-658233708250\", \"external\": [], \"internal\": [{\"portName\": \"Input_dir\", \"nodeId\": \"6d155c0c\"}]}, {\"name\": \"Char2Index_JSON_d7090f4d-1490-47ee-b474-9e5b06d8b2ce\", \"external\": [], \"internal\": [{\"portName\": \"Char2index_dir\", \"nodeId\": \"9783c0aa\"}]}, {\"name\": \"Char2Index_JSON_53a35043-b956-4877-b26e-d14cdcbbc97d\", \"external\": [], \"internal\": [{\"portName\": \"Char2index_dir\", \"nodeId\": \"26d6c8e7\"}]}], \"outputs\": [{\"name\": \"scored_dataset\", \"external\": [], \"internal\": [{\"portName\": \"Scored_dataset\", \"nodeId\": \"26d6c8e7\"}]}, {\"name\": \"trained_model_dir\", \"external\": [], \"internal\": [{\"portName\": \"Trained_model_dir\", \"nodeId\": \"9783c0aa\"}]}]}], \"nodeIdToSubGraphIdMapping\": {\"6d155c0c\": \"f24c6615-36de-4f2e-9da4-34b1f4d0d6d7\", \"9783c0aa\": \"f24c6615-36de-4f2e-9da4-34b1f4d0d6d7\", \"26d6c8e7\": \"f24c6615-36de-4f2e-9da4-34b1f4d0d6d7\"}, \"modules\": [{\"module_id\": \"eecfa9fe-cff3-4ff0-9211-f7c891006fb9\", \"version\": \"0.0.10\", \"name\": \"Split Data Txt Parallel\", \"namespace\": \"fundamental3\", \"structured_interface\": {\"inputs\": [{\"name\": \"Input_dir\", \"label\": \"Input dir\", \"description\": null}], \"outputs\": [{\"name\": \"Training_data_output\", \"label\": \"Training data output\", \"description\": null}, {\"name\": \"Validation_data_output\", \"label\": \"Validation data output\", \"description\": null}, {\"name\": \"Test_data_output\", \"label\": \"Test data output\", \"description\": null}]}}, {\"module_id\": \"063c9b75-df48-4ad2-879e-74692d164e57\", \"version\": \"0.0.33\", \"name\": \"FastText Train\", \"namespace\": \"fundamental3\", \"structured_interface\": {\"inputs\": [{\"name\": \"Training_data_dir\", \"label\": \"Training data dir\", \"description\": null}, {\"name\": \"Validation_data_dir\", \"label\": \"Validation data dir\", \"description\": null}, {\"name\": \"Char2index_dir\", \"label\": \"Char2index dir\", \"description\": null}], \"outputs\": [{\"name\": \"Trained_model_dir\", \"label\": \"Trained model dir\", \"description\": null}]}}, {\"module_id\": \"7f2731a9-c061-4acc-8784-a2ea1d80f4f8\", \"version\": \"0.0.9\", \"name\": \"FastText Score Parallel\", \"namespace\": \"fundamental3\", \"structured_interface\": {\"inputs\": [{\"name\": \"Texts_to_score\", \"label\": \"Texts to score\", \"description\": null}, {\"name\": \"Fasttext_model\", \"label\": \"Fasttext model\", \"description\": null}, {\"name\": \"Char2index_dir\", \"label\": \"Char2index dir\", \"description\": null}], \"outputs\": [{\"name\": \"Scored_dataset\", \"label\": \"Scored dataset\", \"description\": null}]}}], \"datasources\": [{\"name\": \"THUCNews_TXT\", \"description\": \"THUCNews dataset is generated by filtering and filtering historical data of Sina News RSS subscription channel from 2005 to 2011\", \"version\": 1, \"tags\": {}, \"registered_id\": \"b2319b6a-338d-4788-adfe-d55ca1db06b7\", \"saved_id\": \"9e16ea04-3074-4f84-8a8c-83adb226c4ae\", \"nodeId\": \"1692ae10-3aec-3f26-b7f3-593e52e0fee5\"}, {\"name\": \"Char2Index_JSON\", \"description\": \"The mapping relationship between character and index \", \"version\": 1, \"tags\": {}, \"registered_id\": \"01760799-3cea-4885-9d68-04bbd10e3bd9\", \"saved_id\": \"9de9b550-46a4-41ce-b1b4-54b6c665fcf3\", \"nodeId\": \"dfcdcbb3-34ad-3e81-b126-5240de24d7a5\"}]};\n",
       "                window.env_json={};\n",
       "                window.before_script = performance.now();\n",
       "\n",
       "                var script = document.createElement('script')\n",
       "                script.src = \"https://yucongj.azureedge.net/libs/prod/0.0.6/index.js\"\n",
       "                document.getElementById(\"container_id_f8e17598-d48e-47ae-9ba8-c498bc1ee6af_script\").appendChild(script)\n",
       "            })()\n",
       "        </script>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>parallel</td><td>3e404217-983f-46d0-850f-1aa13bb656f9</td><td>azureml.PipelineRun</td><td>Completed</td><td><a href=\"https://ml.azure.com/experiments/parallel/runs/3e404217-983f-46d0-850f-1aa13bb656f9?wsid=/subscriptions/4f455bd0-f95a-4b7d-8d08-078611508e0b/resourcegroups/fundamental/workspaces/fundamental3\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: parallel,\n",
       "Id: 3e404217-983f-46d0-850f-1aa13bb656f9,\n",
       "Type: azureml.PipelineRun,\n",
       "Status: Completed)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run\n",
    "run = pipeline.submit(experiment_name='parallel', pipeline_parameters={'epochs':1})\n",
    "run.wait_for_completion()\n",
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(Experiment: parallel,\n",
      "Id: e9975a6c-e464-4e82-9e4c-f455278f3084,\n",
      "Type: azureml.StepRun,\n",
      "Status: Completed) \n",
      "\n",
      "['Trained_model_dir', 'azureml-logs/55_azureml-execution-tvmps_fb77582e7cc8ed084df58427e709a3b17a8427a4b23e098fef9097dba30fa63b_d.txt', 'azureml-logs/65_job_prep-tvmps_fb77582e7cc8ed084df58427e709a3b17a8427a4b23e098fef9097dba30fa63b_d.txt', 'azureml-logs/70_driver_log.txt', 'azureml-logs/75_job_post-tvmps_fb77582e7cc8ed084df58427e709a3b17a8427a4b23e098fef9097dba30fa63b_d.txt', 'azureml-logs/process_info.json', 'azureml-logs/process_status.json', 'logs/azureml/executionlogs.txt', 'logs/azureml/stderrlogs.txt', 'logs/azureml/stdoutlogs.txt']\n"
     ]
    }
   ],
   "source": [
    "# get the child run of FastText Train\n",
    "child_run=None\n",
    "for cr in run.get_children():\n",
    "    if cr.name == 'FastText Train':\n",
    "        child_run = cr\n",
    "print(child_run,'\\n')\n",
    "print(child_run.get_file_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path_on_data_store azureml/e5c21cd1-0fb4-4acb-b6be-ff382c3b7f89/Trained_model_dir\n",
      "target_path ./deployment\n",
      "Downloading azureml/e5c21cd1-0fb4-4acb-b6be-ff382c3b7f89/Trained_model_dir/BestModel\n",
      "Downloaded azureml/e5c21cd1-0fb4-4acb-b6be-ff382c3b7f89/Trained_model_dir/BestModel, 1 files out of an estimated total of 1\n",
      "model is downloaded to the directory of ./deployment\n"
     ]
    }
   ],
   "source": [
    "# download the trained model\n",
    "source_child_run_id=get_source_child_run_id(child_run)\n",
    "# this depends on the module of FastText Train\n",
    "trained_model_dir='Trained_model_dir'\n",
    "deploy_source_dir='./deployment'\n",
    "path_on_data_store='azureml/{}/{}'.format(source_child_run_id, trained_model_dir)\n",
    "target_path=deploy_source_dir\n",
    "print('path_on_data_store',path_on_data_store)\n",
    "print('target_path',target_path)\n",
    "download_model(workspace, path_on_data_store, target_path=target_path, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_path ./deployment/azureml/e5c21cd1-0fb4-4acb-b6be-ff382c3b7f89/Trained_model_dir/BestModel\n",
      "Registering model BestModel\n",
      "model is registered from local\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(workspace=Workspace.create(name='fundamental3', subscription_id='4f455bd0-f95a-4b7d-8d08-078611508e0b', resource_group='fundamental'), name=BestModel, id=BestModel:11, version=11, tags={'algorithm': 'fasttext'}, properties={})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# register the trained model from local\n",
    "model_name='BestModel'\n",
    "model_path=os.path.join(deploy_source_dir,path_on_data_store, model_name)\n",
    "print('model_path',model_path)\n",
    "tags={\"algorithm\": \"fasttext\"}\n",
    "model=register_model_from_local(workspace, model_name, model_path, tags=tags)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# register env\n",
    "name='env_for_deployment'\n",
    "file_path='deployment/env_for_deployment.yaml'\n",
    "env=register_enviroment(workspace, name, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define inference configuration\n",
    "entry_script='scoring_for_deployment.py'\n",
    "source_directory='deployment'\n",
    "version='1'\n",
    "environment=get_env(workspace, name, version)\n",
    "inference_config = define_inference_configuration(entry_script, source_directory, environment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model BestModel:11 to /tmp/azureml_apymmcmp/BestModel/11\n",
      "Generating Docker build context.\n",
      "Package creation Succeeded\n",
      "Logging into Docker registry fundamental33c005c1f.azurecr.io\n",
      "Logging into Docker registry fundamental33c005c1f.azurecr.io\n",
      "Building Docker image from Dockerfile...\n",
      "Step 1/5 : FROM fundamental33c005c1f.azurecr.io/azureml/azureml_55f6443a7f1f616df548a00877130395\n",
      " ---> ecd09a31e78d\n",
      "Step 2/5 : COPY azureml-app /var/azureml-app\n",
      " ---> 04acce6d7e92\n",
      "Step 3/5 : RUN mkdir -p '/var/azureml-app' && echo eyJhY2NvdW50Q29udGV4dCI6eyJzdWJzY3JpcHRpb25JZCI6IjRmNDU1YmQwLWY5NWEtNGI3ZC04ZDA4LTA3ODYxMTUwOGUwYiIsInJlc291cmNlR3JvdXBOYW1lIjoiZnVuZGFtZW50YWwiLCJhY2NvdW50TmFtZSI6ImZ1bmRhbWVudGFsMyIsIndvcmtzcGFjZUlkIjoiYTdjMmFjYWEtYzhmMS00NDhiLWI4OTQtYzJlN2E3MWIzYTMyIn0sIm1vZGVscyI6e30sIm1vZGVsc0luZm8iOnt9fQ== | base64 --decode > /var/azureml-app/model_config_map.json\n",
      " ---> Running in f0ccd6515dbc\n",
      " ---> 1ea13c418ed3\n",
      "Step 4/5 : RUN mv '/var/azureml-app/tmp3sdwlpjw.py' /var/azureml-app/main.py\n",
      " ---> Running in 944d74b1e76d\n",
      " ---> 99c004925e59\n",
      "Step 5/5 : CMD [\"runsvdir\",\"/var/runit\"]\n",
      " ---> Running in c966e34925df\n",
      " ---> 88330222b6c8\n",
      "Successfully built 88330222b6c8\n",
      "Successfully tagged local-deploy-test:latest\n",
      "Container (name:dreamy_kirch, id:7d6669c8d7b61dfbfd74aea2a77485ff5901be1499d2dc574eb342fea967ad90) cannot be killed.\n",
      "Container has been successfully cleaned up.\n",
      "Image sha256:c0c2711adbe9bc1a68b3208c0975b9ec79326dee2f7e83083d2ccfd2023681c9 successfully removed.\n",
      "Starting Docker container...\n",
      "Docker container running.\n",
      "Checking container health...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: Container has crashed. Did your init method fail?\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Container Logs:\n",
      "2020-07-15T15:05:13,765236601+00:00 - iot-server/run \n",
      "2020-07-15T15:05:13,765713704+00:00 - gunicorn/run \n",
      "2020-07-15T15:05:13,768638322+00:00 - nginx/run \n",
      "/usr/sbin/nginx: /azureml-envs/azureml_a5322dee92f8252a51213eb553ff6f2b/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_a5322dee92f8252a51213eb553ff6f2b/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_a5322dee92f8252a51213eb553ff6f2b/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_a5322dee92f8252a51213eb553ff6f2b/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_a5322dee92f8252a51213eb553ff6f2b/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "2020-07-15T15:05:13,778016980+00:00 - rsyslog/run \n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "2020-07-15T15:05:13,838245354+00:00 - iot-server/finish 1 0\n",
      "2020-07-15T15:05:13,839353560+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "Starting gunicorn 19.9.0\n",
      "Listening at: http://127.0.0.1:31311 (11)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 42\n",
      "Initialized PySpark session.\n",
      "Initializing logger\n",
      "Starting up app insights client\n",
      "Starting up request id generator\n",
      "Starting up app insight hooks\n",
      "Invoking user's init function\n",
      "=====================================================\n",
      "fasttext_model: /var/azureml-app\n",
      "char2index_dir: /var/azureml-app\n",
      "cur: ['deployment', 'azureml-models', '__pycache__', 'main.py', 'model_config_map.json']\n",
      "cur: ['character2index.json', 'scoring_for_deployment-Copy1.py', 'FastText.py', 'try_register.ipynb', '.ipynb_checkpoints', 'consume_service.ipynb', 'utils.py', 'azureml', 'env_for_deployment.yaml', 'scoring_for_deployment.py', '__pycache__']\n",
      "cur: ['BestModel']\n",
      "cur: ['11']\n",
      "======\n",
      "False\n",
      "isdir\n",
      "False\n",
      "isfile\n",
      "False\n",
      "isabs\n",
      "False\n",
      "islink\n",
      "False\n",
      "ismount\n",
      "False\n",
      "======\n",
      "User's init function failed\n",
      "Encountered Exception Traceback (most recent call last):\n",
      "  File \"/var/azureml-server/aml_blueprint.py\", line 163, in register\n",
      "    main.init()\n",
      "  File \"/var/azureml-app/main.py\", line 35, in init\n",
      "    driver_module.init()\n",
      "  File \"/var/azureml-app/deployment/scoring_for_deployment.py\", line 41, in init\n",
      "    model = torch.load(f=path)\n",
      "  File \"/azureml-envs/azureml_a5322dee92f8252a51213eb553ff6f2b/lib/python3.6/site-packages/torch/serialization.py\", line 525, in load\n",
      "    with _open_file_like(f, 'rb') as opened_file:\n",
      "  File \"/azureml-envs/azureml_a5322dee92f8252a51213eb553ff6f2b/lib/python3.6/site-packages/torch/serialization.py\", line 212, in _open_file_like\n",
      "    return _open_file(name_or_buffer, mode)\n",
      "  File \"/azureml-envs/azureml_a5322dee92f8252a51213eb553ff6f2b/lib/python3.6/site-packages/torch/serialization.py\", line 193, in __init__\n",
      "    super(_open_file, self).__init__(open(name, mode))\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'azureml-models/BestModel_tmp/1/BestModel'\n",
      "\n",
      "Worker exiting (pid: 42)\n",
      "Shutting down: Master\n",
      "Reason: Worker failed to boot.\n",
      "2020-07-15T15:05:15,539925303+00:00 - gunicorn/finish 3 0\n",
      "2020-07-15T15:05:15,541127210+00:00 - Exit code 3 is not normal. Killing image.\n",
      "\n"
     ]
    },
    {
     "ename": "WebserviceException",
     "evalue": "WebserviceException:\n\tMessage: Error: Container has crashed. Did your init method fail?\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Error: Container has crashed. Did your init method fail?\"\n    }\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWebserviceException\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-d75932af8f31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8891\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mservice_locally\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeploy_locally\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mservice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minference_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/mnt/batch/tasks/shared/LS_root/mounts/clusters/my-compute/code/Users/t-yangx/azureml-designer-demo/fasttext_pipeline_utils.py\u001b[0m in \u001b[0;36mdeploy_locally\u001b[0;34m(workspace, service_name, models, inference_config, port)\u001b[0m\n\u001b[1;32m    138\u001b[0m     service = Model.deploy(workspace=workspace, name=service_name, models=models, inference_config=inference_config,\n\u001b[1;32m    139\u001b[0m                            deployment_config=deployment_config)\n\u001b[0;32m--> 140\u001b[0;31m     \u001b[0mservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_deployment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshow_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mservice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/tmp2/lib/python3.6/site-packages/azureml/core/webservice/local.py\u001b[0m in \u001b[0;36mdecorated\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m                 raise WebserviceException('Cannot call {}() when service is {}.'.format(func.__name__, self.state),\n\u001b[1;32m     70\u001b[0m                                           logger=module_logger)\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/tmp2/lib/python3.6/site-packages/azureml/core/webservice/local.py\u001b[0m in \u001b[0;36mwait_for_deployment\u001b[0;34m(self, show_output)\u001b[0m\n\u001b[1;32m    601\u001b[0m                                    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m                                    \u001b[0mhealth_url\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_base_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m                                    cleanup_if_failed=False)\n\u001b[0m\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLocalWebservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTATE_RUNNING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/tmp2/lib/python3.6/site-packages/azureml/_model_management/_util.py\u001b[0m in \u001b[0;36mcontainer_health_check\u001b[0;34m(docker_port, container, health_url, cleanup_if_failed)\u001b[0m\n\u001b[1;32m    745\u001b[0m             \u001b[0;31m# The container has started and crashed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m             _raise_for_container_failure(container, cleanup_if_failed,\n\u001b[0;32m--> 747\u001b[0;31m                                          'Error: Container has crashed. Did your init method fail?')\n\u001b[0m\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m         \u001b[0;31m# The container hasn't crashed, so try to ping the health endpoint.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/tmp2/lib/python3.6/site-packages/azureml/_model_management/_util.py\u001b[0m in \u001b[0;36m_raise_for_container_failure\u001b[0;34m(container, cleanup, message)\u001b[0m\n\u001b[1;32m   1258\u001b[0m         \u001b[0mcleanup_container\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1260\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mWebserviceException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodule_logger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mWebserviceException\u001b[0m: WebserviceException:\n\tMessage: Error: Container has crashed. Did your init method fail?\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Error: Container has crashed. Did your init method fail?\"\n    }\n}"
     ]
    }
   ],
   "source": [
    "# deploy locally\n",
    "service_name='local-deploy-test'\n",
    "models=[model]\n",
    "port=8891\n",
    "service_locally = deploy_locally(workspace, service_name, models, inference_config, port=port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deploy to ACI (Azure Container Instances)\n",
    "service_name='ACI-deploy-test'\n",
    "models=[model]\n",
    "service_aci=deploy_to_ACI(workspace, service_name, models, inference_config, cpu_cores=1, memory_gb=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# workspace with AKS\n",
    "subscription_id = '74eccef0-4b8d-4f83-b5f9-fa100d155b22'\n",
    "resource_group = 'DesignerDRI'\n",
    "workspace_name = 'DesignerDRI_EASTUS'\n",
    "namespace=workspace_name # for loading module\n",
    "# set this if you have multiple tenant\n",
    "tenant_id=\"72f988bf-86f1-41af-91ab-2d7cd011db47\"\n",
    "interactive_auth = InteractiveLoginAuthentication(tenant_id=tenant_id)\n",
    "\n",
    "ws = Workspace(subscription_id, resource_group, workspace_name)\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, ws.compute_targets.keys(),sep = '\\n')\n",
    "\n",
    "\n",
    "\n",
    "# chose a workspace\n",
    "subscription_id = '4f455bd0-f95a-4b7d-8d08-078611508e0b'\n",
    "resource_group = 'fundamental'\n",
    "workspace_name = 'fundamental3'\n",
    "# set this if you have multiple tenant\n",
    "tenant_id=\"72f988bf-86f1-41af-91ab-2d7cd011db47\"\n",
    "workspace=choose_workspace(subscription_id, resource_group, workspace_name, tenant_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deploy to AKS (Azure Kubernetes Service)\n",
    "workspace=\n",
    "attachment_name='aaa'\n",
    "service_name='AKS-deploy-test'\n",
    "models=[model]\n",
    "token_auth_enabled=True\n",
    "deploy_to_AKS(workspace, attachment_name, service_name, models, inference_config, token_auth_enabled=token_auth_enabled,\n",
    "                  cpu_cores=1, memory_gb=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice, Webservice, LocalWebservice\n",
    "from azureml.core.model import Model\n",
    "\n",
    "# deployment_config = AciWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 1)\n",
    "deployment_config_local = LocalWebservice.deploy_configuration(port=8890)\n",
    "service_local = Model.deploy(workspace=workspace, name=\"my-deployment1\", models=[my_model], inference_config=inference_config, deployment_config=deployment_config)\n",
    "service_local.wait_for_deployment(show_output = True)\n",
    "print(service_local.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(service_local.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "\n",
    "# Get a token to authenticate to the compute instance from remote\n",
    "interactive_auth = InteractiveLoginAuthentication()\n",
    "auth_header = interactive_auth.get_authentication_header()\n",
    "\n",
    "# Create and submit a request using the auth header\n",
    "headers = auth_header\n",
    "# Add content type header\n",
    "headers.update({'Content-Type':'application/json'})\n",
    "# print(headers)\n",
    "\n",
    "\n",
    "standard_sample_input = {'param':{'input_sentence': 'haha   haha i want to travel around the world'}}\n",
    "standard_sample_input = {'param':{'input_sentence': '受疫情影响, 今年很多学生不得不在家上课'}}\n",
    "standard_sample_input = json.dumps(standard_sample_input)\n",
    "# print(type(standard_sample_input))\n",
    "# standard_sample_output = {'category': 'dream'}\n",
    "\n",
    "\n",
    "response = requests.post(service_local.scoring_uri, data=standard_sample_input, headers=headers)\n",
    "print(service_local.scoring_uri)\n",
    "print(response)\n",
    "print(response.status_code)\n",
    "print(response.elapsed)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "pprint(service_local.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service.scoring_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa= json.loads(standard_sample_input)\n",
    "print(aaa)\n",
    "print(type(aaa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reuse为Yes时的properties\n",
    "aaa= all_child_run[-2].properties\n",
    "aaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reuse为No时的properties\n",
    "aaa= all_child_run[-2].properties\n",
    "aaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#获取run id\n",
    "all_child_run[-2].id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(aaa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 部署到ACI上\n",
    "from azureml.core.webservice import AciWebservice, Webservice\n",
    "from azureml.core.model import Model\n",
    "\n",
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 1)\n",
    "service = Model.deploy(workspace, \"aci-deployment1\", models=[my_model], inference_config=inference_config, deployment_config=deployment_config)\n",
    "service.wait_for_deployment(show_output = True)\n",
    "print(service.state)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "\n",
    "# Get a token to authenticate to the compute instance from remote\n",
    "interactive_auth = InteractiveLoginAuthentication()\n",
    "auth_header = interactive_auth.get_authentication_header()\n",
    "\n",
    "# Create and submit a request using the auth header\n",
    "headers = auth_header\n",
    "# Add content type header\n",
    "headers.update({'Content-Type':'application/json'})\n",
    "# print(headers)\n",
    "\n",
    "\n",
    "standard_sample_input = {'param':{'input_sentence': 'haha   haha i want to travel around the world'}}\n",
    "standard_sample_input = {'param':{'input_sentence': '2020年受疫情影响, 今年很多学生不得不在家上课'}}\n",
    "standard_sample_input = json.dumps(standard_sample_input)\n",
    "# print(type(standard_sample_input))\n",
    "# standard_sample_output = {'category': 'dream'}\n",
    "\n",
    "\n",
    "response = requests.post(service.scoring_uri, data=standard_sample_input, headers=headers)\n",
    "print(service.scoring_uri)\n",
    "print(response.status_code)\n",
    "print(response.elapsed)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "pprint(service.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 部署到AKS上\n",
    "subscription_id = '74eccef0-4b8d-4f83-b5f9-fa100d155b22'\n",
    "resource_group = 'DesignerDRI'\n",
    "workspace_name = 'DesignerDRI_EASTUS'\n",
    "namespace=workspace_name # for loading module\n",
    "# set this if you have multiple tenant\n",
    "tenant_id=\"72f988bf-86f1-41af-91ab-2d7cd011db47\"\n",
    "interactive_auth = InteractiveLoginAuthentication(tenant_id=tenant_id)\n",
    "\n",
    "ws = Workspace(subscription_id, resource_group, workspace_name)\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, ws.compute_targets.keys(),sep = '\\n')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws.compute_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from azureml.core.compute import AksCompute, ComputeTarget\n",
    "# Set the resource group that contains the AKS cluster and the cluster name\n",
    "resource_group = 'DesignerDRI'\n",
    "cluster_name = 'attachedcompute'\n",
    "# The Azure resource ID for the compute resource being attached.\n",
    "resource_id = '/subscriptions/74eccef0-4b8d-4f83-b5f9-fa100d155b22/resourcegroups/DesignerDRI/providers/Microsoft.ContainerService/managedClusters/designerdri-weu1d991123'\n",
    "cluster_purpose = None\n",
    "\n",
    "# Attach the cluster to your workgroup. If the cluster has less than 12 virtual CPUs, use the following instead:\n",
    "# attach_config = AksCompute.attach_configuration(resource_group = resource_group,\n",
    "#                                         cluster_name = cluster_name,\n",
    "#                                         cluster_purpose = AksCompute.ClusterPurpose.DEV_TEST)\n",
    "\n",
    "#参考这个...\n",
    "# attach_config = AksCompute.attach_configuration(resource_group = resource_group,\n",
    "#                                                  cluster_name = cluster_name,\n",
    "#                                                resource_id = resource_id,\n",
    "#                                                 cluster_purpose = cluster_purpose\n",
    "#                                                )\n",
    "\n",
    "# 这样写才成功\n",
    "attach_config = AksCompute.attach_configuration(\n",
    "                                               resource_id = resource_id,\n",
    "                                                cluster_purpose = cluster_purpose\n",
    "                                               )\n",
    "# aks_target = ComputeTarget.attach(ws, cluster_name, attach_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import AksCompute\n",
    "# resource_id = 'designerdri-weu1d991123'\n",
    "resource_id = '/subscriptions/74eccef0-4b8d-4f83-b5f9-fa100d155b22/resourcegroups/DesignerDRI/providers/Microsoft.ContainerService/managedClusters/designerdri-weu1d991123'\n",
    "attach_config = AksCompute.attach_configuration(resource_id = resource_id)\n",
    "attach_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(attach_config.cluster_name)\n",
    "print(attach_config.cluster_purpose)\n",
    "print(attach_config.leaf_domain_label)\n",
    "print(attach_config.overwrite_existing_domain)\n",
    "print(attach_config.resource_group)\n",
    "print(attach_config.resource_id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aks_target = ComputeTarget.attach(ws, 'myaks1', attach_config)\n",
    "aks_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import Model\n",
    "# 使用fundamental3的BestModel_tmp  会出问题...  模型必须在当前workspace下\n",
    "model_aks = Model(workspace=ws, name='BestModel_tmp', version='1')\n",
    "model_aks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define inference configuration\n",
    "from azureml.core.environment import Environment\n",
    "from azureml.core.model import InferenceConfig\n",
    "\n",
    "myenv_aks = Environment.get(workspace=workspace, name='env_for_deployment', version='1')\n",
    "inference_config_aks = InferenceConfig(entry_script='scoring_for_deployment.py',\n",
    "                                   source_directory='deployment',\n",
    "                                   environment=myenv)\n",
    "inference_config_aks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#deploy to aks\n",
    "from azureml.core.webservice import AksWebservice, Webservice\n",
    "from azureml.core.model import Model\n",
    "\n",
    "aks_target = AksCompute(ws,\"myaks1\")\n",
    "# If deploying to a cluster configured for dev/test, ensure that it was created with enough\n",
    "# cores and memory to handle this deployment configuration. Note that memory is also used by\n",
    "# things such as dependencies and AML components.\n",
    "deployment_config = AksWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 1)\n",
    "service = Model.deploy(ws, \"myservice3\", [model_aks], inference_config_aks, deployment_config, aks_target)\n",
    "service.wait_for_deployment(show_output = True)\n",
    "print(service.state)\n",
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "pprint(service.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary, secondary = service.get_keys()\n",
    "print(primary)\n",
    "print(secondary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "\n",
    "# Get a token to authenticate to the compute instance from remote\n",
    "interactive_auth = InteractiveLoginAuthentication()\n",
    "auth_header = interactive_auth.get_authentication_header()\n",
    "\n",
    "# Create and submit a request using the auth header\n",
    "# headers = auth_header  # 这里用的是token, 不适用于key\n",
    "headers = {}\n",
    "primary, secondary = service.get_keys()\n",
    "headers['Authorization'] = f'Bearer {primary}'\n",
    "# Add content type header\n",
    "headers.update({'Content-Type':'application/json'})\n",
    "# print(headers)\n",
    "print(headers)\n",
    "\n",
    "standard_sample_input = {'param':{'input_sentence': 'haha   haha i want to travel around the world'}}\n",
    "standard_sample_input = {'param':{'input_sentence': '2020年受疫情影响, 今年很多学生不得不在家上课'}}\n",
    "standard_sample_input = json.dumps(standard_sample_input)\n",
    "# print(type(standard_sample_input))\n",
    "# standard_sample_output = {'category': 'dream'}\n",
    "\n",
    "\n",
    "response = requests.post(service.scoring_uri, data=standard_sample_input, headers=headers)\n",
    "print(service.scoring_uri)\n",
    "print(response.status_code)\n",
    "print(response.elapsed)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tmp2",
   "language": "python",
   "name": "tmp2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
