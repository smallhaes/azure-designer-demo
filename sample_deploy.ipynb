{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./azureml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Model\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.environment import Environment\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.pipeline.wrapper import PipelineRun\n",
    "from fasttext_pipeline_utils import choose_workspace, deploy_locally, deploy_to_ACI, deploy_to_AKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: fundamental3\n",
      "resource_group fundamental\n",
      "location eastasia\n",
      "subscription_id 4f455bd0-f95a-4b7d-8d08-078611508e0b\n",
      "compute_targets dict_keys(['myaks2', 'aml-compute', 'my-compute', 'compute-deploy'])\n"
     ]
    }
   ],
   "source": [
    "# chose a workspace\n",
    "subscription_id = '4f455bd0-f95a-4b7d-8d08-078611508e0b'\n",
    "resource_group = 'fundamental'\n",
    "workspace_name = 'fundamental3'\n",
    "# set this if you have multiple tenant\n",
    "tenant_id=\"72f988bf-86f1-41af-91ab-2d7cd011db47\"\n",
    "workspace=choose_workspace(subscription_id, resource_group, workspace_name, tenant_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a PipelineRun object\n",
    "experiment_name = \"deploy\"\n",
    "experiment = Experiment(workspace, experiment_name)\n",
    "run_id = '24f0ba77-1ef8-4a9a-b9a8-9ed14d98190e'\n",
    "pipeline_run = PipelineRun(experiment, run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a StepRun object\n",
    "step_run = pipeline_run.find_step_run(name = 'FastText Train')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input ports:\n",
      "Port(Name:Training data dir,\n",
      "Type:['AnyDirectory'],\n",
      "StepRun:Run(Experiment: deploy,\n",
      "Id: 358a3e99-f299-4089-b2cf-cecc32ac34f8,\n",
      "Type: azureml.StepRun,\n",
      "Status: Completed)) \n",
      "\n",
      "Port(Name:Validation data dir,\n",
      "Type:['AnyDirectory'],\n",
      "StepRun:Run(Experiment: deploy,\n",
      "Id: 358a3e99-f299-4089-b2cf-cecc32ac34f8,\n",
      "Type: azureml.StepRun,\n",
      "Status: Completed)) \n",
      "\n",
      "Port(Name:Char2index dir,\n",
      "Type:['AnyDirectory'],\n",
      "StepRun:Run(Experiment: deploy,\n",
      "Id: 358a3e99-f299-4089-b2cf-cecc32ac34f8,\n",
      "Type: azureml.StepRun,\n",
      "Status: Completed)) \n",
      "\n",
      "\n",
      "\n",
      "output ports:\n",
      "Port(Name:Trained model dir,\n",
      "Type:['ModelDirectory'],\n",
      "StepRun:Run(Experiment: deploy,\n",
      "Id: 358a3e99-f299-4089-b2cf-cecc32ac34f8,\n",
      "Type: azureml.StepRun,\n",
      "Status: Completed)) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check ports\n",
    "print('input ports:')\n",
    "input_ports = step_run.input_ports\n",
    "for port in input_ports:\n",
    "    print(port,'\\n')\n",
    "output_ports = step_run.output_ports\n",
    "print('\\n\\noutput ports:')\n",
    "for port in output_ports:\n",
    "    print(port,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading azureml/358a3e99-f299-4089-b2cf-cecc32ac34f8/Trained_model_dir/BestModel\n",
      "Downloaded azureml/358a3e99-f299-4089-b2cf-cecc32ac34f8/Trained_model_dir/BestModel, 1 files out of an estimated total of 1\n",
      "model save at: data/azureml/358a3e99-f299-4089-b2cf-cecc32ac34f8/Trained_model_dir\n"
     ]
    }
   ],
   "source": [
    "# download model from the output port of the Train module\n",
    "port = step_run.get_port(name='Trained model dir')\n",
    "saved_path = port.download(local_path='data', overwrite=True)\n",
    "print('model save at: {}'.format(saved_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model model_for_deploy\n"
     ]
    }
   ],
   "source": [
    "# register model for deployment\n",
    "model_name = os.listdir(saved_path)[0]\n",
    "model_path = os.path.join(saved_path, model_name)\n",
    "model = Model.register(workspace, model_path=model_path, model_name='model_for_deploy', tags={'deploy':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# register env if not registered before\n",
    "name='env_for_deployment'\n",
    "file_path='deployment/env_for_deployment.yaml'\n",
    "env = Environment.from_conda_specification(name=name, file_path=file_path)\n",
    "env = env.register(workspace=workspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define inference configuration\n",
    "entry_script='scoring_for_deployment.py'\n",
    "version='1'\n",
    "source_directory='deployment'\n",
    "env = Environment.get(workspace=workspace, name=name, version=version)\n",
    "inference_config = InferenceConfig(entry_script=entry_script, source_directory=source_directory,\n",
    "                                       environment=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model model_for_deploy:6 to /tmp/azureml_rv5orlov/model_for_deploy/6\n",
      "Generating Docker build context.\n",
      "Package creation Succeeded\n",
      "Logging into Docker registry fundamental33c005c1f.azurecr.io\n",
      "Logging into Docker registry fundamental33c005c1f.azurecr.io\n",
      "Building Docker image from Dockerfile...\n",
      "Step 1/5 : FROM fundamental33c005c1f.azurecr.io/azureml/azureml_55f6443a7f1f616df548a00877130395\n",
      " ---> ecd09a31e78d\n",
      "Step 2/5 : COPY azureml-app /var/azureml-app\n",
      " ---> b9bf541da553\n",
      "Step 3/5 : RUN mkdir -p '/var/azureml-app' && echo eyJhY2NvdW50Q29udGV4dCI6eyJzdWJzY3JpcHRpb25JZCI6IjRmNDU1YmQwLWY5NWEtNGI3ZC04ZDA4LTA3ODYxMTUwOGUwYiIsInJlc291cmNlR3JvdXBOYW1lIjoiZnVuZGFtZW50YWwiLCJhY2NvdW50TmFtZSI6ImZ1bmRhbWVudGFsMyIsIndvcmtzcGFjZUlkIjoiYTdjMmFjYWEtYzhmMS00NDhiLWI4OTQtYzJlN2E3MWIzYTMyIn0sIm1vZGVscyI6e30sIm1vZGVsc0luZm8iOnt9fQ== | base64 --decode > /var/azureml-app/model_config_map.json\n",
      " ---> Running in cfe265a904fb\n",
      " ---> 04b28734cda3\n",
      "Step 4/5 : RUN mv '/var/azureml-app/tmpaffevggy.py' /var/azureml-app/main.py\n",
      " ---> Running in df7f7dbead10\n",
      " ---> c8365c81d6cb\n",
      "Step 5/5 : CMD [\"runsvdir\",\"/var/runit\"]\n",
      " ---> Running in 8792f31e490a\n",
      " ---> 8499a4a2e899\n",
      "Successfully built 8499a4a2e899\n",
      "Successfully tagged local-deploy-test:latest\n",
      "Container has been successfully cleaned up.\n",
      "Image sha256:d16d69f8031335cc6362c9f6567d246b6c79b84e3a04003c5871cd4dbeb91f2a successfully removed.\n",
      "Starting Docker container...\n",
      "Docker container running.\n",
      "Checking container health...\n",
      "Local webservice is running at http://localhost:8892\n",
      "running\n",
      "2020-08-03T06:45:53,404215555+00:00 - iot-server/run \n",
      "2020-08-03T06:45:53,405989366+00:00 - nginx/run \n",
      "/usr/sbin/nginx: /azureml-envs/azureml_a5322dee92f8252a51213eb553ff6f2b/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_a5322dee92f8252a51213eb553ff6f2b/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_a5322dee92f8252a51213eb553ff6f2b/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_a5322dee92f8252a51213eb553ff6f2b/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_a5322dee92f8252a51213eb553ff6f2b/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "2020-08-03T06:45:53,412785908+00:00 - gunicorn/run \n",
      "2020-08-03T06:45:53,413540813+00:00 - rsyslog/run \n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "2020-08-03T06:45:53,483455444+00:00 - iot-server/finish 1 0\n",
      "2020-08-03T06:45:53,484622751+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "Starting gunicorn 19.9.0\n",
      "Listening at: http://127.0.0.1:31311 (11)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 41\n",
      "Initialized PySpark session.\n",
      "Initializing logger\n",
      "Starting up app insights client\n",
      "Starting up request id generator\n",
      "Starting up app insight hooks\n",
      "Invoking user's init function\n",
      "Users's init has completed successfully\n",
      "Skipping middleware: dbg_model_info as it's not enabled.\n",
      "Scoring timeout setting is not found. Use default timeout: 3600000 ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# deploy locally\n",
    "service_name='local-deploy-test'\n",
    "models=[model]\n",
    "port=8892\n",
    "service_locally = deploy_locally(workspace, service_name, models, inference_config, port=port)\n",
    "print(service_locally.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# deploy to ACI (Azure Container Instances)\n",
    "# every time we deploy to ACI, we need to change the service_name or we delete the existing service beforehand\n",
    "service_name='aci-deploy-test7'\n",
    "models=[model]\n",
    "service_aci=deploy_to_ACI(workspace, service_name, models, inference_config, cpu_cores=1, memory_gb=1, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# deploy to AKS (Azure Kubernetes Service)\n",
    "# workspace with AKS\n",
    "subscription_id = '74eccef0-4b8d-4f83-b5f9-fa100d155b22'\n",
    "resource_group = 'DesignerDRI'\n",
    "workspace_name = 'DesignerDRI_EASTUS'\n",
    "# set this if you have multiple tenant\n",
    "tenant_id=\"72f988bf-86f1-41af-91ab-2d7cd011db47\"\n",
    "\n",
    "workspace_aks=choose_workspace(subscription_id, resource_group, workspace_name, tenant_id)\n",
    "attachment_name='myaks1'\n",
    "# every time we deploy to ACI, we need to change the service_name or we delete the existing service beforehand\n",
    "service_name='aks-deploy-test7'\n",
    "models=[model]\n",
    "token_auth_enabled=True\n",
    "service_aks=deploy_to_AKS(workspace_aks, attachment_name, service_name, models, inference_config, token_auth_enabled=token_auth_enabled,\n",
    "                  cpu_cores=1, memory_gb=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8892/score\n",
      "<Response [200]>\n",
      "b'\"politics\"'\n",
      "politics\n"
     ]
    }
   ],
   "source": [
    "# consume service\n",
    "# consume deployment\n",
    "import requests\n",
    "import json\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "\n",
    "# Get a token to authenticate to the compute instance from remote\n",
    "interactive_auth = InteractiveLoginAuthentication()\n",
    "auth_header = interactive_auth.get_authentication_header()\n",
    "\n",
    "# Create and submit a request using the auth header\n",
    "headers = auth_header\n",
    "# Add content type header\n",
    "headers.update({'Content-Type':'application/json'})\n",
    "# print(headers)\n",
    "\n",
    "\n",
    "standard_sample_input = {'param':{'input_sentence': '受疫情影响, 今年很多学生不得不在家上课'}}\n",
    "standard_sample_input = json.dumps(standard_sample_input)\n",
    "\n",
    "service = service_locally\n",
    "# service = service_aci\n",
    "\n",
    "# service = service_aks\n",
    "# token, refresh_by = service.get_token()\n",
    "# headers['Authorization']=f'Bearer {token}'\n",
    "\n",
    "\n",
    "response = requests.post(service.scoring_uri, data=standard_sample_input, headers=headers)\n",
    "print(service.scoring_uri)\n",
    "print(response)\n",
    "# print(response.status_code)\n",
    "# print(response.elapsed)\n",
    "print(response.content)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tmp2",
   "language": "python",
   "name": "tmp2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
