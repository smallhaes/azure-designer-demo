{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./azureml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Model\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.environment import Environment\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.pipeline.wrapper import PipelineRun\n",
    "from fasttext_pipeline_utils import choose_workspace, deploy_locally, deploy_to_ACI, deploy_to_AKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: fundamental3\n",
      "resource_group fundamental\n",
      "location eastasia\n",
      "subscription_id 4f455bd0-f95a-4b7d-8d08-078611508e0b\n",
      "compute_targets dict_keys(['myaks2', 'aml-compute', 'my-compute', 'compute-deploy'])\n"
     ]
    }
   ],
   "source": [
    "# chose a workspace\n",
    "subscription_id = '4f455bd0-f95a-4b7d-8d08-078611508e0b'\n",
    "resource_group = 'fundamental'\n",
    "workspace_name = 'fundamental3'\n",
    "# set this if you have multiple tenant\n",
    "tenant_id=\"72f988bf-86f1-41af-91ab-2d7cd011db47\"\n",
    "workspace=choose_workspace(subscription_id, resource_group, workspace_name, tenant_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a PipelineRun object\n",
    "experiment_name = \"deploy\"\n",
    "experiment = Experiment(workspace, experiment_name)\n",
    "run_id = '24f0ba77-1ef8-4a9a-b9a8-9ed14d98190e'\n",
    "pipeline_run = PipelineRun(experiment, run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a StepRun object\n",
    "step_run = pipeline_run.find_step_run(name = 'FastText Train')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input ports:\n",
      "Port(Name:Training data dir,\n",
      "Type:['AnyDirectory'],\n",
      "StepRun:Run(Experiment: deploy,\n",
      "Id: 358a3e99-f299-4089-b2cf-cecc32ac34f8,\n",
      "Type: azureml.StepRun,\n",
      "Status: Completed)) \n",
      "\n",
      "Port(Name:Validation data dir,\n",
      "Type:['AnyDirectory'],\n",
      "StepRun:Run(Experiment: deploy,\n",
      "Id: 358a3e99-f299-4089-b2cf-cecc32ac34f8,\n",
      "Type: azureml.StepRun,\n",
      "Status: Completed)) \n",
      "\n",
      "Port(Name:Char2index dir,\n",
      "Type:['AnyDirectory'],\n",
      "StepRun:Run(Experiment: deploy,\n",
      "Id: 358a3e99-f299-4089-b2cf-cecc32ac34f8,\n",
      "Type: azureml.StepRun,\n",
      "Status: Completed)) \n",
      "\n",
      "\n",
      "\n",
      "output ports:\n",
      "Port(Name:Trained model dir,\n",
      "Type:['ModelDirectory'],\n",
      "StepRun:Run(Experiment: deploy,\n",
      "Id: 358a3e99-f299-4089-b2cf-cecc32ac34f8,\n",
      "Type: azureml.StepRun,\n",
      "Status: Completed)) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check ports\n",
    "print('input ports:')\n",
    "input_ports = step_run.input_ports\n",
    "for port in input_ports:\n",
    "    print(port,'\\n')\n",
    "output_ports = step_run.output_ports\n",
    "print('\\n\\noutput ports:')\n",
    "for port in output_ports:\n",
    "    print(port,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading azureml/358a3e99-f299-4089-b2cf-cecc32ac34f8/Trained_model_dir/BestModel\n",
      "Downloaded azureml/358a3e99-f299-4089-b2cf-cecc32ac34f8/Trained_model_dir/BestModel, 1 files out of an estimated total of 1\n",
      "model save at: data/azureml/358a3e99-f299-4089-b2cf-cecc32ac34f8/Trained_model_dir\n"
     ]
    }
   ],
   "source": [
    "# download model from the output port of the Train module\n",
    "port = step_run.get_port(name='Trained model dir')\n",
    "saved_path = port.download(local_path='data', overwrite=True)\n",
    "print('model save at: {}'.format(saved_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model model_for_deploy\n"
     ]
    }
   ],
   "source": [
    "# register model for deployment\n",
    "model_name = os.listdir(saved_path)[0]\n",
    "model_path = os.path.join(saved_path, model_name)\n",
    "model = Model.register(workspace, model_path=model_path, model_name='model_for_deploy', tags={'deploy':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# register env if not registered before\n",
    "name='env_for_deployment'\n",
    "file_path='deployment/env_for_deployment.yaml'\n",
    "env = Environment.from_conda_specification(name=name, file_path=file_path)\n",
    "env = env.register(workspace=workspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define inference configuration\n",
    "entry_script='scoring_for_deployment.py'\n",
    "version='1'\n",
    "source_directory='deployment'\n",
    "env = Environment.get(workspace=workspace, name=name, version=version)\n",
    "inference_config = InferenceConfig(entry_script=entry_script, source_directory=source_directory,\n",
    "                                       environment=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model model_for_deploy:8 to /tmp/azureml_qsj1n71q/model_for_deploy/8\n",
      "Generating Docker build context.\n",
      "Package creation Succeeded\n",
      "Logging into Docker registry fundamental33c005c1f.azurecr.io\n",
      "Logging into Docker registry fundamental33c005c1f.azurecr.io\n",
      "Building Docker image from Dockerfile...\n",
      "Step 1/5 : FROM fundamental33c005c1f.azurecr.io/azureml/azureml_55f6443a7f1f616df548a00877130395\n",
      " ---> ecd09a31e78d\n",
      "Step 2/5 : COPY azureml-app /var/azureml-app\n",
      " ---> 07267dc695a0\n",
      "Step 3/5 : RUN mkdir -p '/var/azureml-app' && echo eyJhY2NvdW50Q29udGV4dCI6eyJzdWJzY3JpcHRpb25JZCI6IjRmNDU1YmQwLWY5NWEtNGI3ZC04ZDA4LTA3ODYxMTUwOGUwYiIsInJlc291cmNlR3JvdXBOYW1lIjoiZnVuZGFtZW50YWwiLCJhY2NvdW50TmFtZSI6ImZ1bmRhbWVudGFsMyIsIndvcmtzcGFjZUlkIjoiYTdjMmFjYWEtYzhmMS00NDhiLWI4OTQtYzJlN2E3MWIzYTMyIn0sIm1vZGVscyI6e30sIm1vZGVsc0luZm8iOnt9fQ== | base64 --decode > /var/azureml-app/model_config_map.json\n",
      " ---> Running in 17bfa353618e\n",
      " ---> 48ca5b5f9f65\n",
      "Step 4/5 : RUN mv '/var/azureml-app/tmpnkpc7zl9.py' /var/azureml-app/main.py\n",
      " ---> Running in 3beed6280bdd\n",
      " ---> 9bbb238e3a44\n",
      "Step 5/5 : CMD [\"runsvdir\",\"/var/runit\"]\n",
      " ---> Running in 3c50a64002fd\n",
      " ---> eda813ff5214\n",
      "Successfully built eda813ff5214\n",
      "Successfully tagged local-deploy-test:latest\n",
      "Container has been successfully cleaned up.\n",
      "Image sha256:8499a4a2e899dd6edc179b4408c7e1f3785e6340088470b30bb2925b3629f6f3 successfully removed.\n",
      "Starting Docker container...\n",
      "Docker container running.\n",
      "Checking container health...\n",
      "Local webservice is running at http://localhost:8892\n",
      "running\n",
      "2020-08-03T07:47:57,613772025+00:00 - gunicorn/run \n",
      "2020-08-03T07:47:57,614755231+00:00 - iot-server/run \n",
      "2020-08-03T07:47:57,615346334+00:00 - nginx/run \n",
      "2020-08-03T07:47:57,614161427+00:00 - rsyslog/run \n",
      "/usr/sbin/nginx: /azureml-envs/azureml_a5322dee92f8252a51213eb553ff6f2b/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_a5322dee92f8252a51213eb553ff6f2b/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_a5322dee92f8252a51213eb553ff6f2b/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_a5322dee92f8252a51213eb553ff6f2b/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_a5322dee92f8252a51213eb553ff6f2b/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "2020-08-03T07:47:57,692447010+00:00 - iot-server/finish 1 0\n",
      "2020-08-03T07:47:57,693811719+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "Starting gunicorn 19.9.0\n",
      "Listening at: http://127.0.0.1:31311 (11)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 42\n",
      "Initialized PySpark session.\n",
      "Initializing logger\n",
      "Starting up app insights client\n",
      "Starting up request id generator\n",
      "Starting up app insight hooks\n",
      "Invoking user's init function\n",
      "Users's init has completed successfully\n",
      "Skipping middleware: dbg_model_info as it's not enabled.\n",
      "Scoring timeout setting is not found. Use default timeout: 3600000 ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# deploy locally\n",
    "service_name='local-deploy-test'\n",
    "models=[model]\n",
    "port=8892\n",
    "service_locally = deploy_locally(workspace, service_name, models, inference_config, port=port)\n",
    "print(service_locally.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found existing service named aci-deploy-test7, delete it right now...\n",
      "Running....................................\n",
      "Succeeded\n",
      "ACI service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n"
     ]
    }
   ],
   "source": [
    "# deploy to ACI (Azure Container Instances)\n",
    "# every time we deploy to ACI, we need to change the service_name or we delete the existing service beforehand\n",
    "service_name='aci-deploy-test7'\n",
    "models=[model]\n",
    "service_aci=deploy_to_ACI(workspace, service_name, models, inference_config, cpu_cores=1, memory_gb=1, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: DesignerDRI_EASTUS\n",
      "resource_group DesignerDRI\n",
      "location eastus\n",
      "subscription_id 74eccef0-4b8d-4f83-b5f9-fa100d155b22\n",
      "compute_targets dict_keys(['attachedcompute', 'myaks1', 'default', 'compute', 'cpu-cluster', 'aml-compute'])\n",
      "Registering model model_for_deploy\n"
     ]
    }
   ],
   "source": [
    "# deploy to AKS (Azure Kubernetes Service)\n",
    "# workspace with AKS\n",
    "subscription_id = '74eccef0-4b8d-4f83-b5f9-fa100d155b22'\n",
    "resource_group = 'DesignerDRI'\n",
    "workspace_name = 'DesignerDRI_EASTUS'\n",
    "# set this if you have multiple tenant\n",
    "tenant_id=\"72f988bf-86f1-41af-91ab-2d7cd011db47\"\n",
    "\n",
    "workspace_aks=choose_workspace(subscription_id, resource_group, workspace_name, tenant_id)\n",
    "\n",
    "# register model in this workspace\n",
    "model = Model.register(workspace_aks, model_path=model_path, model_name='model_for_deploy', tags={'deploy':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found existing service named aks-deploy-test7, delete it right now...\n",
      "auth type: token\n",
      "Running............................................................\n",
      "Failed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Service deployment polling reached non-successful terminal state, current service state: Failed\n",
      "Operation ID: 79909e99-c1db-4574-95bc-edb3d83ce7d8\n",
      "More information can be found using '.get_logs()'\n",
      "Error:\n",
      "{\n",
      "  \"code\": \"KubernetesError\",\n",
      "  \"statusCode\": 400,\n",
      "  \"message\": \"Kubernetes Deployment Error\",\n",
      "  \"details\": [\n",
      "    {\n",
      "      \"code\": \"Unschedulable\",\n",
      "      \"message\": \"0/3 nodes are available: 3 Insufficient cpu.\"\n",
      "    },\n",
      "    {\n",
      "      \"code\": \"DeploymentFailed\",\n",
      "      \"message\": \"Couldn't schedule because the kubernetes cluster didn't have available resources after trying for 00:05:00.\\nYou can address this error by either adding more nodes, changing the SKU of your nodes or changing the resource requirements of your service.\\nPlease refer to https://aka.ms/debugimage#container-cannot-be-scheduled for more information.\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "Service deployment polling reached non-successful terminal state, current service state: Failed\n",
      "Operation ID: 79909e99-c1db-4574-95bc-edb3d83ce7d8\n",
      "More information can be found using '.get_logs()'\n",
      "Error:\n",
      "{\n",
      "  \"code\": \"KubernetesError\",\n",
      "  \"statusCode\": 400,\n",
      "  \"message\": \"Kubernetes Deployment Error\",\n",
      "  \"details\": [\n",
      "    {\n",
      "      \"code\": \"Unschedulable\",\n",
      "      \"message\": \"0/3 nodes are available: 3 Insufficient cpu.\"\n",
      "    },\n",
      "    {\n",
      "      \"code\": \"DeploymentFailed\",\n",
      "      \"message\": \"Couldn't schedule because the kubernetes cluster didn't have available resources after trying for 00:05:00.\\nYou can address this error by either adding more nodes, changing the SKU of your nodes or changing the resource requirements of your service.\\nPlease refer to https://aka.ms/debugimage#container-cannot-be-scheduled for more information.\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n"
     ]
    },
    {
     "ename": "WebserviceException",
     "evalue": "WebserviceException:\n\tMessage: Service deployment polling reached non-successful terminal state, current service state: Failed\nOperation ID: 79909e99-c1db-4574-95bc-edb3d83ce7d8\nMore information can be found using '.get_logs()'\nError:\n{\n  \"code\": \"KubernetesError\",\n  \"statusCode\": 400,\n  \"message\": \"Kubernetes Deployment Error\",\n  \"details\": [\n    {\n      \"code\": \"Unschedulable\",\n      \"message\": \"0/3 nodes are available: 3 Insufficient cpu.\"\n    },\n    {\n      \"code\": \"DeploymentFailed\",\n      \"message\": \"Couldn't schedule because the kubernetes cluster didn't have available resources after trying for 00:05:00.\\nYou can address this error by either adding more nodes, changing the SKU of your nodes or changing the resource requirements of your service.\\nPlease refer to https://aka.ms/debugimage#container-cannot-be-scheduled for more information.\"\n    }\n  ]\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Service deployment polling reached non-successful terminal state, current service state: Failed\\nOperation ID: 79909e99-c1db-4574-95bc-edb3d83ce7d8\\nMore information can be found using '.get_logs()'\\nError:\\n{\\n  \\\"code\\\": \\\"KubernetesError\\\",\\n  \\\"statusCode\\\": 400,\\n  \\\"message\\\": \\\"Kubernetes Deployment Error\\\",\\n  \\\"details\\\": [\\n    {\\n      \\\"code\\\": \\\"Unschedulable\\\",\\n      \\\"message\\\": \\\"0/3 nodes are available: 3 Insufficient cpu.\\\"\\n    },\\n    {\\n      \\\"code\\\": \\\"DeploymentFailed\\\",\\n      \\\"message\\\": \\\"Couldn't schedule because the kubernetes cluster didn't have available resources after trying for 00:05:00.\\\\nYou can address this error by either adding more nodes, changing the SKU of your nodes or changing the resource requirements of your service.\\\\nPlease refer to https://aka.ms/debugimage#container-cannot-be-scheduled for more information.\\\"\\n    }\\n  ]\\n}\"\n    }\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWebserviceException\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/anaconda/envs/tmp2/lib/python3.6/site-packages/azureml/core/webservice/webservice.py\u001b[0m in \u001b[0;36mwait_for_deployment\u001b[0;34m(self, show_output)\u001b[0m\n\u001b[1;32m    673\u001b[0m                                           '{}'.format(self.state, self._operation_endpoint.split('/')[-1],\n\u001b[0;32m--> 674\u001b[0;31m                                                       logs_response, error_response), logger=module_logger)\n\u001b[0m\u001b[1;32m    675\u001b[0m             print('{} service creation operation finished, operation \"{}\"'.format(self._webservice_type,\n",
      "\u001b[0;31mWebserviceException\u001b[0m: WebserviceException:\n\tMessage: Service deployment polling reached non-successful terminal state, current service state: Failed\nOperation ID: 79909e99-c1db-4574-95bc-edb3d83ce7d8\nMore information can be found using '.get_logs()'\nError:\n{\n  \"code\": \"KubernetesError\",\n  \"statusCode\": 400,\n  \"message\": \"Kubernetes Deployment Error\",\n  \"details\": [\n    {\n      \"code\": \"Unschedulable\",\n      \"message\": \"0/3 nodes are available: 3 Insufficient cpu.\"\n    },\n    {\n      \"code\": \"DeploymentFailed\",\n      \"message\": \"Couldn't schedule because the kubernetes cluster didn't have available resources after trying for 00:05:00.\\nYou can address this error by either adding more nodes, changing the SKU of your nodes or changing the resource requirements of your service.\\nPlease refer to https://aka.ms/debugimage#container-cannot-be-scheduled for more information.\"\n    }\n  ]\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Service deployment polling reached non-successful terminal state, current service state: Failed\\nOperation ID: 79909e99-c1db-4574-95bc-edb3d83ce7d8\\nMore information can be found using '.get_logs()'\\nError:\\n{\\n  \\\"code\\\": \\\"KubernetesError\\\",\\n  \\\"statusCode\\\": 400,\\n  \\\"message\\\": \\\"Kubernetes Deployment Error\\\",\\n  \\\"details\\\": [\\n    {\\n      \\\"code\\\": \\\"Unschedulable\\\",\\n      \\\"message\\\": \\\"0/3 nodes are available: 3 Insufficient cpu.\\\"\\n    },\\n    {\\n      \\\"code\\\": \\\"DeploymentFailed\\\",\\n      \\\"message\\\": \\\"Couldn't schedule because the kubernetes cluster didn't have available resources after trying for 00:05:00.\\\\nYou can address this error by either adding more nodes, changing the SKU of your nodes or changing the resource requirements of your service.\\\\nPlease refer to https://aka.ms/debugimage#container-cannot-be-scheduled for more information.\\\"\\n    }\\n  ]\\n}\"\n    }\n}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mWebserviceException\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-5e3e8e7dac36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtoken_auth_enabled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m service_aks=deploy_to_AKS(workspace_aks, attachment_name, service_name, models, inference_config, token_auth_enabled=token_auth_enabled,\n\u001b[0;32m----> 8\u001b[0;31m                   cpu_cores=1, memory_gb=1)\n\u001b[0m",
      "\u001b[0;32m/mnt/batch/tasks/shared/LS_root/mounts/clusters/my-compute/code/users/t-yangx/demo/azureml-designer-demo/fasttext_pipeline_utils.py\u001b[0m in \u001b[0;36mdeploy_to_AKS\u001b[0;34m(workspace, attachment_name, service_name, models, inference_config, token_auth_enabled, cpu_cores, memory_gb, overwrite)\u001b[0m\n\u001b[1;32m    194\u001b[0m                                                            auth_enabled=auth_enabled)\n\u001b[1;32m    195\u001b[0m     \u001b[0mservice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeploy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mservice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minference_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeployment_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maks_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m     \u001b[0mservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_deployment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshow_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mservice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/tmp2/lib/python3.6/site-packages/azureml/core/webservice/webservice.py\u001b[0m in \u001b[0;36mwait_for_deployment\u001b[0;34m(self, show_output)\u001b[0m\n\u001b[1;32m    681\u001b[0m                                           'Current state is {}'.format(self.state), logger=module_logger)\n\u001b[1;32m    682\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 683\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mWebserviceException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodule_logger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_wait_for_operation_to_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mWebserviceException\u001b[0m: WebserviceException:\n\tMessage: Service deployment polling reached non-successful terminal state, current service state: Failed\nOperation ID: 79909e99-c1db-4574-95bc-edb3d83ce7d8\nMore information can be found using '.get_logs()'\nError:\n{\n  \"code\": \"KubernetesError\",\n  \"statusCode\": 400,\n  \"message\": \"Kubernetes Deployment Error\",\n  \"details\": [\n    {\n      \"code\": \"Unschedulable\",\n      \"message\": \"0/3 nodes are available: 3 Insufficient cpu.\"\n    },\n    {\n      \"code\": \"DeploymentFailed\",\n      \"message\": \"Couldn't schedule because the kubernetes cluster didn't have available resources after trying for 00:05:00.\\nYou can address this error by either adding more nodes, changing the SKU of your nodes or changing the resource requirements of your service.\\nPlease refer to https://aka.ms/debugimage#container-cannot-be-scheduled for more information.\"\n    }\n  ]\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Service deployment polling reached non-successful terminal state, current service state: Failed\\nOperation ID: 79909e99-c1db-4574-95bc-edb3d83ce7d8\\nMore information can be found using '.get_logs()'\\nError:\\n{\\n  \\\"code\\\": \\\"KubernetesError\\\",\\n  \\\"statusCode\\\": 400,\\n  \\\"message\\\": \\\"Kubernetes Deployment Error\\\",\\n  \\\"details\\\": [\\n    {\\n      \\\"code\\\": \\\"Unschedulable\\\",\\n      \\\"message\\\": \\\"0/3 nodes are available: 3 Insufficient cpu.\\\"\\n    },\\n    {\\n      \\\"code\\\": \\\"DeploymentFailed\\\",\\n      \\\"message\\\": \\\"Couldn't schedule because the kubernetes cluster didn't have available resources after trying for 00:05:00.\\\\nYou can address this error by either adding more nodes, changing the SKU of your nodes or changing the resource requirements of your service.\\\\nPlease refer to https://aka.ms/debugimage#container-cannot-be-scheduled for more information.\\\"\\n    }\\n  ]\\n}\"\n    }\n}"
     ]
    }
   ],
   "source": [
    "# deploy to AKS (Azure Kubernetes Service)\n",
    "attachment_name='myaks1'\n",
    "# every time we deploy to ACI, we need to change the service_name or we delete the existing service beforehand\n",
    "service_name='aks-deploy-test7'\n",
    "models=[model]\n",
    "token_auth_enabled=True\n",
    "service_aks=deploy_to_AKS(workspace_aks, attachment_name, service_name, models, inference_config, token_auth_enabled=token_auth_enabled,\n",
    "                  cpu_cores=1, memory_gb=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# consume service\n",
    "# consume deployment\n",
    "import requests\n",
    "import json\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "\n",
    "# Get a token to authenticate to the compute instance from remote\n",
    "interactive_auth = InteractiveLoginAuthentication()\n",
    "auth_header = interactive_auth.get_authentication_header()\n",
    "\n",
    "# Create and submit a request using the auth header\n",
    "headers = auth_header\n",
    "# Add content type header\n",
    "headers.update({'Content-Type':'application/json'})\n",
    "# print(headers)\n",
    "\n",
    "\n",
    "standard_sample_input = {'param':{'input_sentence': '受疫情影响, 今年很多学生不得不在家上课'}}\n",
    "standard_sample_input = json.dumps(standard_sample_input)\n",
    "\n",
    "service = service_locally\n",
    "# service = service_aci\n",
    "\n",
    "# service = service_aks\n",
    "# token, refresh_by = service.get_token()\n",
    "# headers['Authorization']=f'Bearer {token}'\n",
    "\n",
    "\n",
    "response = requests.post(service.scoring_uri, data=standard_sample_input, headers=headers)\n",
    "print(service.scoring_uri)\n",
    "print(response)\n",
    "# print(response.status_code)\n",
    "# print(response.elapsed)\n",
    "print(response.content)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tmp2",
   "language": "python",
   "name": "tmp2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
