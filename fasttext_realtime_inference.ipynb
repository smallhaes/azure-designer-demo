{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.  \n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Using a Trained Model for Realtime Inference\n",
    "\n",
    "If your system requires low-latency processing (to process a single document or small set of documents quickly), then the realtime inference is the right choice. In this notebook, we will demonstrate how to make a prediction of an input sentence with a trained [fastText](https://fasttext.cc/) model.\n",
    "\n",
    "The outline of this notebook is as follows:\n",
    "\n",
    "- Visualize the pipeline associated with the pipeline run.\n",
    "- Get a step run with information from the visualization.\n",
    "- Get the port with the trained model from the step run.\n",
    "- Download the model from the port and register it to the workspace.\n",
    "- Deploy the model to local/ACI/AKS.\n",
    "\n",
    "## Prerequisites\n",
    "If you are using an Azure Machine Learning Notebook VM, you are all set. Otherwise, make sure you go through the configuration Notebook located at https://github.com/Azure/MachineLearningNotebooks first. This sets you up with a working config file that has information on your workspace, subscription id, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from azureml.core import Model, Workspace\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "from azureml.core.compute import AksCompute, ComputeTarget\n",
    "from azureml.core.environment import Environment\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.webservice import LocalWebservice, AciWebservice, AksWebservice\n",
    "from azureml.pipeline.wrapper import PipelineRun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to workspace\n",
    "Create a workspace object from the existing workspace. Workspace.from_config() reads the file config.json and loads the details into an object named workspace.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DesignerDRI_EASTUS\n",
      "DesignerDRI\n",
      "eastus\n",
      "74eccef0-4b8d-4f83-b5f9-fa100d155b22\n",
      "dict_keys(['aks-dev', 'aks-dev2', 'attached-aks', 'default', 'compute', 'cpu-cluster', 'aml-compute'])\n"
     ]
    }
   ],
   "source": [
    "workspace = Workspace.from_config('config.json')\n",
    "print(workspace.name, workspace.resource_group, workspace.location, workspace.subscription_id,\n",
    "      workspace.compute_targets.keys(), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a list of experiment names from the workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sample10',\n",
       " 'sample5',\n",
       " 'sample5-realtime',\n",
       " 'simple10-batch',\n",
       " 'pythonscript',\n",
       " 'Data_dependency',\n",
       " 'clement',\n",
       " 'new_module',\n",
       " 'test_module2',\n",
       " 'test_m',\n",
       " 'module_SDK_local_module_test',\n",
       " 'fasttext_pipeline']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_name_list = [exp.name for exp in Experiment.list(workspace)]\n",
    "exp_name_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose the experiment you want with its name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Name</th><th>Workspace</th><th>Report Page</th><th>Docs Page</th></tr><tr><td>fasttext_pipeline</td><td>DesignerDRI_EASTUS</td><td><a href=\"https://ml.azure.com/experiments/fasttext_pipeline?wsid=/subscriptions/74eccef0-4b8d-4f83-b5f9-fa100d155b22/resourcegroups/DesignerDRI/workspaces/DesignerDRI_EASTUS\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.experiment.Experiment?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Experiment(Name: fasttext_pipeline,\n",
       "Workspace: DesignerDRI_EASTUS)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_name = \"fasttext_pipeline\"\n",
    "experiment = Experiment(workspace, experiment_name)\n",
    "experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose the latest run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>fasttext_pipeline</td><td>2353d38d-c191-4045-b0a7-e943c4437ffa</td><td>azureml.PipelineRun</td><td>Completed</td><td><a href=\"https://ml.azure.com/experiments/fasttext_pipeline/runs/2353d38d-c191-4045-b0a7-e943c4437ffa?wsid=/subscriptions/74eccef0-4b8d-4f83-b5f9-fa100d155b22/resourcegroups/DesignerDRI/workspaces/DesignerDRI_EASTUS\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: fasttext_pipeline,\n",
       "Id: 2353d38d-c191-4045-b0a7-e943c4437ffa,\n",
       "Type: azureml.PipelineRun,\n",
       "Status: Completed)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# azureml.pipeline.core.run.PipelineRun\n",
    "run = experiment.get_runs().__next__()\n",
    "run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a PipelineRun object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>fasttext_pipeline</td><td>2353d38d-c191-4045-b0a7-e943c4437ffa</td><td>azureml.PipelineRun</td><td>Completed</td><td><a href=\"https://ml.azure.com/experiments/fasttext_pipeline/runs/2353d38d-c191-4045-b0a7-e943c4437ffa?wsid=/subscriptions/74eccef0-4b8d-4f83-b5f9-fa100d155b22/resourcegroups/DesignerDRI/workspaces/DesignerDRI_EASTUS\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: fasttext_pipeline,\n",
       "Id: 2353d38d-c191-4045-b0a7-e943c4437ffa,\n",
       "Type: azureml.PipelineRun,\n",
       "Status: Completed)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_id = run.id\n",
    "# azureml.pipeline.wrapper.PipelineRun\n",
    "pipeline_run = PipelineRun(experiment, run_id)\n",
    "pipeline_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do\n",
    "# pipeline_run.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a StepRun object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>fasttext_pipeline</td><td>28956fb7-79a2-496e-a09a-64cdacb1771e</td><td>azureml.StepRun</td><td>Completed</td><td><a href=\"https://ml.azure.com/experiments/fasttext_pipeline/runs/28956fb7-79a2-496e-a09a-64cdacb1771e?wsid=/subscriptions/74eccef0-4b8d-4f83-b5f9-fa100d155b22/resourcegroups/DesignerDRI/workspaces/DesignerDRI_EASTUS\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "StepRun(Experiment: fasttext_pipeline,\n",
       "Id: 28956fb7-79a2-496e-a09a-64cdacb1771e,\n",
       "Type: azureml.StepRun,\n",
       "Status: Completed)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step_run_id will be from the visualization result.\n",
    "step_run_id = '28956fb7-79a2-496e-a09a-64cdacb1771e'\n",
    "step_run = pipeline_run.get_step_run(step_run_id)\n",
    "step_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the trained model from the port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading azureml/28956fb7-79a2-496e-a09a-64cdacb1771e/The_better_model/BestModel\n",
      "Downloading azureml/28956fb7-79a2-496e-a09a-64cdacb1771e/The_better_model/label.txt\n",
      "Downloading azureml/28956fb7-79a2-496e-a09a-64cdacb1771e/The_better_model/word_to_index.json\n",
      "Downloaded azureml/28956fb7-79a2-496e-a09a-64cdacb1771e/The_better_model/label.txt, 1 files out of an estimated total of 3\n",
      "Downloaded azureml/28956fb7-79a2-496e-a09a-64cdacb1771e/The_better_model/word_to_index.json, 2 files out of an estimated total of 3\n",
      "Downloaded azureml/28956fb7-79a2-496e-a09a-64cdacb1771e/The_better_model/BestModel, 3 files out of an estimated total of 3\n",
      "model save at: /tmp/azureml/28956fb7-79a2-496e-a09a-64cdacb1771e/The_better_model\n"
     ]
    }
   ],
   "source": [
    "# name will be from the visualization result.\n",
    "# get_port() should supports three kinds of names: (1)the_better_model (2)The better model (3)The_better_model\n",
    "port = step_run.get_port(name='The_better_model')\n",
    "saved_path = port.download(overwrite=True)\n",
    "print('model save at: {}'.format(saved_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register the trained model for deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model model_for_deployment\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(workspace=Workspace.create(name='DesignerDRI_EASTUS', subscription_id='74eccef0-4b8d-4f83-b5f9-fa100d155b22', resource_group='DesignerDRI'), name=model_for_deployment, id=model_for_deployment:2, version=2, tags={}, properties={})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = saved_path\n",
    "model = Model.register(workspace, model_path=saved_path, model_name='model_for_deployment')\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get an Environment object for Inference Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "env_list = Environment.list(workspace)\n",
    "name = 'env_for_deployment'\n",
    "# if the workspace doesn't contain the specific environment, then we'll register a new one.\n",
    "if not name in env_list:\n",
    "    # env_for_deployment.yaml describes dependencies your service need.\n",
    "    file_path = 'deployment/env_for_deployment.yaml'\n",
    "    env = Environment.from_conda_specification(name=name, file_path=file_path)\n",
    "    env = env.register(workspace=workspace)\n",
    "else:\n",
    "    env = Environment.get(workspace=workspace, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get an InferenceConfig object for deployment\n",
    "It represents configuration settings for a custom environment used for deployment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# entry_script defines the processing logic for the input\n",
    "entry_script = 'fasttext_realtime_inference.py'\n",
    "# source_directory is the path to the folder that contains all files to create the service image\n",
    "source_directory = 'deployment'\n",
    "inference_config = InferenceConfig(entry_script=entry_script, source_directory=source_directory,\n",
    "                                   environment=env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy to local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "entry_script /mnt/batch/tasks/shared/LS_root/mounts/clusters/my-compute/code/Users/t-yangx/demo/azureml-designer-demo/deployment/scoring_for_deployment.py doesn't exist. entry_script should be path relative to  current working directory\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model model_for_deployment:2 to /tmp/azureml_9xf58fqr/model_for_deployment/2\n",
      "Generating Docker build context.\n",
      "Package creation Succeeded\n",
      "Logging into Docker registry designerdriea2302d01.azurecr.io\n",
      "Logging into Docker registry designerdriea2302d01.azurecr.io\n",
      "Building Docker image from Dockerfile...\n",
      "Step 1/5 : FROM designerdriea2302d01.azurecr.io/azureml/azureml_ac0df2cc6dbad51226a8d176555b98dc\n",
      " ---> b2300022e9a5\n",
      "Step 2/5 : COPY azureml-app /var/azureml-app\n",
      " ---> c60d299dc972\n",
      "Step 3/5 : RUN mkdir -p '/var/azureml-app' && echo eyJhY2NvdW50Q29udGV4dCI6eyJzdWJzY3JpcHRpb25JZCI6Ijc0ZWNjZWYwLTRiOGQtNGY4My1iNWY5LWZhMTAwZDE1NWIyMiIsInJlc291cmNlR3JvdXBOYW1lIjoiZGVzaWduZXJkcmkiLCJhY2NvdW50TmFtZSI6ImRlc2lnbmVyZHJpX2Vhc3R1cyIsIndvcmtzcGFjZUlkIjoiZjZjNzVkZmYtMmMzMS00NDg2LTg0Y2ItMWRlZDMzODhlMzM3In0sIm1vZGVscyI6e30sIm1vZGVsc0luZm8iOnt9fQ== | base64 --decode > /var/azureml-app/model_config_map.json\n",
      " ---> Running in e3c1c9ae3a10\n",
      " ---> cac7d6c75452\n",
      "Step 4/5 : RUN mv '/var/azureml-app/tmp80x_vcqu.py' /var/azureml-app/main.py\n",
      " ---> Running in 4c72d55eb709\n",
      " ---> 03717eede64d\n",
      "Step 5/5 : CMD [\"runsvdir\",\"/var/runit\"]\n",
      " ---> Running in 1c3cf69055f5\n",
      " ---> e5a72a0f8c65\n",
      "Successfully built e5a72a0f8c65\n",
      "Successfully tagged local-deploy-test:latest\n",
      "Container has been successfully cleaned up.\n",
      "Image sha256:16f753ef98c2f5539039c8be8f0754602b26a856ddd7f4150ee5c64225541f34 successfully removed.\n",
      "Starting Docker container...\n",
      "Docker container running.\n",
      "Checking container health...\n",
      "Local webservice is running at http://localhost:8892\n",
      "running\n",
      "2020-08-13T08:47:41,701680348+00:00 - rsyslog/run \n",
      "2020-08-13T08:47:41,702665054+00:00 - gunicorn/run \n",
      "2020-08-13T08:47:41,705343971+00:00 - nginx/run \n",
      "/usr/sbin/nginx: /azureml-envs/azureml_8b5696d46225932816e569ad3032e43e/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_8b5696d46225932816e569ad3032e43e/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_8b5696d46225932816e569ad3032e43e/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_8b5696d46225932816e569ad3032e43e/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_8b5696d46225932816e569ad3032e43e/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "2020-08-13T08:47:41,709260195+00:00 - iot-server/run \n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "2020-08-13T08:47:41,788275492+00:00 - iot-server/finish 1 0\n",
      "2020-08-13T08:47:41,789596000+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "Starting gunicorn 19.9.0\n",
      "Listening at: http://127.0.0.1:31311 (12)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 42\n",
      "Initialized PySpark session.\n",
      "Initializing logger\n",
      "Starting up app insights client\n",
      "Starting up request id generator\n",
      "Starting up app insight hooks\n",
      "Invoking user's init function\n",
      "Users's init has completed successfully\n",
      "/azureml-envs/azureml_8b5696d46225932816e569ad3032e43e/lib/python3.6/site-packages/torch/serialization.py:593: SourceChangeWarning: source code of class 'common.FastText.FastText' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "Skipping middleware: dbg_model_info as it's not enabled.\n",
      "Scoring timeout setting is not found. Use default timeout: 3600000 ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "service_name = 'local-deploy-test'\n",
    "models = [model]\n",
    "port = 8892\n",
    "deployment_config = LocalWebservice.deploy_configuration(port=port)\n",
    "service_locally = Model.deploy(workspace=workspace, name=service_name, models=models, inference_config=inference_config,\n",
    "                               deployment_config=deployment_config)\n",
    "service_locally.wait_for_deployment(show_output=True)\n",
    "print(service_locally.state)\n",
    "print(service_locally.get_logs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy to ACI (Azure Container Instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running........\n",
      "Succeeded\n",
      "ACI service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n"
     ]
    }
   ],
   "source": [
    "service_name = 'aci-deploy-test'\n",
    "models = [model]\n",
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1)\n",
    "service_aci = Model.deploy(workspace, service_name, models=models, inference_config=inference_config,\n",
    "                           deployment_config=deployment_config, overwrite=True)\n",
    "service_aci.wait_for_deployment(show_output=True)\n",
    "print(service_aci.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy to AKS (Azure Kubernetes Service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AksCompute(workspace=Workspace.create(name='DesignerDRI_EASTUS', subscription_id='74eccef0-4b8d-4f83-b5f9-fa100d155b22', resource_group='DesignerDRI'), name=attached-aks, id=/subscriptions/74eccef0-4b8d-4f83-b5f9-fa100d155b22/resourceGroups/DesignerDRI/providers/Microsoft.MachineLearningServices/workspaces/DesignerDRI_EASTUS/computes/attached-aks, type=AKS, provisioning_state=Succeeded, location=eastus, tags=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# choose an inference cluster\n",
    "name = 'attached-aks'\n",
    "compute_target_name_list = [target.name for target in AksCompute.list(workspace)]\n",
    "if not name in compute_target_name_list:\n",
    "    aks_resource_group = 'AmlStudioV2DRI'\n",
    "    cluster_name = 'aks-dev-6node33512023a'\n",
    "    attach_config = AksCompute.attach_configuration(resource_group=aks_resource_group, cluster_name=cluster_name)\n",
    "    aks_target = ComputeTarget.attach(workspace, name, attach_config)\n",
    "    aks_target.wait_for_completion(show_output=True)\n",
    "aks_target = AksCompute(workspace, name)\n",
    "aks_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running.......\n",
      "Succeeded\n",
      "AKS service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n"
     ]
    }
   ],
   "source": [
    "# deploy to AKS (Azure Kubernetes Service)\n",
    "service_name = 'aks-deploy-test'\n",
    "models = [model]\n",
    "# Only one type of Auth may be enabled\n",
    "token_auth_enabled = True\n",
    "auth_enabled = False if token_auth_enabled else True\n",
    "\n",
    "deployment_config = AksWebservice.deploy_configuration(cpu_cores=1, memory_gb=1,\n",
    "                                                       token_auth_enabled=token_auth_enabled,\n",
    "                                                       auth_enabled=auth_enabled)\n",
    "service_aks = Model.deploy(workspace, service_name, models, inference_config, deployment_config, aks_target, overwrite=True)\n",
    "service_aks.wait_for_deployment(show_output=True)\n",
    "print(service_aks.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consume the service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consume\n",
    "import requests\n",
    "import json\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "\n",
    "# Get a token to authenticate to the compute instance from remote\n",
    "interactive_auth = InteractiveLoginAuthentication()\n",
    "auth_header = interactive_auth.get_authentication_header()\n",
    "\n",
    "# Create and submit a request using the auth header\n",
    "headers = auth_header\n",
    "# Add content type header\n",
    "headers.update({'Content-Type': 'application/json'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### consume the service deployed to local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8892/score\n",
      "<Response [200]>\n",
      "b'\"game\"'\n",
      "game\n"
     ]
    }
   ],
   "source": [
    "# your input\n",
    "standard_sample_input = {'param': {'input_sentence': '当前的预测还不准确'}}\n",
    "standard_sample_input = json.dumps(standard_sample_input)\n",
    "\n",
    "# consume the service deployed to local\n",
    "service = service_locally\n",
    "\n",
    "response = requests.post(service.scoring_uri, data=standard_sample_input, headers=headers)\n",
    "print(service.scoring_uri)\n",
    "print(response)\n",
    "print(response.content)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### consume the service deployed to ACI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://96c84315-acb4-4191-b4e8-ad3ccbd56315.eastus.azurecontainer.io/score\n",
      "<Response [200]>\n",
      "b'\"game\"'\n",
      "game\n"
     ]
    }
   ],
   "source": [
    "# your input\n",
    "standard_sample_input = {'param': {'input_sentence': '当前的预测还不准确'}}\n",
    "standard_sample_input = json.dumps(standard_sample_input)\n",
    "\n",
    "# consume the service deployed to ACI\n",
    "service = service_aci\n",
    "\n",
    "response = requests.post(service.scoring_uri, data=standard_sample_input, headers=headers)\n",
    "print(service.scoring_uri)\n",
    "print(response)\n",
    "print(response.content)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### consume the service deployed to AKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://52.170.37.14:80/api/v1/service/aks-deploy-test/score\n",
      "<Response [200]>\n",
      "b'\"game\"'\n",
      "game\n"
     ]
    }
   ],
   "source": [
    "# your input\n",
    "standard_sample_input = {'param': {'input_sentence': '当前的预测还不准确'}}\n",
    "standard_sample_input = json.dumps(standard_sample_input)\n",
    "\n",
    "# consume the service deployed to AKS\n",
    "service = service_aks\n",
    "token, refresh_by = service.get_token()\n",
    "headers['Authorization']=f'Bearer {token}'\n",
    "\n",
    "\n",
    "response = requests.post(service.scoring_uri, data=standard_sample_input, headers=headers)\n",
    "print(service.scoring_uri)\n",
    "print(response)\n",
    "print(response.content)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
