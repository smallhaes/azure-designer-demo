{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "from azureml.core.compute import AmlCompute, ComputeTarget\n",
    "from azureml.pipeline.wrapper import Module, dsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Falling back to use azure cli login credentials.\n",
      "If you run your code in unattended mode, i.e., where you can't give a user input, then we recommend to use ServicePrincipalAuthentication or MsiAuthentication.\n",
      "Please refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fundamental3\n",
      "fundamental\n",
      "eastasia\n",
      "4f455bd0-f95a-4b7d-8d08-078611508e0b\n",
      "dict_keys(['myaks2', 'aml-compute', 'my-compute', 'compute-deploy'])\n"
     ]
    }
   ],
   "source": [
    "tenant_id = \"72f988bf-86f1-41af-91ab-2d7cd011db47\"\n",
    "InteractiveLoginAuthentication(tenant_id=tenant_id)\n",
    "workspace = Workspace.from_config('config.json')\n",
    "print(workspace.name, workspace.resource_group, workspace.location, workspace.subscription_id,\n",
    "      workspace.compute_targets.keys(), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing compute target: aml-compute\n"
     ]
    }
   ],
   "source": [
    "aml_compute_name = 'aml-compute'\n",
    "try:\n",
    "    aml_compute = AmlCompute(workspace, aml_compute_name)\n",
    "    print(\"Found existing compute target: {}\".format(aml_compute_name))\n",
    "except:\n",
    "    print(\"Creating new compute target: {}\".format(aml_compute_name))\n",
    "\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size=\"STANDARD_D2_V2\", min_nodes=1, max_nodes=4)\n",
    "    aml_compute = ComputeTarget.create(workspace, aml_compute_name, provisioning_config)\n",
    "    aml_compute.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "dataset_name = \"THUCNews\"\n",
    "dataset = workspace.datasets[dataset_name]\n",
    "\n",
    "dataset_name = \"THUCNews_For_Batch_Inference\"\n",
    "dataset_score  = workspace.datasets[dataset_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load module\n",
    "split_data_txt_module_func = Module.from_yaml(workspace, 'split_data_txt/split_data_txt.spec.yaml')\n",
    "fasttext_train_module_func = Module.from_yaml(workspace, 'fasttext_train/fasttext_train.spec.yaml')\n",
    "fasttext_evaluation_module_func = Module.from_yaml(workspace, 'fasttext_evaluation/fasttext_evaluation.spec.yaml')\n",
    "fasttext_score_module_func = Module.from_yaml(workspace, 'fasttext_score/fasttext_score.spec.yaml')\n",
    "compare_two_models_module_func = Module.from_yaml(workspace, 'compare_two_models/compare_two_models.spec.yaml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "@dsl.pipeline(name='training_pipeline', description='A sub pipeline including data processing/train/evaluation',\n",
    "              default_compute_target=aml_compute_name)\n",
    "def training_pipeline(epochs):\n",
    "    split_data_txt = split_data_txt_module_func(\n",
    "        input_dir=dataset,\n",
    "        training_data_ratio=0.1,\n",
    "        validation_data_ratio=0.2\n",
    "    )\n",
    "    fasttext_train = fasttext_train_module_func(\n",
    "        training_data_dir=split_data_txt.outputs.training_data_output,\n",
    "        validation_data_dir=split_data_txt.outputs.validation_data_output,\n",
    "        epochs=epochs\n",
    "    )\n",
    "\n",
    "    fasttext_evaluation = fasttext_evaluation_module_func(\n",
    "        trained_model_dir=fasttext_train.outputs.trained_model_dir,\n",
    "        test_data_dir=split_data_txt.outputs.test_data_output\n",
    "    )\n",
    "\n",
    "    return {**fasttext_evaluation.outputs, **fasttext_train.outputs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "@dsl.pipeline(name='dummy_automl_pipeline',\n",
    "              description='A dummy pipeline that trains two models and output the better one',\n",
    "              default_compute_target=aml_compute_name)\n",
    "def dummy_automl_pipeline():\n",
    "    train_and_evalute_model1 = training_pipeline(epochs=5)\n",
    "    train_and_evalute_model2 = training_pipeline(epochs=10)\n",
    "    compare = compare_two_models_module_func(\n",
    "        first_trained_model=train_and_evalute_model1.outputs.trained_model_dir,\n",
    "        first_trained_result=train_and_evalute_model1.outputs.model_testing_result,\n",
    "        second_trained_model=train_and_evalute_model2.outputs.trained_model_dir,\n",
    "        second_trained_result=train_and_evalute_model2.outputs.model_testing_result\n",
    "    )\n",
    "\n",
    "    # fasttext_score = fasttext_score_module_func(\n",
    "    #     texts_to_score=dataset_score,\n",
    "    #     fasttext_model_dir=compare.outputs.the_better_model\n",
    "    # )\n",
    "    # fasttext_score.runsettings.configure(node_count=2, process_count_per_node=2, mini_batch_size=\"64\")\n",
    "    return {**compare.outputs}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline\n",
    "pipeline = dummy_automl_pipeline()\n",
    "# pipeline.save(experiment_name=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate\n",
    "# pipeline.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false,
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted PipelineRun 0f59b0d6-b343-4639-8d75-da4b91230007\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/fasttext_training_process/runs/0f59b0d6-b343-4639-8d75-da4b91230007?wsid=/subscriptions/4f455bd0-f95a-4b7d-8d08-078611508e0b/resourcegroups/fundamental/workspaces/fundamental3\n"
     ]
    }
   ],
   "source": [
    "# pipeline_run\n",
    "experiment_name = 'fasttext_training_process'\n",
    "pipeline_run = pipeline.submit(experiment_name=experiment_name, regenerate_outputs=False)\n",
    "# pipeline_run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tmp2",
   "language": "python",
   "name": "tmp2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}