{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "from azureml.core import Workspace, Dataset\n",
    "from azureml.core.compute import AmlCompute, ComputeTarget\n",
    "from azureml.pipeline.core.graph import DataType\n",
    "from azureml.pipeline.wrapper import Module, dsl, Pipeline\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "subscription_id = '4f455bd0-f95a-4b7d-8d08-078611508e0b'\n",
    "resource_group = 'fundamental'\n",
    "workspace_name = 'fundamental4'\n",
    "namespace=workspace_name # for loading module\n",
    "# set this if you have multiple tenant\n",
    "tenant_id=\"72f988bf-86f1-41af-91ab-2d7cd011db47\"\n",
    "interactive_auth = InteractiveLoginAuthentication(tenant_id=tenant_id)\n",
    "\n",
    "workspace = Workspace(subscription_id, resource_group, workspace_name)\n",
    "print(workspace.name, workspace.resource_group, workspace.location, workspace.subscription_id, workspace.compute_targets.keys(),sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# choose compute target\n",
    "print(workspace.compute_targets)\n",
    "aml_compute_name = 'aml-compute'\n",
    "try:\n",
    "    aml_compute = AmlCompute(workspace, aml_compute_name)\n",
    "    print(\"Found existing compute target: {}\".format(aml_compute_name))\n",
    "except:\n",
    "    print(\"Creating new compute target: {}\".format(aml_compute_name))\n",
    "\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size=\"STANDARD_D2_V2\",\n",
    "                                                                min_nodes=1,\n",
    "                                                                max_nodes=4)\n",
    "    aml_compute = ComputeTarget.create(workspace, aml_compute_name, provisioning_config)\n",
    "    aml_compute.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "# print(aml_compute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# register my own datatype\n",
    "DataType.create_data_type(workspace, 'MyDirectory', description='', is_directory=True) # won't register repeatedly\n",
    "DataType.create_data_type(workspace, 'MyFile', description='', is_directory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "dataset_name = 'THUCNews_TXT'\n",
    "char2index_name = 'Char2Index_JSON'\n",
    "\n",
    "if dataset_name not in workspace.datasets:\n",
    "    print('Registering a THUCNews dataset for fasttext pipeline ...')\n",
    "    path = ['https://datastore4fasttext.file.core.windows.net/data4fasttext/THUCNews.txt']\n",
    "    data = Dataset.File.from_files(path=path)\n",
    "    data.register(workspace=workspace, name=dataset_name, description='THUCNews dataset is generated by filtering and filtering historical data of Sina News RSS subscription channel from 2005 to 2011')\n",
    "    print('Registerd')\n",
    "data = workspace.datasets[dataset_name]\n",
    "\n",
    "if char2index_name not in workspace.datasets:\n",
    "    print('Registering a Char2Index_JSON for fasttext pipeline ...')\n",
    "    path = ['https://datastore4fasttext.file.core.windows.net/data4fasttext/character2index.json']\n",
    "    data = Dataset.File.from_files(path=path)\n",
    "    data.register(workspace=workspace, name=char2index_name, description='The mapping relationship between character and index ')\n",
    "    print('Registerd')\n",
    "char2index = workspace.datasets[char2index_name]\n",
    "\n",
    "print(data)\n",
    "print(char2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load module\n",
    "try:\n",
    "    split_data_txt_module_func = Module.load(workspace=workspace, namespace=namespace, name='Split Data Txt')\n",
    "    print('found split_data_txt_module')\n",
    "except:\n",
    "    print('not found split_data_txt_module, register it now...')\n",
    "    yaml_file='split_data_txt/split_data_txt.spec.yaml'\n",
    "    split_data_txt_module_func = Module.register(workspace=workspace, yaml_file=yaml_file)\n",
    "\n",
    "try:\n",
    "    split_data_txt_parallel_module_func = Module.load(workspace=workspace, namespace=namespace, name='Split Data Txt Parallel')\n",
    "    print('found split_data_txt_parallel_module')\n",
    "except:\n",
    "    print('not found split_data_txt_parallel_module, register it now...')\n",
    "    yaml_file='split_data_txt_parallel/split_data_txt_parallel.spec.yaml'\n",
    "    split_data_txt_parallel_module_func = Module.register(workspace=workspace, yaml_file=yaml_file)\n",
    "\n",
    "try:\n",
    "    fasttext_train_module_func = Module.load(workspace=workspace, namespace=namespace, name='FastText Train')\n",
    "    print('found fasttext_train_module')\n",
    "except:\n",
    "    print('not found fasttext_train_module, register it now...')\n",
    "    yaml_file='fasttext_train/fasttext_train.spec.yaml'\n",
    "    fasttext_train_module_func = Module.register(workspace=workspace, yaml_file=yaml_file)\n",
    "\n",
    "try:\n",
    "    fasttext_evaluation_module_func = Module.load(workspace=workspace, namespace=namespace, name='FastText Evaluation')\n",
    "    print('found fasttext_evaluation_module')\n",
    "except:\n",
    "    print('not found fasttext_evaluation_module, register it now...')\n",
    "    yaml_file='fasttext_evaluation/fasttext_evaluation.spec.yaml'\n",
    "    fasttext_evaluation_module_func = Module.register(workspace=workspace, yaml_file=yaml_file)\n",
    "\n",
    "try:\n",
    "    fasttext_score_module_func = Module.load(workspace=workspace, namespace=namespace, name='FastText Score')\n",
    "    print('found fasttext_score_module')\n",
    "except:\n",
    "    print('not found fasttext_score_module, register it now...')\n",
    "    yaml_file='fasttext_score/fasttext_score.spec.yaml'\n",
    "    fasttext_score_module_func = Module.register(workspace=workspace, yaml_file=yaml_file)\n",
    "\n",
    "try:\n",
    "    fasttext_score_parallel_module_func = Module.load(workspace=workspace, namespace=namespace, name='FastText Score Parallel')\n",
    "    print('found fasttext_score_parallel_module')\n",
    "except:\n",
    "    print('not found fasttext_score_parallel_module, register it now...')\n",
    "    yaml_file='fasttext_score_parallel/fasttext_score_parallel.spec.yaml'\n",
    "    fasttext_score_parallel_module_func = Module.register(workspace=workspace, yaml_file=yaml_file)\n",
    "\n",
    "try:\n",
    "    compare_two_models_module_func = Module.load(workspace=workspace, namespace=namespace, name='Compare Two Models')\n",
    "    print('found compare_two_models_module')\n",
    "except:\n",
    "    print('not found compare_two_models_module, register it now...')\n",
    "    yaml_file='compare_two_models/compare_two_models.spec.yaml'\n",
    "    compare_two_models_module_func = Module.register(workspace=workspace, yaml_file=yaml_file)\n",
    "\n",
    "\n",
    "\n",
    "# inspect signature\n",
    "# print(inspect.signature(split_data_txt_module_func))\n",
    "# print(inspect.signature(split_data_txt_parallel_module_func))\n",
    "# print(inspect.signature(fasttext_train_module_func))\n",
    "# print(inspect.signature(fasttext_evaluation_module_func))\n",
    "# print(inspect.signature(fasttext_score_module_func))\n",
    "# print(inspect.signature(fasttext_score_parallel_module_func))\n",
    "# print(inspect.signature(compare2model_module_func))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# connect module\n",
    "@dsl.pipeline(name='test deploy', description='Test parallel', default_compute_target=aml_compute_name)\n",
    "def training_pipeline(epochs):\n",
    "    split_data_txt_parallel = split_data_txt_parallel_module_func(\n",
    "    input_dir = data,\n",
    "    training_data_ratio = 0.7,\n",
    "    validation_data_ratio = 0.1,\n",
    "    random_split = True,\n",
    "    seed = 9\n",
    "    )\n",
    "\n",
    "    fasttext_train = fasttext_train_module_func(\n",
    "    training_data_dir = split_data_txt_parallel.outputs.training_data_output,\n",
    "    validation_data_dir = split_data_txt_parallel.outputs.validation_data_output,\n",
    "    char2index_dir = char2index,\n",
    "    epochs = epochs,\n",
    "    batch_size = 64,\n",
    "    learning_rate = 0.0005,\n",
    "    embedding_dim = 128\n",
    "    )\n",
    "    \n",
    "    fasttext_score_parallel = fasttext_score_parallel_module_func(\n",
    "    texts_to_score = split_data_txt_parallel.outputs.test_data_output,\n",
    "    fasttext_model = fasttext_train.outputs.trained_model_dir,\n",
    "    char2index_dir = char2index\n",
    "    )\n",
    "    fasttext_score_parallel.runsettings.configure(node_count=4, process_count_per_node=8, mini_batch_size=128)\n",
    "\n",
    "    return {**fasttext_score_parallel.outputs, **fasttext_train.outputs}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_data_txt_parallel = split_data_txt_parallel_module_func(\n",
    "    input_dir = data,\n",
    "    training_data_ratio = 0.7,\n",
    "    validation_data_ratio = 0.1,\n",
    "    random_split = True,\n",
    "    seed = 8\n",
    "    )\n",
    "\n",
    "fasttext_train = fasttext_train_module_func(\n",
    "    training_data_dir = split_data_txt_parallel.outputs.training_data_output,\n",
    "    validation_data_dir = split_data_txt_parallel.outputs.validation_data_output,\n",
    "    char2index_dir = char2index,\n",
    "    epochs = 1,\n",
    "    batch_size = 64,\n",
    "    learning_rate = 0.0005,\n",
    "    embedding_dim = 128\n",
    "    )\n",
    "type(fasttext_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pipeline\n",
    "pipeline = training_pipeline(epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization\n",
    "pipeline.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline_draft = pipeline.save(\n",
    "#     experiment_name='my test',\n",
    "# )\n",
    "# pipeline_draft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run\n",
    "run = pipeline.submit(experiment_name='parallel', pipeline_parameters={'epochs':1})\n",
    "run.wait_for_completion()\n",
    "run\n",
    "#%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model = run.register_model(model_name='fasttext_model',\n",
    "#                            model_path='Trained_model_dir') #Trained_model_dir/BestModel\n",
    "# print(model.name, model.id, model.version, sep='\\t')\n",
    "\n",
    "pipeline.outputs.trained_model_dir.AVAILABLE_MODE\n",
    "\n",
    "\n",
    "\n",
    "type(run)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model = run.register_model(model_name='fasttext_model',\n",
    "#                            model_path='Trained_model_dir') #Trained_model_dir/BestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run.pipeline.outputs.trained_model_dir.configure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aaa=[]\n",
    "for cr in run.get_children():\n",
    "    aaa.append(cr)\n",
    "    print(cr,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run.child_run(name='FastText Train').register_model(model_name='BestModel', model_path='Trained_model_dir') #Trained_model_dir/BestModel\n",
    "run.get_file_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa[-2].get_file_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(aaa[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aaa[-2].register_model(model_name='BestModel', model_path='Trained_model_dir', tags={'my_tags': 'fasttext'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.get_children()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# register env for deployment to workspace\n",
    "# from azureml.core.environment import Environment\n",
    "# myenv = Environment.from_conda_specification(name = 'env_for_deployment',\n",
    "#                                              file_path = 'deployment/env_for_deployment.yaml')\n",
    "# myenv.register(workspace=workspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from azureml.core.model import Model\n",
    "# model = Model.get_model_path(model_name='fasttext', version=2)\n",
    "# Model.deploy(workspace=workspace, name='my_deployment', models=[model], inference_config=None, deployment_config=None, deployment_target=None, overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Define inference configuration\n",
    "# from azureml.core.environment import Environment\n",
    "# from azureml.core.model import InferenceConfig\n",
    "\n",
    "\n",
    "# myenv = Environment.get(workspace=workspace, name='env_for_deployment', version='2')\n",
    "# inference_config = InferenceConfig(entry_script='deployment/scoring_for_deployment.py',\n",
    "#                                    environment=myenv)\n",
    "# inference_config                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 创建k8s资源\n",
    "# from azureml.core.compute import AksCompute, ComputeTarget\n",
    "\n",
    "# # Use the default configuration (you can also provide parameters to customize this).\n",
    "# # For example, to create a dev/test cluster, use:\n",
    "# # prov_config = AksCompute.provisioning_configuration(cluster_purpose = AksCompute.ClusterPurpose.DEV_TEST)\n",
    "# prov_config = AksCompute.provisioning_configuration()\n",
    "# aks_name = 'myaks'\n",
    "# # Create the cluster\n",
    "# aks_target = ComputeTarget.create(workspace = workspace,\n",
    "#                                     name = aks_name,\n",
    "#                                     provisioning_configuration = prov_config)\n",
    "\n",
    "# # Wait for the create process to complete\n",
    "# aks_target.wait_for_completion(show_output = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Attach an existing AKS cluster\n",
    "# from azureml.core.compute import AksCompute, ComputeTarget\n",
    "# # Set the resource group that contains the AKS cluster and the cluster name\n",
    "# resource_group = 'myresourcegroup'\n",
    "# cluster_name = 'myexistingcluster'\n",
    "\n",
    "# # Attach the cluster to your workgroup. If the cluster has less than 12 virtual CPUs, use the following instead:\n",
    "# # attach_config = AksCompute.attach_configuration(resource_group = resource_group,\n",
    "# #                                         cluster_name = cluster_name,\n",
    "# #                                         cluster_purpose = AksCompute.ClusterPurpose.DEV_TEST)\n",
    "# attach_config = AksCompute.attach_configuration(resource_group = resource_group,\n",
    "#                                          cluster_name = cluster_name)\n",
    "# aks_target = ComputeTarget.attach(ws, 'myaks', attach_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################\n",
    "# register env for deployment to workspace\n",
    "from azureml.core.environment import Environment\n",
    "myenv = Environment.from_conda_specification(name = 'env_for_deployment',\n",
    "                                             file_path = 'deployment/env_for_deployment.yaml')\n",
    "myenv.register(workspace=workspace)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from azureml.core.model import Model\n",
    "# model = Model.get_model_path(model_name='BestModel', version=2)\n",
    "Model.list(workspace)\n",
    "# Model.deploy(workspace=workspace, name='my_deployment', models=[model], inference_config=None, deployment_config=None, deployment_target=None, overwrite=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model = Model.get_model_path(model_name='BestModel', version=2, _workspace=workspace)  # 会把模型下载到本地的azureml-models目录下\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Define inference configuration\n",
    "from azureml.core.environment import Environment\n",
    "from azureml.core.model import InferenceConfig\n",
    "\n",
    "\n",
    "myenv = Environment.get(workspace=workspace, name='env_for_deployment', version='2')\n",
    "inference_config = InferenceConfig(entry_script='deployment/scoring_for_deployment.py',\n",
    "                                   environment=myenv)\n",
    "inference_config      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = aaa[-2].register_model(model_name='BestModel', model_path='Trained_model_dir', tags={'my_tags': 'fasttext'})\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice, Webservice\n",
    "from azureml.core.model import Model\n",
    "\n",
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 1)\n",
    "service = Model.deploy(workspace=workspace, name=\"my-deployment\", models=[model], inference_config=inference_config, deployment_config=deployment_config)\n",
    "service.wait_for_deployment(show_output = True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice, Webservice\n",
    "from azureml.core.model import Model\n",
    "\n",
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 1)\n",
    "service = Model.deploy(workspace=workspace, name=\"my-deployment\", models=[model], inference_config=inference_config, deployment_config=deployment_config)\n",
    "service.wait_for_deployment(show_output = True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice, Webservice\n",
    "from azureml.core.model import Model\n",
    "\n",
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores = 2, memory_gb = 2)\n",
    "service = Model.deploy(workspace=workspace, name=\"my-deployment2\", models=[model], inference_config=inference_config, deployment_config=deployment_config)\n",
    "service.wait_for_deployment(show_output = True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice, Webservice\n",
    "from azureml.core.model import Model\n",
    "\n",
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores = 2, memory_gb = 2)\n",
    "service = Model.deploy(workspace=workspace, name=\"my-deployment3\", models=[model], inference_config=inference_config, deployment_config=deployment_config)\n",
    "service.wait_for_deployment(show_output = True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "headers = {'Content-Type': 'application/json'}\n",
    "\n",
    "if service.auth_enabled:\n",
    "    headers['Authorization'] = 'Bearer '+service.get_keys()[0]\n",
    "elif service.token_auth_enabled:\n",
    "    headers['Authorization'] = 'Bearer '+service.get_token()[0]\n",
    "\n",
    "print(headers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service.auth_enabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# test_sample = json.dumps({'data': [\n",
    "#     [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "#     [10, 9, 8, 7, 6, 5, 4, 3, 2, 1]\n",
    "# ]})\n",
    "\n",
    "standard_sample_input = {'input sentence': 'i want to travel around the world'}\n",
    "\n",
    "response = requests.post(\n",
    "    service.scoring_uri, data=standard_sample_input, headers=headers)\n",
    "print(response.status_code)\n",
    "print(response.elapsed)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "\n",
    "environment = Environment('my-sklearn-environment')\n",
    "environment.python.conda_dependencies = CondaDependencies.create(pip_packages=[\n",
    "    'azureml-defaults',\n",
    "    'inference-schema[numpy-support]',\n",
    "    'joblib',\n",
    "    'numpy',\n",
    "    'scikit-learn'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# register env for deployment to workspace\n",
    "from azureml.core.environment import Environment\n",
    "myenv = Environment.from_conda_specification(name = 'env_for_deployment',\n",
    "                                             file_path = 'deployment/env_for_deployment.yaml')\n",
    "myenv.register(workspace=workspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from azureml.core import Webservice\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.webservice import AciWebservice\n",
    "from azureml.exceptions import WebserviceException\n",
    "\n",
    "\n",
    "service_name = 'my-service-1'\n",
    "\n",
    "# Remove any existing service under the same name.\n",
    "try:\n",
    "    Webservice(workspace, service_name).delete()\n",
    "except WebserviceException:\n",
    "    pass\n",
    "\n",
    "inference_config = InferenceConfig(entry_script='deployment/scoring_for_deployment.py', environment=myenv)\n",
    "aci_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1)\n",
    "\n",
    "service = Model.deploy(workspace=workspace,\n",
    "                       name=service_name,\n",
    "                       models=[model],\n",
    "                       inference_config=inference_config,\n",
    "                       deployment_config=aci_config)\n",
    "service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python_defaultSpec_1594342843165",
   "language": "python",
   "display_name": "Python 3.6.8 64-bit ('tmp2': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}