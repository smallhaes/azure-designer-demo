{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.  \n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Using a Trained Model for Batch Inference\n",
    "\n",
    "In this notebook, we will demonstrate how to make predictions on large quantities of data asynchronously using the ML pipelines with Azure Machine Learning. Batch inference (or batch scoring) provides cost-effective inference, with unparalleled throughput for asynchronous applications. Batch prediction pipelines can scale to perform inference on terabytes of production data. Batch prediction is optimized for high throughput, fire-and-forget predictions for a large collection of data.\n",
    "\n",
    "> **Tip**\n",
    "The dataset we use is not that huge. We aim to make you know the workflow of batch inference. If your system requires low-latency processing (to process a single document or small set of documents quickly), please use realtime inference. Refer to fasttext_realtime_inference.ipynb for more details. \n",
    "\n",
    "The outline of this notebook is as follows:\n",
    "\n",
    "- Create a DataStore referencing documents stored in a blob container.\n",
    "- Reference a trained fastText model from a complete experiment.\n",
    "- Use the fastText model to do batch inference on the documents in the data blob container.\n",
    "\n",
    "## Prerequisites\n",
    "If you are using an Azure Machine Learning Notebook VM, you are all set. Otherwise, make sure you go through the configuration Notebook located at https://github.com/Azure/MachineLearningNotebooks first. This sets you up with a working config file that has information on your workspace, subscription id, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from azureml.core import Workspace, Dataset, Datastore, Run\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "from azureml.core.compute import AmlCompute, ComputeTarget\n",
    "from azureml.data.datapath import DataPath\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.pipeline.wrapper import PipelineRun, Module, dsl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to workspace\n",
    "Create a workspace object from the existing workspace. Workspace.from_config() reads the file config.json and loads the details into an object named workspace.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fundamental3\n",
      "fundamental\n",
      "eastasia\n",
      "4f455bd0-f95a-4b7d-8d08-078611508e0b\n",
      "dict_keys(['myaks2', 'aml-compute', 'my-compute'])\n"
     ]
    }
   ],
   "source": [
    "workspace = Workspace.from_config('config2.json')\n",
    "print(workspace.name, workspace.resource_group, workspace.location, workspace.subscription_id,\n",
    "      workspace.compute_targets.keys(), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create or Attach existing compute resource\n",
    "By using Azure Machine Learning Compute, a managed service, data scientists can train machine learning models on clusters of Azure virtual machines. Examples include VMs with GPU support. In this tutorial, you create Azure Machine Learning Compute as your training environment. The code below creates the compute clusters for you if they don't already exist in your workspace.\n",
    "\n",
    "**Creation of compute takes approximately 5 minutes. If the AmlCompute with that name is already in your workspace the code will skip the creation process.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing compute target: aml-compute\n"
     ]
    }
   ],
   "source": [
    "aml_compute_name = 'aml-compute'\n",
    "if aml_compute_name in workspace.compute_targets:\n",
    "    aml_compute = AmlCompute(workspace, aml_compute_name)\n",
    "    print(\"Found existing compute target: {}\".format(aml_compute_name))\n",
    "else:\n",
    "    print(\"Creating new compute target: {}\".format(aml_compute_name))\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size=\"STANDARD_D2_V2\", min_nodes=1, max_nodes=4)\n",
    "    aml_compute = ComputeTarget.create(workspace, aml_compute_name, provisioning_config)\n",
    "    aml_compute.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the dataset onto a blob container and register it to the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 100 files\n",
      "Uploading data/data_for_batch_inference/0\n",
      "Uploading data/data_for_batch_inference/1\n",
      "Uploading data/data_for_batch_inference/10\n",
      "Uploading data/data_for_batch_inference/11\n",
      "Uploading data/data_for_batch_inference/12\n",
      "Uploading data/data_for_batch_inference/13\n",
      "Uploading data/data_for_batch_inference/14\n",
      "Uploading data/data_for_batch_inference/15\n",
      "Uploading data/data_for_batch_inference/16\n",
      "Uploading data/data_for_batch_inference/17\n",
      "Uploading data/data_for_batch_inference/18\n",
      "Uploading data/data_for_batch_inference/19\n",
      "Uploading data/data_for_batch_inference/2\n",
      "Uploading data/data_for_batch_inference/20\n",
      "Uploading data/data_for_batch_inference/21\n",
      "Uploading data/data_for_batch_inference/22\n",
      "Uploading data/data_for_batch_inference/23\n",
      "Uploading data/data_for_batch_inference/24\n",
      "Uploading data/data_for_batch_inference/25\n",
      "Uploading data/data_for_batch_inference/26\n",
      "Uploading data/data_for_batch_inference/27\n",
      "Uploading data/data_for_batch_inference/28\n",
      "Uploading data/data_for_batch_inference/29\n",
      "Uploading data/data_for_batch_inference/3\n",
      "Uploading data/data_for_batch_inference/30\n",
      "Uploading data/data_for_batch_inference/31\n",
      "Uploading data/data_for_batch_inference/32\n",
      "Uploading data/data_for_batch_inference/33\n",
      "Uploading data/data_for_batch_inference/34\n",
      "Uploading data/data_for_batch_inference/35\n",
      "Uploading data/data_for_batch_inference/36\n",
      "Uploading data/data_for_batch_inference/37\n",
      "Uploaded data/data_for_batch_inference/0, 1 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/38\n",
      "Uploaded data/data_for_batch_inference/1, 2 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/39\n",
      "Uploaded data/data_for_batch_inference/10, 3 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/4\n",
      "Uploaded data/data_for_batch_inference/11, 4 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/40\n",
      "Uploaded data/data_for_batch_inference/12, 5 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/41\n",
      "Uploaded data/data_for_batch_inference/13, 6 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/42\n",
      "Uploaded data/data_for_batch_inference/14, 7 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/43\n",
      "Uploaded data/data_for_batch_inference/15, 8 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/44\n",
      "Uploaded data/data_for_batch_inference/16, 9 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/45\n",
      "Uploaded data/data_for_batch_inference/17, 10 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/46\n",
      "Uploaded data/data_for_batch_inference/18, 11 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/47\n",
      "Uploaded data/data_for_batch_inference/19, 12 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/48\n",
      "Uploaded data/data_for_batch_inference/2, 13 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/49\n",
      "Uploaded data/data_for_batch_inference/20, 14 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/5\n",
      "Uploaded data/data_for_batch_inference/21, 15 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/50\n",
      "Uploaded data/data_for_batch_inference/22, 16 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/51\n",
      "Uploaded data/data_for_batch_inference/23, 17 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/52\n",
      "Uploaded data/data_for_batch_inference/24, 18 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/53\n",
      "Uploaded data/data_for_batch_inference/25, 19 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/54\n",
      "Uploaded data/data_for_batch_inference/26, 20 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/55\n",
      "Uploaded data/data_for_batch_inference/27, 21 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/56\n",
      "Uploaded data/data_for_batch_inference/28, 22 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/57\n",
      "Uploaded data/data_for_batch_inference/29, 23 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/58\n",
      "Uploaded data/data_for_batch_inference/3, 24 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/59\n",
      "Uploaded data/data_for_batch_inference/30, 25 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/6\n",
      "Uploaded data/data_for_batch_inference/31, 26 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/60\n",
      "Uploaded data/data_for_batch_inference/32, 27 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/61\n",
      "Uploaded data/data_for_batch_inference/33, 28 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/62\n",
      "Uploaded data/data_for_batch_inference/34, 29 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/63\n",
      "Uploaded data/data_for_batch_inference/35, 30 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/64\n",
      "Uploaded data/data_for_batch_inference/36, 31 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/65\n",
      "Uploaded data/data_for_batch_inference/37, 32 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/66\n",
      "Uploaded data/data_for_batch_inference/38, 33 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/67\n",
      "Uploaded data/data_for_batch_inference/39, 34 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/68\n",
      "Uploaded data/data_for_batch_inference/4, 35 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/69\n",
      "Uploaded data/data_for_batch_inference/40, 36 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/7\n",
      "Uploaded data/data_for_batch_inference/41, 37 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/70\n",
      "Uploaded data/data_for_batch_inference/42, 38 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/71\n",
      "Uploaded data/data_for_batch_inference/43, 39 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/72\n",
      "Uploaded data/data_for_batch_inference/44, 40 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/73\n",
      "Uploaded data/data_for_batch_inference/45, 41 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/74\n",
      "Uploaded data/data_for_batch_inference/46, 42 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/75\n",
      "Uploaded data/data_for_batch_inference/47, 43 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/76\n",
      "Uploaded data/data_for_batch_inference/48, 44 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/77\n",
      "Uploaded data/data_for_batch_inference/49, 45 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/78\n",
      "Uploaded data/data_for_batch_inference/5, 46 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/79\n",
      "Uploaded data/data_for_batch_inference/50, 47 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/8\n",
      "Uploaded data/data_for_batch_inference/51, 48 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/80\n",
      "Uploaded data/data_for_batch_inference/52, 49 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/81\n",
      "Uploaded data/data_for_batch_inference/53, 50 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/82\n",
      "Uploaded data/data_for_batch_inference/54, 51 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/83\n",
      "Uploaded data/data_for_batch_inference/55, 52 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/84\n",
      "Uploaded data/data_for_batch_inference/56, 53 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/85\n",
      "Uploaded data/data_for_batch_inference/57, 54 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/86\n",
      "Uploaded data/data_for_batch_inference/58, 55 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/87\n",
      "Uploaded data/data_for_batch_inference/59, 56 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/88\n",
      "Uploaded data/data_for_batch_inference/6, 57 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/89\n",
      "Uploaded data/data_for_batch_inference/60, 58 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/9\n",
      "Uploaded data/data_for_batch_inference/61, 59 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/90\n",
      "Uploaded data/data_for_batch_inference/62, 60 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/91\n",
      "Uploaded data/data_for_batch_inference/63, 61 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/92\n",
      "Uploaded data/data_for_batch_inference/64, 62 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded data/data_for_batch_inference/65, 63 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/94\n",
      "Uploaded data/data_for_batch_inference/66, 64 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/95\n",
      "Uploaded data/data_for_batch_inference/67, 65 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/96\n",
      "Uploaded data/data_for_batch_inference/68, 66 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/97\n",
      "Uploaded data/data_for_batch_inference/69, 67 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/98\n",
      "Uploaded data/data_for_batch_inference/7, 68 files out of an estimated total of 100\n",
      "Uploading data/data_for_batch_inference/99\n",
      "Uploaded data/data_for_batch_inference/70, 69 files out of an estimated total of 100\n",
      "Uploaded data/data_for_batch_inference/71, 70 files out of an estimated total of 100\n",
      "Uploaded data/data_for_batch_inference/72, 71 files out of an estimated total of 100\n",
      "Uploaded data/data_for_batch_inference/73, 72 files out of an estimated total of 100\n",
      "Uploaded data/data_for_batch_inference/74, 73 files out of an estimated total of 100\n",
      "Uploaded data/data_for_batch_inference/75, 74 files out of an estimated total of 100\n",
      "Uploaded data/data_for_batch_inference/76, 75 files out of an estimated total of 100\n",
      "Uploaded data/data_for_batch_inference/77, 76 files out of an estimated total of 100\n",
      "Uploaded data/data_for_batch_inference/78, 77 files out of an estimated total of 100\n",
      "Uploaded data/data_for_batch_inference/79, 78 files out of an estimated total of 100\n",
      "Uploaded data/data_for_batch_inference/8, 79 files out of an estimated total of 100\n",
      "Uploaded data/data_for_batch_inference/80, 80 files out of an estimated total of 100\n",
      "Uploaded data/data_for_batch_inference/81, 81 files out of an estimated total of 100\n",
      "Uploaded data/data_for_batch_inference/82, 82 files out of an estimated total of 100\n",
      "Uploaded data/data_for_batch_inference/83, 83 files out of an estimated total of 100\n",
      "Uploaded data/data_for_batch_inference/84, 84 files out of an estimated total of 100\n",
      "Uploaded data/data_for_batch_inference/85, 85 files out of an estimated total of 100\n",
      "Uploaded data/data_for_batch_inference/86, 86 files out of an estimated total of 100\n",
      "Uploaded data/data_for_batch_inference/87, 87 files out of an estimated total of 100\n",
      "Uploaded data/data_for_batch_inference/88, 88 files out of an estimated total of 100\n",
      "Uploaded data/data_for_batch_inference/89, 89 files out of an estimated total of 100\n",
      "Uploaded data/data_for_batch_inference/9, 90 files out of an estimated total of 100\n",
      "Uploaded data/data_for_batch_inference/90, 91 files out of an estimated total of 100\n",
      "Uploaded data/data_for_batch_inference/91, 92 files out of an estimated total of 100\n",
      "Uploaded data/data_for_batch_inference/92, 93 files out of an estimated total of 100\n",
      "Uploaded data/data_for_batch_inference/93, 94 files out of an estimated total of 100\n",
      "Uploaded data/data_for_batch_inference/94, 95 files out of an estimated total of 100\n",
      "Uploaded data/data_for_batch_inference/95, 96 files out of an estimated total of 100\n",
      "Uploaded data/data_for_batch_inference/96, 97 files out of an estimated total of 100\n",
      "Uploaded data/data_for_batch_inference/97, 98 files out of an estimated total of 100\n",
      "Uploaded data/data_for_batch_inference/98, 99 files out of an estimated total of 100\n",
      "Uploaded data/data_for_batch_inference/99, 100 files out of an estimated total of 100\n",
      "Uploaded 100 files\n"
     ]
    }
   ],
   "source": [
    "dataset_name = 'THUCNews_For_Batch_Inference'\n",
    "# if the workspace don't contain the dataset, then register it\n",
    "if not dataset_name in workspace.datasets:\n",
    "    # upload files onto path_on_datastore to a blob container\n",
    "    # our files are in the directory of 'path_on_datastore' in the blob container\n",
    "    path_on_datastore = 'data_for_batch_inference'\n",
    "    datastore = Datastore.get(workspace=workspace, datastore_name='workspaceblobstore')\n",
    "    datastore.upload(src_dir='data/data_for_batch_inference', target_path=path_on_datastore, overwrite=True, show_progress=True)\n",
    "    # description of the dataset\n",
    "    description = 'THUCNews dataset is generated by filtering and filtering historical data \\\n",
    "    of Sina News RSS subscription channel from 2005 to 2011'\n",
    "    # get the DataPath object associated with the uploaded dataset\n",
    "    datastore_path = [DataPath(datastore=datastore, path_on_datastore=path_on_datastore)]\n",
    "    data = Dataset.File.from_files(path=datastore_path)\n",
    "    # register the dataset to your workspace\n",
    "    data.register(workspace=workspace, name=dataset_name, description=description, create_new_version=True)\n",
    "# get the registered dataset\n",
    "dataset = workspace.datasets[dataset_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register an anonymous module from yaml file to the workspace.\n",
    "If you decorate your module function with ```@dsl.module```, azure-cli-ml could help to generate the ```*.spec.yaml``` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fasttext_score_module_func = Module.from_yaml(workspace, 'fasttext_score/fasttext_score.spec.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a trained fastText model from a complete experiment\n",
    "- get all experiments\n",
    "- choose an experiment from all experiments\n",
    "- get the latest run\n",
    "- get a PipelineRun associated with the run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fasttext_test',\n",
       " 'sample-pipelines',\n",
       " 'automobile',\n",
       " 'fasttext_predict',\n",
       " 'sample-pipelines2',\n",
       " 'fasttext_with_two_training_process',\n",
       " 'train-within-notebook',\n",
       " 'train-on-local',\n",
       " 'logging-api-test',\n",
       " 'fasttext_with_one_training_process',\n",
       " 'fasttext_train',\n",
       " 'my_test',\n",
       " 'split_data_txt',\n",
       " 'compare_two_models',\n",
       " 'yucongj-test',\n",
       " 'fasttext_parallel_score',\n",
       " 'parallel',\n",
       " 'dir',\n",
       " 'test0717',\n",
       " 'test_0727',\n",
       " 'test_0727_experiment',\n",
       " 'localtest',\n",
       " 'mpi_0729',\n",
       " 'mpi_0729_experiment',\n",
       " 'test',\n",
       " 'para_0729',\n",
       " 'para_0729_experiment',\n",
       " 'basic_0721',\n",
       " 'basic_0721_experiment',\n",
       " 'deploy',\n",
       " 'fasttext_training_process',\n",
       " 'fasttext_batch_inference',\n",
       " 'fasttext_pipeline',\n",
       " 'fasttext_evaluation']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_name_list = [exp.name for exp in Experiment.list(workspace)]\n",
    "exp_name_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose the experiment you want with its name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Name</th><th>Workspace</th><th>Report Page</th><th>Docs Page</th></tr><tr><td>fasttext_pipeline</td><td>fundamental3</td><td><a href=\"https://ml.azure.com/experiments/fasttext_pipeline?wsid=/subscriptions/4f455bd0-f95a-4b7d-8d08-078611508e0b/resourcegroups/fundamental/workspaces/fundamental3\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.experiment.Experiment?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Experiment(Name: fasttext_pipeline,\n",
       "Workspace: fundamental3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_name = \"fasttext_pipeline\"\n",
    "experiment = Experiment(workspace, experiment_name)\n",
    "experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>fasttext_pipeline</td><td>42946bf0-b870-4af9-b230-7c257e9523d8</td><td>azureml.PipelineRun</td><td>Completed</td><td><a href=\"https://ml.azure.com/experiments/fasttext_pipeline/runs/42946bf0-b870-4af9-b230-7c257e9523d8?wsid=/subscriptions/4f455bd0-f95a-4b7d-8d08-078611508e0b/resourcegroups/fundamental/workspaces/fundamental3\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.run.Run?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: fasttext_pipeline,\n",
       "Id: 42946bf0-b870-4af9-b230-7c257e9523d8,\n",
       "Type: azureml.PipelineRun,\n",
       "Status: Completed)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# azureml.pipeline.core.run.PipelineRun\n",
    "run = Run.list(experiment, status='Completed').__next__()\n",
    "run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a PipelineRun object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>fasttext_pipeline</td><td>42946bf0-b870-4af9-b230-7c257e9523d8</td><td>azureml.PipelineRun</td><td>Completed</td><td><a href=\"https://ml.azure.com/experiments/fasttext_pipeline/runs/42946bf0-b870-4af9-b230-7c257e9523d8?wsid=/subscriptions/4f455bd0-f95a-4b7d-8d08-078611508e0b/resourcegroups/fundamental/workspaces/fundamental3\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: fasttext_pipeline,\n",
       "Id: 42946bf0-b870-4af9-b230-7c257e9523d8,\n",
       "Type: azureml.PipelineRun,\n",
       "Status: Completed)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_id = run.id\n",
    "# azureml.pipeline.wrapper._pipeline_run.PipelineRun\n",
    "pipeline_run = PipelineRun(experiment, run_id)\n",
    "pipeline_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the pipeline so as to obtain information about the module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "try {\n",
       "    require.undef(\"validate_widget\")\n",
       "\n",
       "    define('validate_widget', [\"@jupyter-widgets/base\"], function(widgets) {\n",
       "        var ValidateView = widgets.DOMWidgetView.extend({\n",
       "            render () {\n",
       "                window.widget_self = this\n",
       "                var visualize_id = this.model.get('visualize_id')\n",
       "\n",
       "                if (!window._renderLock) {\n",
       "                    window._renderLock = {}\n",
       "                }\n",
       "                if (window._renderLock[visualize_id]) {\n",
       "                    return\n",
       "                }\n",
       "                window._renderLock[visualize_id] = \"widget\"\n",
       "                console.log(\"load as widget\", Date.now())\n",
       "\n",
       "                var lib_url = this.model.get('lib_url')\n",
       "                var graph_json = JSON.parse(this.model.get('graph_json'))\n",
       "                var env_json = JSON.parse(this.model.get('env_json'))\n",
       "                var container_id = this.model.get('container_id')\n",
       "\n",
       "                window.render_container_id = container_id\n",
       "                window.graph_json = graph_json\n",
       "                window.graph_json_to_compare = undefined\n",
       "                window.env_json = env_json\n",
       "                window.before_script = performance.now()\n",
       "\n",
       "                var container = document.createElement('div')\n",
       "                container.id = container_id\n",
       "                this.el.appendChild(container)\n",
       "\n",
       "                var style = document.createElement('style')\n",
       "                style.innerHTML = [\n",
       "                    \"#\", container_id, \" svg.react-dag-editor-svg-container { height: 800px; }\",\n",
       "                    \".cell-output-ipywidget-background { background: transparent !important }\"\n",
       "                ].join('')\n",
       "                this.el.appendChild(style)\n",
       "\n",
       "                this.model.on('msg:custom', dispatchMessage, this);\n",
       "\n",
       "                if (!window.__event_hub) {\n",
       "                    window.__event_hub = {}\n",
       "                }\n",
       "                if (!window.__event_hub[container_id]) {\n",
       "                    window.__event_hub[container_id] = {}\n",
       "                }\n",
       "\n",
       "                if (!window.__send_event) {\n",
       "                    window.__send_event = {}\n",
       "                }\n",
       "                window.__send_event[container_id] = sendMessage.bind(this)\n",
       "\n",
       "                function sendMessage(message, uid, content) {\n",
       "                    return new Promise((resolve) => {\n",
       "                        this.model.send({\n",
       "                            message: `${message}:request`,\n",
       "                            body: {\n",
       "                                uid,\n",
       "                                content\n",
       "                            }\n",
       "                        })\n",
       "    \n",
       "                        var respMessageKey = `${message}:response`\n",
       "                        if (!window.__event_hub[container_id][respMessageKey]) {\n",
       "                            window.__event_hub[container_id][respMessageKey] = []\n",
       "                        }\n",
       "                        window.__event_hub[container_id][respMessageKey].push(callback)\n",
       "    \n",
       "                        function callback (response) {\n",
       "                            if (response.uid !== uid) {\n",
       "                                return\n",
       "                            }\n",
       "\n",
       "                            var idx = window.__event_hub[container_id][respMessageKey].indexOf(callback) \n",
       "                            window.__event_hub[container_id][respMessageKey].splice(idx, 1)\n",
       "                            \n",
       "                            resolve(response)\n",
       "                        }\n",
       "                    })\n",
       "                }\n",
       "\n",
       "                function dispatchMessage (rawMessage) {\n",
       "                    var message = rawMessage.message\n",
       "                    var body = rawMessage.body\n",
       "\n",
       "                    if (!window.__event_hub[container_id][message]) {\n",
       "                        window.__event_hub[container_id][message] = []\n",
       "                    }\n",
       "                    var listeners = window.__event_hub[container_id][message]\n",
       "\n",
       "                    listeners.forEach(cb => {\n",
       "                        try {\n",
       "                            cb(body)\n",
       "                        } catch (e) {\n",
       "                            console.error(\"Unexpected error in listener\", e)\n",
       "                        }\n",
       "                    })\n",
       "\n",
       "                    console.log(body)\n",
       "                }\n",
       "\n",
       "                var script = document.createElement('script')\n",
       "                script.src = lib_url\n",
       "                this.el.appendChild(script)\n",
       "            }\n",
       "        });\n",
       "\n",
       "        return {\n",
       "            ValidateView\n",
       "        }\n",
       "    })\n",
       "} catch (e) {\n",
       "    console.log(\"create validation widget failed\", e)\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1e051fec48b4770a513e5397cc3037e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ValidateView(container_id='container_id_288aeb82-97eb-4459-841a-4157f0783542_widget', env_json='{}', graph_jso…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "        #container_id_288aeb82-97eb-4459-841a-4157f0783542_script svg.react-dag-editor-svg-container {\n",
       "            height: 800px;\n",
       "        }\n",
       "        </style>\n",
       "        <div id=\"container_id_288aeb82-97eb-4459-841a-4157f0783542_script\"></div>\n",
       "        <script>\n",
       "            (function () {\n",
       "                if (!window._renderLock) {\n",
       "                    window._renderLock = {}\n",
       "                }\n",
       "                if (window._renderLock[\"288aeb82-97eb-4459-841a-4157f0783542\"]) {\n",
       "                    return\n",
       "                }\n",
       "                window._renderLock[\"288aeb82-97eb-4459-841a-4157f0783542\"] = \"script\"\n",
       "                console.log(\"load as script\", Date.now())\n",
       "                window.render_container_id=\"container_id_288aeb82-97eb-4459-841a-4157f0783542_script\";\n",
       "                window.graph_json={\"pipeline\": {\"name\": \"fasttext_pipeline\", \"data_references\": {\"THUCNews\": {\"dataset_id\": \"89a5a8e3-9df3-4a1a-a3ee-d82ec112c4fb\"}}, \"steps\": {\"25e82957\": {\"inputs\": {\"Input_dir\": {\"source\": \"THUCNews\"}}, \"outputs\": {\"Training_data_output\": {\"destination\": \"25e82957_Training_data_output\"}, \"Validation_data_output\": {\"destination\": \"25e82957_Validation_data_output\"}, \"Test_data_output\": {\"destination\": \"25e82957_Test_data_output\"}}, \"module\": {\"id\": \"bbaeec54-12ee-4b66-be83-143f009aeb83\", \"version\": \"0.0.43\"}, \"validate\": {\"error\": [], \"module_id\": \"bbaeec54-12ee-4b66-be83-143f009aeb83\", \"namespace\": \"fundamental3\", \"module_name\": \"Split Data Txt\", \"module_version\": \"0.0.43\"}}, \"6a1f92ab\": {\"inputs\": {\"Training_data_dir\": {\"source\": \"25e82957_Training_data_output\"}, \"Validation_data_dir\": {\"source\": \"25e82957_Validation_data_output\"}}, \"outputs\": {\"Trained_model_dir\": {\"destination\": \"6a1f92ab_Trained_model_dir\"}}, \"module\": {\"id\": \"3d2893e3-b4a1-49f3-bf91-8c3dc001a8d4\", \"version\": \"0.0.41\"}, \"validate\": {\"error\": [], \"module_id\": \"3d2893e3-b4a1-49f3-bf91-8c3dc001a8d4\", \"namespace\": \"fundamental3\", \"module_name\": \"FastText Train\", \"module_version\": \"0.0.41\"}}, \"82ebee16\": {\"inputs\": {\"Trained_model_dir\": {\"source\": \"6a1f92ab_Trained_model_dir\"}, \"Test_data_dir\": {\"source\": \"25e82957_Test_data_output\"}}, \"outputs\": {\"Model_testing_result\": {\"destination\": \"82ebee16_Model_testing_result\"}}, \"module\": {\"id\": \"ed876e8a-73f5-4d7a-9ea3-b65d3752bd6d\", \"version\": \"0.0.8\"}, \"validate\": {\"error\": [], \"module_id\": \"ed876e8a-73f5-4d7a-9ea3-b65d3752bd6d\", \"namespace\": \"fundamental3\", \"module_name\": \"FastText Evaluation\", \"module_version\": \"0.0.8\"}}, \"5ebe6ef2\": {\"inputs\": {\"Input_dir\": {\"source\": \"THUCNews\"}}, \"outputs\": {\"Training_data_output\": {\"destination\": \"5ebe6ef2_Training_data_output\"}, \"Validation_data_output\": {\"destination\": \"5ebe6ef2_Validation_data_output\"}, \"Test_data_output\": {\"destination\": \"5ebe6ef2_Test_data_output\"}}, \"module\": {\"id\": \"bbaeec54-12ee-4b66-be83-143f009aeb83\", \"version\": \"0.0.43\"}, \"validate\": {\"error\": [], \"module_id\": \"bbaeec54-12ee-4b66-be83-143f009aeb83\", \"namespace\": \"fundamental3\", \"module_name\": \"Split Data Txt\", \"module_version\": \"0.0.43\"}}, \"a07cf37b\": {\"inputs\": {\"Training_data_dir\": {\"source\": \"5ebe6ef2_Training_data_output\"}, \"Validation_data_dir\": {\"source\": \"5ebe6ef2_Validation_data_output\"}}, \"outputs\": {\"Trained_model_dir\": {\"destination\": \"a07cf37b_Trained_model_dir\"}}, \"module\": {\"id\": \"3d2893e3-b4a1-49f3-bf91-8c3dc001a8d4\", \"version\": \"0.0.41\"}, \"validate\": {\"error\": [], \"module_id\": \"3d2893e3-b4a1-49f3-bf91-8c3dc001a8d4\", \"namespace\": \"fundamental3\", \"module_name\": \"FastText Train\", \"module_version\": \"0.0.41\"}}, \"7001efeb\": {\"inputs\": {\"Trained_model_dir\": {\"source\": \"a07cf37b_Trained_model_dir\"}, \"Test_data_dir\": {\"source\": \"5ebe6ef2_Test_data_output\"}}, \"outputs\": {\"Model_testing_result\": {\"destination\": \"7001efeb_Model_testing_result\"}}, \"module\": {\"id\": \"ed876e8a-73f5-4d7a-9ea3-b65d3752bd6d\", \"version\": \"0.0.8\"}, \"validate\": {\"error\": [], \"module_id\": \"ed876e8a-73f5-4d7a-9ea3-b65d3752bd6d\", \"namespace\": \"fundamental3\", \"module_name\": \"FastText Evaluation\", \"module_version\": \"0.0.8\"}}, \"cdeae8aa\": {\"inputs\": {\"First_trained_model\": {\"source\": \"6a1f92ab_Trained_model_dir\"}, \"First_trained_result\": {\"source\": \"82ebee16_Model_testing_result\"}, \"Second_trained_model\": {\"source\": \"a07cf37b_Trained_model_dir\"}, \"Second_trained_result\": {\"source\": \"7001efeb_Model_testing_result\"}}, \"outputs\": {}, \"module\": {\"id\": \"c607f3bc-6651-42ba-9fe9-9efb687de3d1\", \"version\": \"0.0.18\"}, \"validate\": {\"error\": [], \"module_id\": \"c607f3bc-6651-42ba-9fe9-9efb687de3d1\", \"namespace\": \"fundamental3\", \"module_name\": \"Compare Two Models\", \"module_version\": \"0.0.18\"}}}}, \"modules\": [{\"module_id\": \"bbaeec54-12ee-4b66-be83-143f009aeb83\", \"version\": \"0.0.43\", \"name\": \"Split Data Txt\", \"namespace\": \"fundamental3\", \"structured_interface\": {\"inputs\": [{\"name\": \"Input_dir\", \"label\": \"Input dir\", \"description\": null, \"data_type_ids_list\": [\"AnyDirectory\"]}], \"outputs\": [{\"name\": \"Training_data_output\", \"label\": \"Training data output\", \"description\": null, \"data_type_id\": \"AnyDirectory\"}, {\"name\": \"Validation_data_output\", \"label\": \"Validation data output\", \"description\": null, \"data_type_id\": \"AnyDirectory\"}, {\"name\": \"Test_data_output\", \"label\": \"Test data output\", \"description\": null, \"data_type_id\": \"AnyDirectory\"}]}}, {\"module_id\": \"3d2893e3-b4a1-49f3-bf91-8c3dc001a8d4\", \"version\": \"0.0.41\", \"name\": \"FastText Train\", \"namespace\": \"fundamental3\", \"structured_interface\": {\"inputs\": [{\"name\": \"Training_data_dir\", \"label\": \"Training data dir\", \"description\": null, \"data_type_ids_list\": [\"AnyDirectory\"]}, {\"name\": \"Validation_data_dir\", \"label\": \"Validation data dir\", \"description\": null, \"data_type_ids_list\": [\"AnyDirectory\"]}], \"outputs\": [{\"name\": \"Trained_model_dir\", \"label\": \"Trained model dir\", \"description\": null, \"data_type_id\": \"ModelDirectory\"}]}}, {\"module_id\": \"ed876e8a-73f5-4d7a-9ea3-b65d3752bd6d\", \"version\": \"0.0.8\", \"name\": \"FastText Evaluation\", \"namespace\": \"fundamental3\", \"structured_interface\": {\"inputs\": [{\"name\": \"Trained_model_dir\", \"label\": \"Trained model dir\", \"description\": null, \"data_type_ids_list\": [\"AnyDirectory\"]}, {\"name\": \"Test_data_dir\", \"label\": \"Test data dir\", \"description\": null, \"data_type_ids_list\": [\"AnyDirectory\"]}], \"outputs\": [{\"name\": \"Model_testing_result\", \"label\": \"Model testing result\", \"description\": null, \"data_type_id\": \"AnyDirectory\"}]}}, {\"module_id\": \"c607f3bc-6651-42ba-9fe9-9efb687de3d1\", \"version\": \"0.0.18\", \"name\": \"Compare Two Models\", \"namespace\": \"fundamental3\", \"structured_interface\": {\"inputs\": [{\"name\": \"First_trained_model\", \"label\": \"First trained model\", \"description\": null, \"data_type_ids_list\": [\"AnyDirectory\"]}, {\"name\": \"First_trained_result\", \"label\": \"First trained result\", \"description\": null, \"data_type_ids_list\": [\"AnyDirectory\"]}, {\"name\": \"Second_trained_model\", \"label\": \"Second trained model\", \"description\": null, \"data_type_ids_list\": [\"AnyDirectory\"]}, {\"name\": \"Second_trained_result\", \"label\": \"Second trained result\", \"description\": null, \"data_type_ids_list\": [\"AnyDirectory\"]}], \"outputs\": [{\"name\": \"The_better_model\", \"label\": \"The better model\", \"description\": null, \"data_type_id\": \"AnyDirectory\"}]}}], \"datasources\": [{\"name\": \"THUCNews\", \"description\": \"THUCNews dataset is generated by filtering and filtering historical data     of Sina News RSS subscription channel from 2005 to 2011\", \"version\": \"1\", \"registered_id\": \"89a5a8e3-9df3-4a1a-a3ee-d82ec112c4fb\", \"saved_id\": \"91c342a3-19c5-4de6-a237-7132d420ae18\", \"nodeId\": \"0b25adc0-e816-3e80-853c-4414fb851997\"}], \"subGraphInfo\": [{\"name\": \"fasttext_pipeline\", \"description\": \"The pipeline that trains two fasttext models and output the better one\", \"default_compute_target\": {\"name\": \"aml-compute\", \"compute_type\": \"0\"}, \"default_data_store\": {\"data_store_name\": \"workspaceblobstore\"}, \"id\": \"f0ec7173-c523-49e3-bcb5-fba698892261\", \"pipeline_definition_id\": \"a46d2265-b8b5-4aeb-90b4-13dcb9b5ede1\", \"sub_graph_parameter_assignment\": [], \"sub_graph_data_path_parameter_assignment\": [], \"sub_graph_default_compute_target_nodes\": [\"cdeae8aa\"], \"sub_graph_default_data_store_nodes\": [\"cdeae8aa\"], \"inputs\": [], \"outputs\": [{\"name\": \"the_better_model\", \"internal\": [{\"node_id\": \"cdeae8aa\", \"port_name\": \"The_better_model\"}], \"external\": []}]}, {\"name\": \"sub_pipeline\", \"description\": \"A sub pipeline including processes of data processing/train/evaluation\", \"default_compute_target\": {\"name\": \"aml-compute\", \"compute_type\": \"0\"}, \"default_data_store\": {\"data_store_name\": \"workspaceblobstore\"}, \"id\": \"882bf186-7531-4725-8ddf-71633ab2988c\", \"parent_graph_id\": \"f0ec7173-c523-49e3-bcb5-fba698892261\", \"pipeline_definition_id\": \"c904aac5-ab7e-464a-9b53-e173a14fad61\", \"sub_graph_parameter_assignment\": [{\"parameter\": {\"name\": \"epochs\", \"is_optional\": false, \"type\": \"0\"}, \"parameter_assignments\": [{\"node_id\": \"6a1f92ab\", \"parameter_name\": \"Epochs\"}]}, {\"parameter\": {\"name\": \"batch_size\", \"is_optional\": false, \"type\": \"0\"}, \"parameter_assignments\": [{\"node_id\": \"6a1f92ab\", \"parameter_name\": \"Batch size\"}]}, {\"parameter\": {\"name\": \"max_len\", \"is_optional\": false, \"type\": \"0\"}, \"parameter_assignments\": [{\"node_id\": \"6a1f92ab\", \"parameter_name\": \"Max len\"}]}], \"sub_graph_data_path_parameter_assignment\": [], \"sub_graph_default_compute_target_nodes\": [\"25e82957\", \"6a1f92ab\", \"82ebee16\"], \"sub_graph_default_data_store_nodes\": [], \"inputs\": [], \"outputs\": [{\"name\": \"model_testing_result\", \"internal\": [{\"node_id\": \"82ebee16\", \"port_name\": \"Model_testing_result\"}], \"external\": [{\"node_id\": \"cdeae8aa\", \"port_name\": \"First_trained_result\"}]}, {\"name\": \"trained_model_dir\", \"internal\": [{\"node_id\": \"6a1f92ab\", \"port_name\": \"Trained_model_dir\"}], \"external\": [{\"node_id\": \"82ebee16\", \"port_name\": \"Trained_model_dir\"}, {\"node_id\": \"cdeae8aa\", \"port_name\": \"First_trained_model\"}]}]}, {\"name\": \"sub_pipeline\", \"description\": \"A sub pipeline including processes of data processing/train/evaluation\", \"default_compute_target\": {\"name\": \"aml-compute\", \"compute_type\": \"0\"}, \"default_data_store\": {\"data_store_name\": \"workspaceblobstore\"}, \"id\": \"481e7997-ae7f-4e21-9575-5d5ddc94c28d\", \"parent_graph_id\": \"f0ec7173-c523-49e3-bcb5-fba698892261\", \"pipeline_definition_id\": \"c904aac5-ab7e-464a-9b53-e173a14fad61\", \"sub_graph_parameter_assignment\": [{\"parameter\": {\"name\": \"epochs\", \"is_optional\": false, \"type\": \"0\"}, \"parameter_assignments\": [{\"node_id\": \"a07cf37b\", \"parameter_name\": \"Epochs\"}]}, {\"parameter\": {\"name\": \"batch_size\", \"is_optional\": false, \"type\": \"0\"}, \"parameter_assignments\": [{\"node_id\": \"a07cf37b\", \"parameter_name\": \"Batch size\"}]}, {\"parameter\": {\"name\": \"max_len\", \"is_optional\": false, \"type\": \"0\"}, \"parameter_assignments\": [{\"node_id\": \"a07cf37b\", \"parameter_name\": \"Max len\"}]}], \"sub_graph_data_path_parameter_assignment\": [], \"sub_graph_default_compute_target_nodes\": [\"5ebe6ef2\", \"a07cf37b\", \"7001efeb\"], \"sub_graph_default_data_store_nodes\": [], \"inputs\": [], \"outputs\": [{\"name\": \"model_testing_result\", \"internal\": [{\"node_id\": \"7001efeb\", \"port_name\": \"Model_testing_result\"}], \"external\": [{\"node_id\": \"cdeae8aa\", \"port_name\": \"Second_trained_result\"}]}, {\"name\": \"trained_model_dir\", \"internal\": [{\"node_id\": \"a07cf37b\", \"port_name\": \"Trained_model_dir\"}], \"external\": [{\"node_id\": \"7001efeb\", \"port_name\": \"Trained_model_dir\"}, {\"node_id\": \"cdeae8aa\", \"port_name\": \"Second_trained_model\"}]}]}], \"nodeIdToSubGraphIdMapping\": {\"25e82957\": \"882bf186-7531-4725-8ddf-71633ab2988c\", \"6a1f92ab\": \"882bf186-7531-4725-8ddf-71633ab2988c\", \"82ebee16\": \"882bf186-7531-4725-8ddf-71633ab2988c\", \"5ebe6ef2\": \"481e7997-ae7f-4e21-9575-5d5ddc94c28d\", \"a07cf37b\": \"481e7997-ae7f-4e21-9575-5d5ddc94c28d\", \"7001efeb\": \"481e7997-ae7f-4e21-9575-5d5ddc94c28d\", \"cdeae8aa\": \"f0ec7173-c523-49e3-bcb5-fba698892261\"}, \"subPipelineDefinition\": [{\"name\": \"fasttext_pipeline\", \"description\": \"The pipeline that trains two fasttext models and output the better one\", \"default_compute_target\": {\"name\": \"aml-compute\", \"compute_type\": \"0\"}, \"default_data_store\": {\"data_store_name\": \"workspaceblobstore\"}, \"pipeline_function_name\": \"fasttext_pipeline\", \"id\": \"a46d2265-b8b5-4aeb-90b4-13dcb9b5ede1\", \"from_module_name\": \"__main__\", \"parameter_list\": []}, {\"name\": \"sub_pipeline\", \"description\": \"A sub pipeline including processes of data processing/train/evaluation\", \"default_compute_target\": {\"name\": \"aml-compute\", \"compute_type\": \"0\"}, \"default_data_store\": {\"data_store_name\": \"workspaceblobstore\"}, \"pipeline_function_name\": \"training_pipeline\", \"id\": \"c904aac5-ab7e-464a-9b53-e173a14fad61\", \"from_module_name\": \"__main__\", \"parameter_list\": [{\"key\": \"epochs\"}, {\"key\": \"batch_size\"}, {\"key\": \"max_len\"}]}]};\n",
       "                window.graph_json_to_compare=undefined;\n",
       "                window.env_json={};\n",
       "                window.before_script = performance.now();\n",
       "                var script = document.createElement('script')\n",
       "                script.src = \"https://yucongj.azureedge.net/libs/prod/0.0.9/index.js\"\n",
       "                document.getElementById(\"container_id_288aeb82-97eb-4459-841a-4157f0783542_script\").appendChild(script)\n",
       "            })()\n",
       "        </script>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline_run.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Get the trained model from a StepRun object.\n",
    "- get a StepRun from the PipelineRun\n",
    "- get the port with the trained model from the StepRun\n",
    "- get DataPath from the port\n",
    "- change DataPath into the form of module input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>fasttext_pipeline</td><td>9502941c-d015-4e8d-b7cb-436c783f17d1</td><td>azureml.StepRun</td><td>Completed</td><td><a href=\"https://ml.azure.com/experiments/fasttext_pipeline/runs/9502941c-d015-4e8d-b7cb-436c783f17d1?wsid=/subscriptions/4f455bd0-f95a-4b7d-8d08-078611508e0b/resourcegroups/fundamental/workspaces/fundamental3\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "StepRun(Experiment: fasttext_pipeline,\n",
       "Id: 9502941c-d015-4e8d-b7cb-436c783f17d1,\n",
       "Type: azureml.StepRun,\n",
       "Status: Completed)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# obtain step_run_id from the visualization result.\n",
    "step_run_id = '9502941c-d015-4e8d-b7cb-436c783f17d1'\n",
    "step_run = pipeline_run.get_step_run(step_run_id)\n",
    "step_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In order to use the trained model from a port without registration, we need to install an extra dependence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://azuremlsdktestpypi.azureedge.net/modulesdkpreview\n",
      "Requirement already up-to-date: azureml-dataset-runtime[fuse] in /home/azureuser/.local/lib/python3.6/site-packages (1.11.0.post1)\n",
      "Requirement already satisfied, skipping upgrade: azureml-dataprep<2.1.0a,>=2.0.1a in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from azureml-dataset-runtime[fuse]) (2.0.3a2020080602)\n",
      "Requirement already satisfied, skipping upgrade: pyarrow<1.0.0,>=0.17.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from azureml-dataset-runtime[fuse]) (0.17.1)\n",
      "Requirement already satisfied, skipping upgrade: fusepy<4.0.0,>=3.0.1; extra == \"fuse\" in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from azureml-dataset-runtime[fuse]) (3.0.1)\n",
      "Requirement already satisfied, skipping upgrade: dotnetcore2<3.0.0,>=2.1.14 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from azureml-dataprep<2.1.0a,>=2.0.1a->azureml-dataset-runtime[fuse]) (2.1.14)\n",
      "Requirement already satisfied, skipping upgrade: azureml-dataprep-native<21.0.0,>=20.0.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from azureml-dataprep<2.1.0a,>=2.0.1a->azureml-dataset-runtime[fuse]) (20.0.0)\n",
      "Requirement already satisfied, skipping upgrade: cloudpickle<2.0.0,>=1.1.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from azureml-dataprep<2.1.0a,>=2.0.1a->azureml-dataset-runtime[fuse]) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: azure-identity<1.3.0,>=1.2.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from azureml-dataprep<2.1.0a,>=2.0.1a->azureml-dataset-runtime[fuse]) (1.2.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.14 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from pyarrow<1.0.0,>=0.17.0->azureml-dataset-runtime[fuse]) (1.16.2)\n",
      "Requirement already satisfied, skipping upgrade: distro>=1.2.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from dotnetcore2<3.0.0,>=2.1.14->azureml-dataprep<2.1.0a,>=2.0.1a->azureml-dataset-runtime[fuse]) (1.5.0)\n",
      "Requirement already satisfied, skipping upgrade: msal<2.0.0,>=1.0.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from azure-identity<1.3.0,>=1.2.0->azureml-dataprep<2.1.0a,>=2.0.1a->azureml-dataset-runtime[fuse]) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: cryptography>=2.1.4 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from azure-identity<1.3.0,>=1.2.0->azureml-dataprep<2.1.0a,>=2.0.1a->azureml-dataset-runtime[fuse]) (2.9.2)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.6 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from azure-identity<1.3.0,>=1.2.0->azureml-dataprep<2.1.0a,>=2.0.1a->azureml-dataset-runtime[fuse]) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: msal-extensions~=0.1.3 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from azure-identity<1.3.0,>=1.2.0->azureml-dataprep<2.1.0a,>=2.0.1a->azureml-dataset-runtime[fuse]) (0.1.3)\n",
      "Requirement already satisfied, skipping upgrade: azure-core<2.0.0,>=1.0.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from azure-identity<1.3.0,>=1.2.0->azureml-dataprep<2.1.0a,>=2.0.1a->azureml-dataset-runtime[fuse]) (1.6.0)\n",
      "Requirement already satisfied, skipping upgrade: PyJWT[crypto]<2,>=1.0.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from msal<2.0.0,>=1.0.0->azure-identity<1.3.0,>=1.2.0->azureml-dataprep<2.1.0a,>=2.0.1a->azureml-dataset-runtime[fuse]) (1.7.1)\n",
      "Requirement already satisfied, skipping upgrade: requests<3,>=2.0.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from msal<2.0.0,>=1.0.0->azure-identity<1.3.0,>=1.2.0->azureml-dataprep<2.1.0a,>=2.0.1a->azureml-dataset-runtime[fuse]) (2.24.0)\n",
      "Requirement already satisfied, skipping upgrade: cffi!=1.11.3,>=1.8 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from cryptography>=2.1.4->azure-identity<1.3.0,>=1.2.0->azureml-dataprep<2.1.0a,>=2.0.1a->azureml-dataset-runtime[fuse]) (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: portalocker~=1.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from msal-extensions~=0.1.3->azure-identity<1.3.0,>=1.2.0->azureml-dataprep<2.1.0a,>=2.0.1a->azureml-dataset-runtime[fuse]) (1.7.0)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from requests<3,>=2.0.0->msal<2.0.0,>=1.0.0->azure-identity<1.3.0,>=1.2.0->azureml-dataprep<2.1.0a,>=2.0.1a->azureml-dataset-runtime[fuse]) (2.9)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from requests<3,>=2.0.0->msal<2.0.0,>=1.0.0->azure-identity<1.3.0,>=1.2.0->azureml-dataprep<2.1.0a,>=2.0.1a->azureml-dataset-runtime[fuse]) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from requests<3,>=2.0.0->msal<2.0.0,>=1.0.0->azure-identity<1.3.0,>=1.2.0->azureml-dataprep<2.1.0a,>=2.0.1a->azureml-dataset-runtime[fuse]) (2020.6.20)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from requests<3,>=2.0.0->msal<2.0.0,>=1.0.0->azure-identity<1.3.0,>=1.2.0->azureml-dataprep<2.1.0a,>=2.0.1a->azureml-dataset-runtime[fuse]) (1.25.9)\n",
      "Requirement already satisfied, skipping upgrade: pycparser in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.1.4->azure-identity<1.3.0,>=1.2.0->azureml-dataprep<2.1.0a,>=2.0.1a->azureml-dataset-runtime[fuse]) (2.20)\n"
     ]
    }
   ],
   "source": [
    "# Install dataset runtime to enable dataset registration in sample notebooks\n",
    "!pip install azureml-dataset-runtime[fuse] --extra-index-url https://azuremlsdktestpypi.azureedge.net/modulesdkpreview --user --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Use the trained model as the input of a new pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<azureml.data.dataset_consumption_config.DatasetConsumptionConfig at 0x7f63ab6ba320>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get_port() should supports three kinds of names: (1)The better model (2)the_better_model (3)The_better_model\n",
    "port = step_run.get_port(name='The_better_model')\n",
    "data_path = port.get_data_path()\n",
    "model = Dataset.File.from_files(path=[data_path]).as_named_input('model_for_batch_inference')\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Construct the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "@dsl.pipeline(name='batch inference', description='Batch Inference', default_compute_target=aml_compute.name)\n",
    "def training_pipeline():\n",
    "    fasttext_score = fasttext_score_module_func(\n",
    "        texts_to_score=dataset,\n",
    "        fasttext_model_dir=model\n",
    "    )\n",
    "    fasttext_score.runsettings.configure(node_count=1, process_count_per_node=2, mini_batch_size=\"64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<azureml.pipeline.wrapper._pipeline.Pipeline at 0x7f63aabc1320>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pipeline\n",
    "pipeline = training_pipeline()\n",
    "# pipeline.save(experiment_name=experiment_name)\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted PipelineRun dd31b79d-3146-4e6a-b49b-6dfb8f646c56\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/fasttext_batch_inference/runs/dd31b79d-3146-4e6a-b49b-6dfb8f646c56?wsid=/subscriptions/4f455bd0-f95a-4b7d-8d08-078611508e0b/resourcegroups/fundamental/workspaces/fundamental3\n",
      "PipelineRunId: dd31b79d-3146-4e6a-b49b-6dfb8f646c56\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/fasttext_batch_inference/runs/dd31b79d-3146-4e6a-b49b-6dfb8f646c56?wsid=/subscriptions/4f455bd0-f95a-4b7d-8d08-078611508e0b/resourcegroups/fundamental/workspaces/fundamental3\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "try {\n",
       "    require.undef(\"validate_widget\")\n",
       "\n",
       "    define('validate_widget', [\"@jupyter-widgets/base\"], function(widgets) {\n",
       "        var ValidateView = widgets.DOMWidgetView.extend({\n",
       "            render () {\n",
       "                window.widget_self = this\n",
       "                var visualize_id = this.model.get('visualize_id')\n",
       "\n",
       "                if (!window._renderLock) {\n",
       "                    window._renderLock = {}\n",
       "                }\n",
       "                if (window._renderLock[visualize_id]) {\n",
       "                    return\n",
       "                }\n",
       "                window._renderLock[visualize_id] = \"widget\"\n",
       "                console.log(\"load as widget\", Date.now())\n",
       "\n",
       "                var lib_url = this.model.get('lib_url')\n",
       "                var graph_json = JSON.parse(this.model.get('graph_json'))\n",
       "                var env_json = JSON.parse(this.model.get('env_json'))\n",
       "                var container_id = this.model.get('container_id')\n",
       "\n",
       "                window.render_container_id = container_id\n",
       "                window.graph_json = graph_json\n",
       "                window.graph_json_to_compare = undefined\n",
       "                window.env_json = env_json\n",
       "                window.before_script = performance.now()\n",
       "\n",
       "                var container = document.createElement('div')\n",
       "                container.id = container_id\n",
       "                this.el.appendChild(container)\n",
       "\n",
       "                var style = document.createElement('style')\n",
       "                style.innerHTML = [\n",
       "                    \"#\", container_id, \" svg.react-dag-editor-svg-container { height: 800px; }\",\n",
       "                    \".cell-output-ipywidget-background { background: transparent !important }\"\n",
       "                ].join('')\n",
       "                this.el.appendChild(style)\n",
       "\n",
       "                this.model.on('msg:custom', dispatchMessage, this);\n",
       "\n",
       "                if (!window.__event_hub) {\n",
       "                    window.__event_hub = {}\n",
       "                }\n",
       "                if (!window.__event_hub[container_id]) {\n",
       "                    window.__event_hub[container_id] = {}\n",
       "                }\n",
       "\n",
       "                if (!window.__send_event) {\n",
       "                    window.__send_event = {}\n",
       "                }\n",
       "                window.__send_event[container_id] = sendMessage.bind(this)\n",
       "\n",
       "                function sendMessage(message, uid, content) {\n",
       "                    return new Promise((resolve) => {\n",
       "                        this.model.send({\n",
       "                            message: `${message}:request`,\n",
       "                            body: {\n",
       "                                uid,\n",
       "                                content\n",
       "                            }\n",
       "                        })\n",
       "    \n",
       "                        var respMessageKey = `${message}:response`\n",
       "                        if (!window.__event_hub[container_id][respMessageKey]) {\n",
       "                            window.__event_hub[container_id][respMessageKey] = []\n",
       "                        }\n",
       "                        window.__event_hub[container_id][respMessageKey].push(callback)\n",
       "    \n",
       "                        function callback (response) {\n",
       "                            if (response.uid !== uid) {\n",
       "                                return\n",
       "                            }\n",
       "\n",
       "                            var idx = window.__event_hub[container_id][respMessageKey].indexOf(callback) \n",
       "                            window.__event_hub[container_id][respMessageKey].splice(idx, 1)\n",
       "                            \n",
       "                            resolve(response)\n",
       "                        }\n",
       "                    })\n",
       "                }\n",
       "\n",
       "                function dispatchMessage (rawMessage) {\n",
       "                    var message = rawMessage.message\n",
       "                    var body = rawMessage.body\n",
       "\n",
       "                    if (!window.__event_hub[container_id][message]) {\n",
       "                        window.__event_hub[container_id][message] = []\n",
       "                    }\n",
       "                    var listeners = window.__event_hub[container_id][message]\n",
       "\n",
       "                    listeners.forEach(cb => {\n",
       "                        try {\n",
       "                            cb(body)\n",
       "                        } catch (e) {\n",
       "                            console.error(\"Unexpected error in listener\", e)\n",
       "                        }\n",
       "                    })\n",
       "\n",
       "                    console.log(body)\n",
       "                }\n",
       "\n",
       "                var script = document.createElement('script')\n",
       "                script.src = lib_url\n",
       "                this.el.appendChild(script)\n",
       "            }\n",
       "        });\n",
       "\n",
       "        return {\n",
       "            ValidateView\n",
       "        }\n",
       "    })\n",
       "} catch (e) {\n",
       "    console.log(\"create validation widget failed\", e)\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a4ace036cc949f2ad139664fdeab82a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ValidateView(container_id='container_id_9229f8b8-24c7-4160-b2a0-1c2430380d20_widget', env_json='{}', graph_jso…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "        #container_id_9229f8b8-24c7-4160-b2a0-1c2430380d20_script svg.react-dag-editor-svg-container {\n",
       "            height: 800px;\n",
       "        }\n",
       "        </style>\n",
       "        <div id=\"container_id_9229f8b8-24c7-4160-b2a0-1c2430380d20_script\"></div>\n",
       "        <script>\n",
       "            (function () {\n",
       "                if (!window._renderLock) {\n",
       "                    window._renderLock = {}\n",
       "                }\n",
       "                if (window._renderLock[\"9229f8b8-24c7-4160-b2a0-1c2430380d20\"]) {\n",
       "                    return\n",
       "                }\n",
       "                window._renderLock[\"9229f8b8-24c7-4160-b2a0-1c2430380d20\"] = \"script\"\n",
       "                console.log(\"load as script\", Date.now())\n",
       "                window.render_container_id=\"container_id_9229f8b8-24c7-4160-b2a0-1c2430380d20_script\";\n",
       "                window.graph_json={\"pipeline\": {\"name\": \"batch inference\", \"data_references\": {\"THUCNews_For_Batch_Inference\": {\"dataset_id\": \"a7a2a98d-0088-420d-8142-3c3591e26345\"}, \"17756dac-03de-4626-a3c8-9ea71a4391a5\": {\"saved_id\": \"17756dac-03de-4626-a3c8-9ea71a4391a5\"}}, \"steps\": {\"a580c213\": {\"inputs\": {\"Texts_to_score\": {\"source\": \"THUCNews_For_Batch_Inference\"}, \"Fasttext_model_dir\": {\"source\": \"17756dac-03de-4626-a3c8-9ea71a4391a5\"}}, \"outputs\": {}, \"module\": {\"id\": \"2573c3c5-1416-4a18-b6d6-bf763e77dbbd\", \"version\": \"0.0.23\"}, \"validate\": {\"error\": [], \"module_id\": \"2573c3c5-1416-4a18-b6d6-bf763e77dbbd\", \"namespace\": \"fundamental3\", \"module_name\": \"FastText Score\", \"module_version\": \"0.0.23\"}}}}, \"modules\": [{\"module_id\": \"2573c3c5-1416-4a18-b6d6-bf763e77dbbd\", \"version\": \"0.0.23\", \"name\": \"FastText Score\", \"namespace\": \"fundamental3\", \"structured_interface\": {\"inputs\": [{\"name\": \"Texts_to_score\", \"label\": \"Texts to score\", \"description\": null, \"data_type_ids_list\": [\"AnyDirectory\"]}, {\"name\": \"Fasttext_model_dir\", \"label\": \"Fasttext model dir\", \"description\": null, \"data_type_ids_list\": [\"AnyDirectory\"]}], \"outputs\": [{\"name\": \"Scored_data_output_dir\", \"label\": \"Scored data output dir\", \"description\": null, \"data_type_id\": \"AnyDirectory\"}]}}], \"datasources\": [{\"name\": \"THUCNews_For_Batch_Inference\", \"description\": \"THUCNews dataset is generated by filtering and filtering historical data     of Sina News RSS subscription channel from 2005 to 2011\", \"version\": \"1\", \"registered_id\": \"a7a2a98d-0088-420d-8142-3c3591e26345\", \"saved_id\": \"4085d7f5-999e-48c8-ab2a-0833a33c6dcb\", \"nodeId\": \"2d7a7ff7-c411-389a-8d40-ee9572db5454\"}], \"subGraphInfo\": [{\"name\": \"batch inference\", \"description\": \"Batch Inference\", \"default_compute_target\": {\"name\": \"aml-compute\", \"compute_type\": \"0\"}, \"default_data_store\": {\"data_store_name\": \"workspaceblobstore\"}, \"id\": \"16500fa5-39ff-49d2-96b8-cd89df22692a\", \"pipeline_definition_id\": \"692a5d5f-2020-4cd1-9570-87d8125efdbe\", \"sub_graph_parameter_assignment\": [], \"sub_graph_data_path_parameter_assignment\": [], \"sub_graph_default_compute_target_nodes\": [\"a580c213\"], \"sub_graph_default_data_store_nodes\": [\"a580c213\"], \"inputs\": [], \"outputs\": []}], \"nodeIdToSubGraphIdMapping\": {\"a580c213\": \"16500fa5-39ff-49d2-96b8-cd89df22692a\"}, \"subPipelineDefinition\": [{\"name\": \"batch inference\", \"description\": \"Batch Inference\", \"default_compute_target\": {\"name\": \"aml-compute\", \"compute_type\": \"0\"}, \"default_data_store\": {\"data_store_name\": \"workspaceblobstore\"}, \"pipeline_function_name\": \"training_pipeline\", \"id\": \"692a5d5f-2020-4cd1-9570-87d8125efdbe\", \"from_module_name\": \"__main__\", \"parameter_list\": []}]};\n",
       "                window.graph_json_to_compare=undefined;\n",
       "                window.env_json={};\n",
       "                window.before_script = performance.now();\n",
       "                var script = document.createElement('script')\n",
       "                script.src = \"https://yucongj.azureedge.net/libs/prod/0.0.9/index.js\"\n",
       "                document.getElementById(\"container_id_9229f8b8-24c7-4160-b2a0-1c2430380d20_script\").appendChild(script)\n",
       "            })()\n",
       "        </script>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# pipeline_run\n",
    "experiment_name = 'fasttext_batch_inference'\n",
    "pipeline_run = pipeline.submit(experiment_name=experiment_name, regenerate_outputs=True)\n",
    "pipeline_run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download results of batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "port = step_run.get_port(name='Scored data output dir')\n",
    "save_path = port.download(overwrite=True)\n",
    "save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fasttext",
   "language": "python",
   "name": "fasttext"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
